{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sansith/gpt2sp/blob/ensemble-gpt2/model_training_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "qyLoXxhlhfbk"
      },
      "source": [
        "# Model Training Script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Ren7VyEyhfbl"
      },
      "source": [
        "### Necessary Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMyN0hhThfbl",
        "outputId": "7688b593-3195-4953-8bb5-756733f3bd35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: pandas===1.5.3 in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: koila in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas===1.5.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas===1.5.3) (2023.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from koila) (11.5.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from koila) (13.7.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->koila) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->koila) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->koila) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install torch pandas===1.5.3 transformers numpy tokenizers koila tensorboard Cython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pdb"
      ],
      "metadata": {
        "id": "O8TuUYj7h6St"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIh96xVTiuIa",
        "outputId": "836fd895-63d9-407e-f770-eee697882681"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/Year4/FYP/effort-estimation/gpt2sp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3R16ZxuirGo",
        "outputId": "64662092-9454-48eb-f7f0-aead25f71a30"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/Year4/FYP/effort-estimation/gpt2sp'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/gpt2sp"
      ],
      "metadata": {
        "id": "HLuP4fBCSXRm",
        "outputId": "41d06559-c8fb-405a-ecec-70d7ee3083c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "ls"
      ],
      "metadata": {
        "id": "Ct8N4OzwyswX",
        "outputId": "f6d83241-1bab-4118-c084-df1c48e9f75c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mabe0\u001b[0m/                               \u001b[01;34mmodels\u001b[0m/\n",
            "\u001b[01;34mall_tokenizers\u001b[0m/                     model_training_notebook_bigBird.ipynb\n",
            "base_model_training_notebook.ipynb  model_training_notebook.ipynb\n",
            "BigBird.py                          model_training_notebook_new_impl.ipynb\n",
            "\u001b[01;34mcorpus_tokenization_comparison\u001b[0m/     \u001b[01;34m__pycache__\u001b[0m/\n",
            "\u001b[01;34mcustom_transformers_interpret\u001b[0m/      README.md\n",
            "\u001b[01;34mdata_model_analysis\u001b[0m/                \u001b[01;34mresults\u001b[0m/\n",
            "GPT2SPEN.py                         \u001b[01;34msp_dataset\u001b[0m/\n",
            "GPT2SP_inspection_notebook.ipynb    \u001b[01;34mtb\u001b[0m/\n",
            "GPT2SP.py                           tokenizer_training_notebook.ipynb\n",
            "LICENSE                             vocab_and_tokenization_comparison.ipynb\n",
            "\u001b[01;34mlogo\u001b[0m/                               \u001b[01;34mxai_tokens\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.modeling_outputs import SequenceClassifierOutputWithPast\n",
        "import torch.nn as nn\n",
        "from transformers import GPT2Model, GPT2PreTrainedModel\n",
        "import torch\n",
        "\n",
        "\n",
        "class GPT2SPEN(GPT2PreTrainedModel):\n",
        "    _keys_to_ignore_on_load_missing = [r\"h\\.\\d+\\.attn\\.masked_bias\", r\"lm_head\\.weight\"]\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.transformer = GPT2Model(config)\n",
        "        self.transformer_description = GPT2Model(config)\n",
        "        print(\"n embd :: \",config.n_embd)\n",
        "        self.dense1 = nn.Linear(2* config.n_embd, 8 * config.n_embd, bias=False)\n",
        "        self.dense2 = nn.Linear(8 * config.n_embd,2* config.n_embd, bias=False)\n",
        "        self.score = nn.Linear(2* config.n_embd, self.num_labels, bias=False)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        # Model parallel\n",
        "        self.model_parallel = False\n",
        "        self.device_map = None\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids_title=None,\n",
        "        input_ids_description=None,\n",
        "        past_key_values=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        use_cache=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
        "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
        "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        # Title model\n",
        "        transformer_outputs_title = self.transformer(\n",
        "            input_ids_title,\n",
        "            past_key_values=past_key_values,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        title_hidden_states = transformer_outputs_title[0]\n",
        "\n",
        "\n",
        "        # Description model\n",
        "        transformer_outputs_description = self.transformer_description(\n",
        "            input_ids_description,\n",
        "            past_key_values=past_key_values,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        description_hidden_states = transformer_outputs_description[0]\n",
        "\n",
        "        # Concatenate the output tensors from both models\n",
        "        concatenated_hidden_states = torch.cat((title_hidden_states, description_hidden_states), dim=2)\n",
        "        # print(\"concatenated_hidden_states len :: \",len(concatenated_hidden_states))\n",
        "        # MLP Layer\n",
        "        # pdb.set_trace()\n",
        "        hidden_states = self.dense1(concatenated_hidden_states)\n",
        "        hidden_states = self.dense2(hidden_states)\n",
        "\n",
        "        logits = self.score(hidden_states)\n",
        "\n",
        "        if input_ids_title is not None:\n",
        "            batch_size, sequence_length = input_ids_title.shape[:2]\n",
        "        else:\n",
        "            batch_size, sequence_length = inputs_embeds.shape[:2]\n",
        "\n",
        "        assert (\n",
        "            self.config.pad_token_id is not None or batch_size == 1\n",
        "        ), \"Cannot handle batch sizes > 1 if no padding token is defined.\"\n",
        "\n",
        "        if self.config.pad_token_id is None:\n",
        "            sequence_lengths = -1\n",
        "        else:\n",
        "            if input_ids_title is not None:\n",
        "                sequence_lengths = torch.ne(input_ids_title, self.config.pad_token_id).sum(-1) - 1\n",
        "            else:\n",
        "                sequence_lengths = -1\n",
        "                logger.warning(\n",
        "                    f\"{self.__class__.__name__} will not detect padding tokens in `inputs_embeds`. Results may be \"\n",
        "                    f\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"\n",
        "                )\n",
        "\n",
        "        pooled_logits = logits[range(batch_size), sequence_lengths]\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = nn.L1Loss()\n",
        "                # pdb.set_trace()\n",
        "                loss = loss_fct(pooled_logits.view(-1), labels.to(self.dtype).view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(pooled_logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (logits,) + transformer_outputs_title[1:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutputWithPast(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            past_key_values=transformer_outputs_title.past_key_values,\n",
        "            hidden_states=transformer_outputs_title.hidden_states,\n",
        "            attentions=transformer_outputs_title.attentions,\n",
        "        )"
      ],
      "metadata": {
        "id": "mQFV95HsVKMt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "tags": [],
        "id": "bhcSAPbLhfbm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from GPT2SP import GPT2ForSequenceClassification as GPT2SP\n",
        "#from GPT2SPEN import GPT2ForSequenceClassification as GPT2SPEN\n",
        "from transformers import GPT2ForSequenceClassification as LinearGPT2\n",
        "from transformers import GPT2Config\n",
        "import os\n",
        "from tokenizers import Tokenizer\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbQNj41Ghfbn"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "tags": [],
        "id": "ch24eOM0hfbn"
      },
      "outputs": [],
      "source": [
        "global EPOCHS, BATCH_SIZE_RATIO, SEQUENCE_LEN, LEARNING_RATE, TOKENIZER, MODEL_NAME , ADD_DESCRIPTION\n",
        "\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE_RATIO = 0.1# within proj: 0.3 / cross proj: 0.4\n",
        "SEQUENCE_LEN = 20\n",
        "LEARNING_RATE = 5e-4\n",
        "TOKENIZER = 'gpt2' # available: gpt2, wordlevel, sentencepiece, wordpiece\n",
        "MODEL_NAME = 'gpt2spen' # available:gpt2spen , gpt2sp, gpt2\n",
        "ADD_DESCRIPTION = False\n",
        "\n",
        "# define device\n",
        "global DEVICE\n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# define files to be used\n",
        "global DATA_PATH\n",
        "DATA_PATH = './sp_dataset/marked_data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH1j_lvmhfbn"
      },
      "source": [
        "### Static Methods and Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "tags": [],
        "id": "W1FZRuJ7hfbn"
      },
      "outputs": [],
      "source": [
        "OUTPUT = '  '\n",
        "MODEL = None\n",
        "DYNAMIC_BATCH = True\n",
        "BATCH_SIZE = None\n",
        "WITHIN_PROJECT = None\n",
        "MAE_RECORDS = []\n",
        "MDAE_RECORDS = []\n",
        "\n",
        "def data_processing(file_pair):\n",
        "    global BATCH_SIZE, BATCH_SIZE_RATIO, DATA_PATH, WITHIN_PROJECT, DYNAMIC_BATCH\n",
        "\n",
        "    train_data = pd.DataFrame(columns=['title', 'description',\"label\"])\n",
        "    for train_file_name in file_pair['train']:\n",
        "        fname = DATA_PATH + train_file_name + '.csv'\n",
        "        df = prepare_dataframe(fname)\n",
        "        train_data = train_data.append(df)\n",
        "\n",
        "    # data split\n",
        "    if WITHIN_PROJECT:\n",
        "        train_title,train_description,train_labels,  val_title,val_description,val_labels,  test_title,test_description,test_labels = within_project_split(train_data)\n",
        "    else:\n",
        "        train_title,train_description , train_labels, val_title,val_description , val_labels = train_val_split(train_data, 0.6)\n",
        "    # define batch size dynamically based on training length\n",
        "    if DYNAMIC_BATCH:\n",
        "        BATCH_SIZE = int(len(train_title) * BATCH_SIZE_RATIO)\n",
        "    # tokenization\n",
        "    title_tokens_train = tokenization(train_title.tolist())\n",
        "    description_tokens_train = tokenization(train_description.tolist())\n",
        "\n",
        "    title_tokens_val = tokenization(val_title.tolist())\n",
        "    description_tokens_val = tokenization(val_description.tolist())\n",
        "\n",
        "\n",
        "    train_seq_titles = torch.tensor(title_tokens_train['input_ids'])\n",
        "    train_seq_descriptions = torch.tensor(description_tokens_train['input_ids'])\n",
        "    train_y = torch.tensor(train_labels.tolist()).type(torch.LongTensor)\n",
        "\n",
        "    train_dataloader = prepare_dataloader(train_seq_titles,train_seq_descriptions ,  train_y, sampler_type='random')\n",
        "\n",
        "\n",
        "    val_seq_titles = torch.tensor(title_tokens_val['input_ids'])\n",
        "    val_seq__descriptions = torch.tensor(description_tokens_val['input_ids'])\n",
        "    val_y = torch.tensor(val_labels.tolist()).type(torch.LongTensor)\n",
        "\n",
        "    val_dataloader = prepare_dataloader(val_seq_titles,val_seq__descriptions ,val_y, sampler_type='sequential')\n",
        "\n",
        "    # prepare testing datasets\n",
        "    all_test_dataloader = []\n",
        "    test_file_names = []\n",
        "    if WITHIN_PROJECT:\n",
        "        tokens_test_title = tokenization(test_title.tolist())\n",
        "        tokens_test_description = tokenization(test_description.tolist())\n",
        "\n",
        "        test_seq_title = torch.tensor(tokens_test_title['input_ids'])\n",
        "        test_seq_description = torch.tensor(tokens_test_description['input_ids'])\n",
        "        test_y = torch.tensor(test_labels.tolist()).type(torch.LongTensor)\n",
        "\n",
        "        test_dataloader = prepare_dataloader(test_seq_title,test_seq_description, test_y, sampler_type='sequential')\n",
        "        all_test_dataloader.append(test_dataloader)\n",
        "        test_file_names.append(file_pair['test'][0])\n",
        "        return file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names\n",
        "\n",
        "    for test_file_name in file_pair['test']:\n",
        "        fname = DATA_PATH + test_file_name + '.csv'\n",
        "        test_data = prepare_dataframe(fname)\n",
        "\n",
        "        test_title = test_data['title']\n",
        "        test_description = test_data['description']\n",
        "        test_labels = test_data['label']\n",
        "\n",
        "        # tokenization\n",
        "        tokens_test_title = tokenization(test_title.tolist())\n",
        "        tokens_test_description = tokenization(test_description.tolist())\n",
        "        test_seq_title = torch.tensor(tokens_test_title['input_ids'])\n",
        "        test_seq_description = torch.tensor(tokens_test_description['input_ids'])\n",
        "\n",
        "        test_y = torch.tensor(test_labels.tolist()).type(torch.LongTensor)\n",
        "        test_dataloader = prepare_dataloader(test_seq_title,test_seq_description, test_y, sampler_type='sequential')\n",
        "\n",
        "        all_test_dataloader.append(test_dataloader)\n",
        "        test_file_names.append(test_file_name)\n",
        "    print('cross project data processing!')\n",
        "    return file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names\n",
        "\n",
        "\n",
        "def train_val_split(data, split_ratio):\n",
        "    print('cross project split!')\n",
        "    split_point = int(len(data) * split_ratio)\n",
        "\n",
        "    train_title = data['title'][:split_point]\n",
        "    train_description = data['description'][:split_point]\n",
        "    train_labels = data['label'][:split_point]\n",
        "\n",
        "    val_title = data['title'][split_point:]\n",
        "    val_description = data['description'][split_point:]\n",
        "    val_labels = data['label'][split_point:]\n",
        "    return train_title,train_description , train_labels, val_title,val_description , val_labels\n",
        "\n",
        "\n",
        "def tokenization(text_list):\n",
        "    global TOKENIZER, SEQUENCE_LEN, MODEL\n",
        "    # tokenization\n",
        "    if TOKENIZER == 'wordpiece':\n",
        "        print('using wordpiece tokenizer!')\n",
        "        tokenizer = BertTokenizer('all_tokenizers/word_piece/vocab.txt')\n",
        "    elif TOKENIZER == 'sentencepiece':\n",
        "        print('using sentencepiece tokenizer!')\n",
        "        tokenizer = XLNetTokenizer('all_tokenizers/sentence_piece/spm_tokenizer.model', padding_side='right')\n",
        "    elif TOKENIZER == 'wordlevel':\n",
        "        print('using wordlevel tokenizer!')\n",
        "        tokenizer = Tokenizer.from_file('all_tokenizers/word_level/wordlevel.json')\n",
        "        encoded_sentences = {'input_ids':[]}\n",
        "        for sentence in text_list:\n",
        "            encoded = tokenizer.encode(sentence)\n",
        "            encoded = encoded.ids\n",
        "            if len(encoded) > SEQUENCE_LEN:\n",
        "                encoded = encoded[:SEQUENCE_LEN]\n",
        "            elif len(encoded) < SEQUENCE_LEN:\n",
        "                padding = SEQUENCE_LEN - len(encoded)\n",
        "                for _ in range(padding):\n",
        "                    encoded.append(3)\n",
        "            encoded_sentences['input_ids'].append(encoded)\n",
        "        return encoded_sentences\n",
        "    elif TOKENIZER == 'gpt2':\n",
        "        print('using pretrained gpt-2 tokenizer')\n",
        "        tokenizer = GPT2Tokenizer.from_pretrained(TOKENIZER)\n",
        "        tokenizer.pad_token = '[PAD]'\n",
        "    return tokenizer.batch_encode_plus(text_list, truncation=True, max_length=SEQUENCE_LEN, padding='max_length')\n",
        "\n",
        "\n",
        "def prepare_dataframe(file_name):\n",
        "    data = pd.read_csv(file_name)\n",
        "    # some rows have no description, fill blank to avoid Null\n",
        "    data = data.fillna(' ')\n",
        "\n",
        "\n",
        "    # if ADD_DESCRIPTION :\n",
        "    #   print(\"### text : title+description\")\n",
        "    #   d = {'text': (data['title'] + \" : \" + data[\"description\"]).tolist(), 'label': data['storypoint']}\n",
        "    # else:\n",
        "    #   print(\"### text : title\")\n",
        "    #   d = {'text': (data['title']).tolist(), 'label': data['storypoint']}\n",
        "\n",
        "    d = { 'title':(data['title']).tolist(), 'description': (data[\"description\"]).tolist() , 'label': data['storypoint'] }\n",
        "    print(\"Input data feed ::: \",d.keys())\n",
        "    return pd.DataFrame(data=d)\n",
        "\n",
        "\n",
        "def prepare_dataloader(seq_title,seq_description, y, sampler_type):\n",
        "    global BATCH_SIZE\n",
        "    tensor_dataset = TensorDataset(seq_title,seq_description, y)\n",
        "    if sampler_type == 'random':\n",
        "        sampler = RandomSampler(tensor_dataset)\n",
        "    elif sampler_type == 'sequential':\n",
        "        sampler = SequentialSampler(tensor_dataset)\n",
        "    print(\"BATCH_SIZE : \",BATCH_SIZE)\n",
        "    dataloader = DataLoader(tensor_dataset, sampler=sampler, batch_size=BATCH_SIZE)\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def within_project_split(data):\n",
        "    print('within project split!')\n",
        "\n",
        "    train_val_split_point = int(len(data) * 0.6)\n",
        "    val_test_split_point = int(len(data) * 0.8)\n",
        "\n",
        "    train_title = data['title'][:train_val_split_point]\n",
        "    train_description = data['description'][:train_val_split_point]\n",
        "    train_labels = data['label'][:train_val_split_point]\n",
        "\n",
        "    val_title = data['title'][train_val_split_point:val_test_split_point]\n",
        "    val_description = data['description'][train_val_split_point:val_test_split_point]\n",
        "    val_labels = data['label'][train_val_split_point:val_test_split_point]\n",
        "\n",
        "    test_title = data['title'][val_test_split_point:]\n",
        "    test_description = data['description'][val_test_split_point:]\n",
        "    test_labels = data['label'][val_test_split_point:]\n",
        "\n",
        "    return train_title,train_description,train_labels,  val_title,val_description,val_labels,  test_title,test_description,test_labels\n",
        "\n",
        "\n",
        "def train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, model, test_file_names):\n",
        "    global LEARNING_RATE, EPOCHS, MAE_RECORDS, MDAE_RECORDS, DEVICE\n",
        "\n",
        "    # Optimizerrr -->\n",
        "    optimizer = AdamW(MODEL.parameters(), lr=LEARNING_RATE)\n",
        "    # Total number of training steps is [number of batches] x [number of epochs]\n",
        "    total_steps = len(train_dataloader) * EPOCHS\n",
        "    # Create the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "    print(\"Start training for \", file_pair, \".....\")\n",
        "    training_start_time = time.time()\n",
        "\n",
        "    # tensorboard writer\n",
        "    writer_path = 'tb/' + str(file_pair['train'][0]) + '_' + str(file_pair['test'][0])\n",
        "    writer = SummaryWriter(writer_path)\n",
        "\n",
        "    # vars for model selection\n",
        "    min_eval_loss_epoch = [10000, 0]\n",
        "\n",
        "    time_records = []\n",
        "    MAE_RECORDS = []\n",
        "    MDAE_RECORDS = []\n",
        "    start_time = time.time()\n",
        "    loss_fct = nn.L1Loss()\n",
        "    for e in range(EPOCHS):\n",
        "        # ---TRAINING---\n",
        "        # clean GPU memory\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\">>> epoch \", e)\n",
        "        # set model into train mode\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # pdb.set_trace()\n",
        "            b_input_ids_title = batch[0].to(DEVICE)\n",
        "            b_input_ids_description = batch[1].to(DEVICE)\n",
        "            b_labels = batch[2].to(DEVICE)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            result = model(input_ids_title=b_input_ids_title,\n",
        "                           input_ids_description=b_input_ids_description,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "            loss = result.loss\n",
        "            logits = result.logits\n",
        "            total_train_loss += loss.item()\n",
        "            # Calculates the gradients\n",
        "            loss.backward()\n",
        "            # The clip_grad_norm_ function clips (limits) the norm (magnitude) of the gradients to a maximum value specified by the user.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            #updates the weights and bias accrding to the calculated gradients\n",
        "            optimizer.step()\n",
        "            # update learning rates\n",
        "            scheduler.step()\n",
        "            # clean memory\n",
        "            del step, batch, b_input_ids_title,b_input_ids_description, b_labels, result, loss, logits\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "        print(\" Average training MAE loss: {0:.2f}\".format(avg_train_loss))\n",
        "        writer.add_scalar('loss/train', avg_train_loss, e)\n",
        "        # clean memory\n",
        "        del avg_train_loss, total_train_loss\n",
        "\n",
        "        time_records.append(time.time() - start_time)\n",
        "\n",
        "        # ---EVAL---\n",
        "        print(\"-\")\n",
        "        # set model into eval mode\n",
        "        model.eval()\n",
        "        total_eval_loss = 0\n",
        "        for batch in val_dataloader:\n",
        "            b_input_ids_title = batch[0].to(DEVICE)\n",
        "            b_input_ids_description = batch[1].to(DEVICE)\n",
        "            b_labels = batch[2].to(DEVICE)\n",
        "\n",
        "            model.zero_grad()\n",
        "            result = model(input_ids_title=b_input_ids_title,\n",
        "                           input_ids_description=b_input_ids_description,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "            loss = result.loss\n",
        "            logits = result.logits\n",
        "            total_eval_loss += loss.item()\n",
        "            # clean memory\n",
        "            del b_input_ids_title,b_input_ids_description, b_labels, batch, result, loss, logits\n",
        "        avg_eval_loss = total_eval_loss / len(val_dataloader)\n",
        "        print(\" Average eval MAE loss: {0:.2f}\".format(avg_eval_loss))\n",
        "\n",
        "        if avg_eval_loss <= min_eval_loss_epoch[0]:\n",
        "            min_eval_loss_epoch[0] = avg_eval_loss\n",
        "            min_eval_loss_epoch[1] = e\n",
        "\n",
        "        writer.add_scalar('loss/eval', avg_eval_loss, e)\n",
        "        # clean memory\n",
        "        del avg_eval_loss, total_eval_loss\n",
        "        # save model state to dict\n",
        "        torch.save(model.state_dict(), './models/' + 'epo_' + str(e))\n",
        "\n",
        "        print(\"===============================\")\n",
        "\n",
        "        # testing on holdout data\n",
        "        index = 0\n",
        "        for test_dataloader in all_test_dataloader:\n",
        "            test_file_name = test_file_names[index]\n",
        "            index += 1\n",
        "            testing_start_time = time.time()\n",
        "            predictions = []\n",
        "            true_labels = []\n",
        "            for batch in test_dataloader:\n",
        "                # batch = tuple(t.to(DEVICE) for t in batch)\n",
        "                b_input_ids_title = batch[0].to(DEVICE)\n",
        "                b_input_ids_description = batch[1].to(DEVICE)\n",
        "                b_labels = batch[2].to(DEVICE)\n",
        "\n",
        "                # b_input_ids, b_labels = batch\n",
        "                with torch.no_grad():\n",
        "                    logits = model(input_ids_title=b_input_ids_title,input_ids_description=b_input_ids_description)\n",
        "                logits = logits['logits'].detach().cpu().numpy()\n",
        "                label_ids = b_labels.to('cpu').numpy()\n",
        "                predictions.append(logits)\n",
        "                true_labels.append(label_ids)\n",
        "\n",
        "                del b_input_ids_title, b_input_ids_description ,b_labels\n",
        "            # calculate errors\n",
        "            distance_records = []\n",
        "            for i in range(len(predictions)):\n",
        "                for j in range(len(predictions[i])):\n",
        "                    distance = abs(predictions[i][j] - true_labels[i][j])\n",
        "                    distance_records.append(distance)\n",
        "\n",
        "            ## MAE = mean value of all absolute errors (stored in distance_records)\n",
        "            MAE = np.mean(np.array(distance_records))\n",
        "            ## MdAE = median value of all absolute errors (stored in distance_records)\n",
        "            MdAE = np.median(np.array(distance_records))\n",
        "\n",
        "            MAE_RECORDS.append(MAE)\n",
        "            MDAE_RECORDS.append(MdAE)\n",
        "\n",
        "            global OUTPUT\n",
        "            OUTPUT +=  'Epochs ' + str(e) + '\\n'\n",
        "            OUTPUT += 'MAE: ' + str(MAE) + '\\n'\n",
        "            OUTPUT += 'MdAE: ' + str(MdAE) + '\\n\\n'\n",
        "            print('MAE: ', MAE)\n",
        "            print('MdAE: ', MdAE)\n",
        "    writer.flush()\n",
        "    writer.close()\n",
        "\n",
        "    # select model\n",
        "    os.rename('models/epo_' + str(min_eval_loss_epoch[1]),\n",
        "              'models/' + str(file_pair['train'][0]) + '_'\n",
        "              + str(file_pair['test'][0]) + '_epo_' + str(min_eval_loss_epoch[1]))\n",
        "\n",
        "    # del unwanted models\n",
        "    for i in range(20):\n",
        "        try:\n",
        "            os.remove(\"models/epo_\" + str(i))\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    OUTPUT += 'MAE: ' + str(MAE_RECORDS[min_eval_loss_epoch[1]]) \\\n",
        "                + '  MdAE: ' + str(MDAE_RECORDS[min_eval_loss_epoch[1]]) + '\\n'\n",
        "    OUTPUT += 'training time: ' + str(time_records[min_eval_loss_epoch[1]]) + '\\n'\n",
        "    OUTPUT += 'Epochs: ' + str(min_eval_loss_epoch[1]) +'\\n'\n",
        "    global BATCH_SIZE\n",
        "    OUTPUT += 'batch size: ' + str(BATCH_SIZE) + '\\n'\n",
        "    global ADD_DESCRIPTION\n",
        "    OUTPUT += 'Description added : ' + str(ADD_DESCRIPTION) + '\\n'\n",
        "\n",
        "\n",
        "    print('all done for one project')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn3yXK4lhfbo"
      },
      "source": [
        "### Within Project Training Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "tags": [],
        "id": "x-uMZ1Cfhfbo"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f4ffffaf36024348bdaa6249f25ebc2f",
            "c0a97e9cadd248b690d9ab5543bba68c",
            "b3c8511daa5b4468a01c17ee7edabe42",
            "d046d93760924c15b2d2255679453eae",
            "6dcff16d2a2b44ed8158e080f93a6aff",
            "b3bf5fd2a4414c9f9b4bb405ac6dd74f",
            "6ff6bcacd22b441c8acf22981e0af00a",
            "ac0ba7793639442b8b2831f85a9dda95",
            "45c75277604e4e6abe159524ac3751b5",
            "c26923bf2a8243e491c0ca5c03bd5b87",
            "1274b971fa5748b9b7c849bbcc9b7e5d",
            "8b4d06ecb81e460aaa329c654224f42c",
            "817a0b00ee6f4f44b215ac553bb45974",
            "01bce2f5e54e4beaae521e51f0a0b655",
            "4c710b472c67480da4952a4ee2c15e33",
            "f8bfbc71b3604bcf9a230b0f006bc21e",
            "6cd4ab3fc488409aba11978457338148",
            "57c66773182a4e089079a9cd71961fab",
            "ed246449def2450f8a3e2595d6c64fb3",
            "3a42df29cefd4d83a95389cb2d94d37e",
            "c0050d6e82f041f98063f89edee0900e",
            "643cbf4768fe424ba717b86c4a779365",
            "86d9324ba51a4baf875698254f8a5e78",
            "dcec0bbe0dfd4eac90c6cd0b28f4689b",
            "49e88bfdc1f3461aa5e8b1e8ad9e266f",
            "e5a01c6ec3c741a3a48e30f63a75d607",
            "1c0a38953d064d56a09d9cb150306187",
            "f0a555f8569e4142b8c530f152597397",
            "ea204766ccfc454ba0dc8084066ff377",
            "3405f57f417b4781b3cef8bb17ba0243",
            "279d5204c8a542748d70d38082a1aeaf",
            "c47b4f0b4f8d41aeabb739b7f95b43d3",
            "21e5bc2fba2a43eda7e4b17ff328fbe3",
            "d44459a090994330ab09216a07e24dba",
            "672256d9aaee41268844e0484b9abe36",
            "51b0d1c682a54dabb6f74137276420f1",
            "e2ce808ce8f94337bae09db0de40ae88",
            "8c6ee65dbd7c4c83a3548972ab449beb",
            "c6606cc47ab845cdb972525df2895269",
            "30cd635f27f34212a2662e75414decca",
            "f813b55fcbbc4c3894b64ac5b3520ee2",
            "39236b1b25ec48fc9a406dfb26831448",
            "cb570f7319cf46a79cf0f3309b3bd8ae",
            "69e22f3a46e54fd4901790805bd3f901",
            "c65660de51e54844aba5e351f4cca351",
            "b444dd97f5134b20bbffedcb1924afa2",
            "53a66a8d49ed40f1a644560f4e60d832",
            "4da0a6100d1347c0984cdf0f38dac085",
            "59761fcd467e4ceba81f159437f87041",
            "b15ddd79917b409da989761389840aef",
            "6734704bea6b45288f966e53c5a10f02",
            "d0ace0b243af420187bbb21fcbcdb82b",
            "60db5bb4041f4e899408426eda5e5252",
            "2dc731d72e9a4dfca01f10efc188b956",
            "afa5b38b5ab64623bde56048a376922d",
            "b7c05a3a34f34c718834bbbac1f3744a",
            "de083215c76c4e71b8214bc3c573b4e4",
            "ba597e2a8ef546b8a920eece50eab4b4",
            "9e7f546dc88d4f23b6d0c7cadc98a2bb",
            "194e9f2fc71e4e85b887d7d088955c89",
            "3342d2b5e79d48f1839dea1c3099c84c",
            "df818aaed0784ce28316acc4fdb2adbe",
            "e252cde50dfb49e6a5e4d2cd54f08bb0",
            "43002142a6fb4522a2110bc6cc5e1d3c",
            "83dca60325f3457abf21e55cb813ec6f",
            "e7a3b6c564db4b21b5fce0b22af9e494"
          ]
        },
        "id": "MwmBk2BPhfbo",
        "outputId": "08e13694-9538-4e10-df0b-bcf541e30ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4ffffaf36024348bdaa6249f25ebc2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n embd ::  768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2SPEN were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight', 'transformer_description.h.0.attn.c_attn.bias', 'transformer_description.h.0.attn.c_attn.weight', 'transformer_description.h.0.attn.c_proj.bias', 'transformer_description.h.0.attn.c_proj.weight', 'transformer_description.h.0.ln_1.bias', 'transformer_description.h.0.ln_1.weight', 'transformer_description.h.0.ln_2.bias', 'transformer_description.h.0.ln_2.weight', 'transformer_description.h.0.mlp.c_fc.bias', 'transformer_description.h.0.mlp.c_fc.weight', 'transformer_description.h.0.mlp.c_proj.bias', 'transformer_description.h.0.mlp.c_proj.weight', 'transformer_description.h.1.attn.c_attn.bias', 'transformer_description.h.1.attn.c_attn.weight', 'transformer_description.h.1.attn.c_proj.bias', 'transformer_description.h.1.attn.c_proj.weight', 'transformer_description.h.1.ln_1.bias', 'transformer_description.h.1.ln_1.weight', 'transformer_description.h.1.ln_2.bias', 'transformer_description.h.1.ln_2.weight', 'transformer_description.h.1.mlp.c_fc.bias', 'transformer_description.h.1.mlp.c_fc.weight', 'transformer_description.h.1.mlp.c_proj.bias', 'transformer_description.h.1.mlp.c_proj.weight', 'transformer_description.h.10.attn.c_attn.bias', 'transformer_description.h.10.attn.c_attn.weight', 'transformer_description.h.10.attn.c_proj.bias', 'transformer_description.h.10.attn.c_proj.weight', 'transformer_description.h.10.ln_1.bias', 'transformer_description.h.10.ln_1.weight', 'transformer_description.h.10.ln_2.bias', 'transformer_description.h.10.ln_2.weight', 'transformer_description.h.10.mlp.c_fc.bias', 'transformer_description.h.10.mlp.c_fc.weight', 'transformer_description.h.10.mlp.c_proj.bias', 'transformer_description.h.10.mlp.c_proj.weight', 'transformer_description.h.11.attn.c_attn.bias', 'transformer_description.h.11.attn.c_attn.weight', 'transformer_description.h.11.attn.c_proj.bias', 'transformer_description.h.11.attn.c_proj.weight', 'transformer_description.h.11.ln_1.bias', 'transformer_description.h.11.ln_1.weight', 'transformer_description.h.11.ln_2.bias', 'transformer_description.h.11.ln_2.weight', 'transformer_description.h.11.mlp.c_fc.bias', 'transformer_description.h.11.mlp.c_fc.weight', 'transformer_description.h.11.mlp.c_proj.bias', 'transformer_description.h.11.mlp.c_proj.weight', 'transformer_description.h.2.attn.c_attn.bias', 'transformer_description.h.2.attn.c_attn.weight', 'transformer_description.h.2.attn.c_proj.bias', 'transformer_description.h.2.attn.c_proj.weight', 'transformer_description.h.2.ln_1.bias', 'transformer_description.h.2.ln_1.weight', 'transformer_description.h.2.ln_2.bias', 'transformer_description.h.2.ln_2.weight', 'transformer_description.h.2.mlp.c_fc.bias', 'transformer_description.h.2.mlp.c_fc.weight', 'transformer_description.h.2.mlp.c_proj.bias', 'transformer_description.h.2.mlp.c_proj.weight', 'transformer_description.h.3.attn.c_attn.bias', 'transformer_description.h.3.attn.c_attn.weight', 'transformer_description.h.3.attn.c_proj.bias', 'transformer_description.h.3.attn.c_proj.weight', 'transformer_description.h.3.ln_1.bias', 'transformer_description.h.3.ln_1.weight', 'transformer_description.h.3.ln_2.bias', 'transformer_description.h.3.ln_2.weight', 'transformer_description.h.3.mlp.c_fc.bias', 'transformer_description.h.3.mlp.c_fc.weight', 'transformer_description.h.3.mlp.c_proj.bias', 'transformer_description.h.3.mlp.c_proj.weight', 'transformer_description.h.4.attn.c_attn.bias', 'transformer_description.h.4.attn.c_attn.weight', 'transformer_description.h.4.attn.c_proj.bias', 'transformer_description.h.4.attn.c_proj.weight', 'transformer_description.h.4.ln_1.bias', 'transformer_description.h.4.ln_1.weight', 'transformer_description.h.4.ln_2.bias', 'transformer_description.h.4.ln_2.weight', 'transformer_description.h.4.mlp.c_fc.bias', 'transformer_description.h.4.mlp.c_fc.weight', 'transformer_description.h.4.mlp.c_proj.bias', 'transformer_description.h.4.mlp.c_proj.weight', 'transformer_description.h.5.attn.c_attn.bias', 'transformer_description.h.5.attn.c_attn.weight', 'transformer_description.h.5.attn.c_proj.bias', 'transformer_description.h.5.attn.c_proj.weight', 'transformer_description.h.5.ln_1.bias', 'transformer_description.h.5.ln_1.weight', 'transformer_description.h.5.ln_2.bias', 'transformer_description.h.5.ln_2.weight', 'transformer_description.h.5.mlp.c_fc.bias', 'transformer_description.h.5.mlp.c_fc.weight', 'transformer_description.h.5.mlp.c_proj.bias', 'transformer_description.h.5.mlp.c_proj.weight', 'transformer_description.h.6.attn.c_attn.bias', 'transformer_description.h.6.attn.c_attn.weight', 'transformer_description.h.6.attn.c_proj.bias', 'transformer_description.h.6.attn.c_proj.weight', 'transformer_description.h.6.ln_1.bias', 'transformer_description.h.6.ln_1.weight', 'transformer_description.h.6.ln_2.bias', 'transformer_description.h.6.ln_2.weight', 'transformer_description.h.6.mlp.c_fc.bias', 'transformer_description.h.6.mlp.c_fc.weight', 'transformer_description.h.6.mlp.c_proj.bias', 'transformer_description.h.6.mlp.c_proj.weight', 'transformer_description.h.7.attn.c_attn.bias', 'transformer_description.h.7.attn.c_attn.weight', 'transformer_description.h.7.attn.c_proj.bias', 'transformer_description.h.7.attn.c_proj.weight', 'transformer_description.h.7.ln_1.bias', 'transformer_description.h.7.ln_1.weight', 'transformer_description.h.7.ln_2.bias', 'transformer_description.h.7.ln_2.weight', 'transformer_description.h.7.mlp.c_fc.bias', 'transformer_description.h.7.mlp.c_fc.weight', 'transformer_description.h.7.mlp.c_proj.bias', 'transformer_description.h.7.mlp.c_proj.weight', 'transformer_description.h.8.attn.c_attn.bias', 'transformer_description.h.8.attn.c_attn.weight', 'transformer_description.h.8.attn.c_proj.bias', 'transformer_description.h.8.attn.c_proj.weight', 'transformer_description.h.8.ln_1.bias', 'transformer_description.h.8.ln_1.weight', 'transformer_description.h.8.ln_2.bias', 'transformer_description.h.8.ln_2.weight', 'transformer_description.h.8.mlp.c_fc.bias', 'transformer_description.h.8.mlp.c_fc.weight', 'transformer_description.h.8.mlp.c_proj.bias', 'transformer_description.h.8.mlp.c_proj.weight', 'transformer_description.h.9.attn.c_attn.bias', 'transformer_description.h.9.attn.c_attn.weight', 'transformer_description.h.9.attn.c_proj.bias', 'transformer_description.h.9.attn.c_proj.weight', 'transformer_description.h.9.ln_1.bias', 'transformer_description.h.9.ln_1.weight', 'transformer_description.h.9.ln_2.bias', 'transformer_description.h.9.ln_2.weight', 'transformer_description.h.9.mlp.c_fc.bias', 'transformer_description.h.9.mlp.c_fc.weight', 'transformer_description.h.9.mlp.c_proj.bias', 'transformer_description.h.9.mlp.c_proj.weight', 'transformer_description.ln_f.bias', 'transformer_description.ln_f.weight', 'transformer_description.wpe.weight', 'transformer_description.wte.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data feed :::  dict_keys(['title', 'description', 'label'])\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-55aa6fcdda15>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b4d06ecb81e460aaa329c654224f42c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86d9324ba51a4baf875698254f8a5e78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d44459a090994330ab09216a07e24dba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c65660de51e54844aba5e351f4cca351"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7c05a3a34f34c718834bbbac1f3744a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "using pretrained gpt-2 tokenizer\n",
            "using pretrained gpt-2 tokenizer\n",
            "BATCH_SIZE :  39\n",
            "BATCH_SIZE :  39\n",
            "using pretrained gpt-2 tokenizer\n",
            "using pretrained gpt-2 tokenizer\n",
            "BATCH_SIZE :  39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training for  {'train': ['duracloud'], 'test': ['duracloud']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 75.13\n",
            "-\n",
            " Average eval MAE loss: 14.58\n",
            "===============================\n",
            "MAE:  30.399889\n",
            "MdAE:  24.185776\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 13.08\n",
            "-\n",
            " Average eval MAE loss: 7.99\n",
            "===============================\n",
            "MAE:  7.9924207\n",
            "MdAE:  7.848277\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 8.55\n",
            "-\n",
            " Average eval MAE loss: 6.21\n",
            "===============================\n",
            "MAE:  6.2100515\n",
            "MdAE:  6.300209\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 4.19\n",
            "-\n",
            " Average eval MAE loss: 2.73\n",
            "===============================\n",
            "MAE:  2.570571\n",
            "MdAE:  2.4922552\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 1.82\n",
            "-\n",
            " Average eval MAE loss: 0.85\n",
            "===============================\n",
            "MAE:  0.80157\n",
            "MdAE:  0.51126164\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 1.59\n",
            "-\n",
            " Average eval MAE loss: 1.39\n",
            "===============================\n",
            "MAE:  1.2834293\n",
            "MdAE:  1.4396579\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 1.38\n",
            "-\n",
            " Average eval MAE loss: 1.10\n",
            "===============================\n",
            "MAE:  0.9834571\n",
            "MdAE:  0.94485843\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 1.20\n",
            "-\n",
            " Average eval MAE loss: 1.42\n",
            "===============================\n",
            "MAE:  1.3170936\n",
            "MdAE:  1.0275536\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 1.23\n",
            "-\n",
            " Average eval MAE loss: 0.84\n",
            "===============================\n",
            "MAE:  0.8488635\n",
            "MdAE:  0.542537\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 0.98\n",
            "-\n",
            " Average eval MAE loss: 0.98\n",
            "===============================\n",
            "MAE:  0.89480126\n",
            "MdAE:  0.6200574\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 0.94\n",
            "-\n",
            " Average eval MAE loss: 1.01\n",
            "===============================\n",
            "MAE:  0.87003046\n",
            "MdAE:  0.60445374\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 0.89\n",
            "-\n",
            " Average eval MAE loss: 1.10\n",
            "===============================\n",
            "MAE:  0.9319406\n",
            "MdAE:  0.5765511\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 0.80\n",
            "-\n",
            " Average eval MAE loss: 0.94\n",
            "===============================\n",
            "MAE:  0.8552536\n",
            "MdAE:  0.58787596\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 0.71\n",
            "-\n",
            " Average eval MAE loss: 0.91\n",
            "===============================\n",
            "MAE:  0.85052973\n",
            "MdAE:  0.86926126\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 0.63\n",
            "-\n",
            " Average eval MAE loss: 0.88\n",
            "===============================\n",
            "MAE:  0.78502697\n",
            "MdAE:  0.5145235\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 0.48\n",
            "-\n",
            " Average eval MAE loss: 0.91\n",
            "===============================\n",
            "MAE:  0.8046198\n",
            "MdAE:  0.5333067\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 0.41\n",
            "-\n",
            " Average eval MAE loss: 0.98\n",
            "===============================\n",
            "MAE:  0.8408227\n",
            "MdAE:  0.62628156\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 0.49\n",
            "-\n",
            " Average eval MAE loss: 0.92\n",
            "===============================\n",
            "MAE:  0.79900146\n",
            "MdAE:  0.58835113\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 0.39\n",
            "-\n",
            " Average eval MAE loss: 0.96\n",
            "===============================\n",
            "MAE:  0.8214217\n",
            "MdAE:  0.6571267\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 0.39\n",
            "-\n",
            " Average eval MAE loss: 0.90\n",
            "===============================\n",
            "MAE:  0.7906732\n",
            "MdAE:  0.5204937\n",
            "all done for one project\n",
            "results have been written into a text file!\n",
            "n embd ::  768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2SPEN were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight', 'transformer_description.h.0.attn.c_attn.bias', 'transformer_description.h.0.attn.c_attn.weight', 'transformer_description.h.0.attn.c_proj.bias', 'transformer_description.h.0.attn.c_proj.weight', 'transformer_description.h.0.ln_1.bias', 'transformer_description.h.0.ln_1.weight', 'transformer_description.h.0.ln_2.bias', 'transformer_description.h.0.ln_2.weight', 'transformer_description.h.0.mlp.c_fc.bias', 'transformer_description.h.0.mlp.c_fc.weight', 'transformer_description.h.0.mlp.c_proj.bias', 'transformer_description.h.0.mlp.c_proj.weight', 'transformer_description.h.1.attn.c_attn.bias', 'transformer_description.h.1.attn.c_attn.weight', 'transformer_description.h.1.attn.c_proj.bias', 'transformer_description.h.1.attn.c_proj.weight', 'transformer_description.h.1.ln_1.bias', 'transformer_description.h.1.ln_1.weight', 'transformer_description.h.1.ln_2.bias', 'transformer_description.h.1.ln_2.weight', 'transformer_description.h.1.mlp.c_fc.bias', 'transformer_description.h.1.mlp.c_fc.weight', 'transformer_description.h.1.mlp.c_proj.bias', 'transformer_description.h.1.mlp.c_proj.weight', 'transformer_description.h.10.attn.c_attn.bias', 'transformer_description.h.10.attn.c_attn.weight', 'transformer_description.h.10.attn.c_proj.bias', 'transformer_description.h.10.attn.c_proj.weight', 'transformer_description.h.10.ln_1.bias', 'transformer_description.h.10.ln_1.weight', 'transformer_description.h.10.ln_2.bias', 'transformer_description.h.10.ln_2.weight', 'transformer_description.h.10.mlp.c_fc.bias', 'transformer_description.h.10.mlp.c_fc.weight', 'transformer_description.h.10.mlp.c_proj.bias', 'transformer_description.h.10.mlp.c_proj.weight', 'transformer_description.h.11.attn.c_attn.bias', 'transformer_description.h.11.attn.c_attn.weight', 'transformer_description.h.11.attn.c_proj.bias', 'transformer_description.h.11.attn.c_proj.weight', 'transformer_description.h.11.ln_1.bias', 'transformer_description.h.11.ln_1.weight', 'transformer_description.h.11.ln_2.bias', 'transformer_description.h.11.ln_2.weight', 'transformer_description.h.11.mlp.c_fc.bias', 'transformer_description.h.11.mlp.c_fc.weight', 'transformer_description.h.11.mlp.c_proj.bias', 'transformer_description.h.11.mlp.c_proj.weight', 'transformer_description.h.2.attn.c_attn.bias', 'transformer_description.h.2.attn.c_attn.weight', 'transformer_description.h.2.attn.c_proj.bias', 'transformer_description.h.2.attn.c_proj.weight', 'transformer_description.h.2.ln_1.bias', 'transformer_description.h.2.ln_1.weight', 'transformer_description.h.2.ln_2.bias', 'transformer_description.h.2.ln_2.weight', 'transformer_description.h.2.mlp.c_fc.bias', 'transformer_description.h.2.mlp.c_fc.weight', 'transformer_description.h.2.mlp.c_proj.bias', 'transformer_description.h.2.mlp.c_proj.weight', 'transformer_description.h.3.attn.c_attn.bias', 'transformer_description.h.3.attn.c_attn.weight', 'transformer_description.h.3.attn.c_proj.bias', 'transformer_description.h.3.attn.c_proj.weight', 'transformer_description.h.3.ln_1.bias', 'transformer_description.h.3.ln_1.weight', 'transformer_description.h.3.ln_2.bias', 'transformer_description.h.3.ln_2.weight', 'transformer_description.h.3.mlp.c_fc.bias', 'transformer_description.h.3.mlp.c_fc.weight', 'transformer_description.h.3.mlp.c_proj.bias', 'transformer_description.h.3.mlp.c_proj.weight', 'transformer_description.h.4.attn.c_attn.bias', 'transformer_description.h.4.attn.c_attn.weight', 'transformer_description.h.4.attn.c_proj.bias', 'transformer_description.h.4.attn.c_proj.weight', 'transformer_description.h.4.ln_1.bias', 'transformer_description.h.4.ln_1.weight', 'transformer_description.h.4.ln_2.bias', 'transformer_description.h.4.ln_2.weight', 'transformer_description.h.4.mlp.c_fc.bias', 'transformer_description.h.4.mlp.c_fc.weight', 'transformer_description.h.4.mlp.c_proj.bias', 'transformer_description.h.4.mlp.c_proj.weight', 'transformer_description.h.5.attn.c_attn.bias', 'transformer_description.h.5.attn.c_attn.weight', 'transformer_description.h.5.attn.c_proj.bias', 'transformer_description.h.5.attn.c_proj.weight', 'transformer_description.h.5.ln_1.bias', 'transformer_description.h.5.ln_1.weight', 'transformer_description.h.5.ln_2.bias', 'transformer_description.h.5.ln_2.weight', 'transformer_description.h.5.mlp.c_fc.bias', 'transformer_description.h.5.mlp.c_fc.weight', 'transformer_description.h.5.mlp.c_proj.bias', 'transformer_description.h.5.mlp.c_proj.weight', 'transformer_description.h.6.attn.c_attn.bias', 'transformer_description.h.6.attn.c_attn.weight', 'transformer_description.h.6.attn.c_proj.bias', 'transformer_description.h.6.attn.c_proj.weight', 'transformer_description.h.6.ln_1.bias', 'transformer_description.h.6.ln_1.weight', 'transformer_description.h.6.ln_2.bias', 'transformer_description.h.6.ln_2.weight', 'transformer_description.h.6.mlp.c_fc.bias', 'transformer_description.h.6.mlp.c_fc.weight', 'transformer_description.h.6.mlp.c_proj.bias', 'transformer_description.h.6.mlp.c_proj.weight', 'transformer_description.h.7.attn.c_attn.bias', 'transformer_description.h.7.attn.c_attn.weight', 'transformer_description.h.7.attn.c_proj.bias', 'transformer_description.h.7.attn.c_proj.weight', 'transformer_description.h.7.ln_1.bias', 'transformer_description.h.7.ln_1.weight', 'transformer_description.h.7.ln_2.bias', 'transformer_description.h.7.ln_2.weight', 'transformer_description.h.7.mlp.c_fc.bias', 'transformer_description.h.7.mlp.c_fc.weight', 'transformer_description.h.7.mlp.c_proj.bias', 'transformer_description.h.7.mlp.c_proj.weight', 'transformer_description.h.8.attn.c_attn.bias', 'transformer_description.h.8.attn.c_attn.weight', 'transformer_description.h.8.attn.c_proj.bias', 'transformer_description.h.8.attn.c_proj.weight', 'transformer_description.h.8.ln_1.bias', 'transformer_description.h.8.ln_1.weight', 'transformer_description.h.8.ln_2.bias', 'transformer_description.h.8.ln_2.weight', 'transformer_description.h.8.mlp.c_fc.bias', 'transformer_description.h.8.mlp.c_fc.weight', 'transformer_description.h.8.mlp.c_proj.bias', 'transformer_description.h.8.mlp.c_proj.weight', 'transformer_description.h.9.attn.c_attn.bias', 'transformer_description.h.9.attn.c_attn.weight', 'transformer_description.h.9.attn.c_proj.bias', 'transformer_description.h.9.attn.c_proj.weight', 'transformer_description.h.9.ln_1.bias', 'transformer_description.h.9.ln_1.weight', 'transformer_description.h.9.ln_2.bias', 'transformer_description.h.9.ln_2.weight', 'transformer_description.h.9.mlp.c_fc.bias', 'transformer_description.h.9.mlp.c_fc.weight', 'transformer_description.h.9.mlp.c_proj.bias', 'transformer_description.h.9.mlp.c_proj.weight', 'transformer_description.ln_f.bias', 'transformer_description.ln_f.weight', 'transformer_description.wpe.weight', 'transformer_description.wte.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data feed :::  dict_keys(['title', 'description', 'label'])\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-55aa6fcdda15>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "using pretrained gpt-2 tokenizer\n",
            "using pretrained gpt-2 tokenizer\n",
            "BATCH_SIZE :  21\n",
            "BATCH_SIZE :  21\n",
            "using pretrained gpt-2 tokenizer\n",
            "using pretrained gpt-2 tokenizer\n",
            "BATCH_SIZE :  21\n",
            "Start training for  {'train': ['jirasoftware'], 'test': ['jirasoftware']} .....\n",
            ">>> epoch  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Average training MAE loss: 120.50\n",
            "-\n",
            " Average eval MAE loss: 18.72\n",
            "===============================\n",
            "MAE:  20.781164\n",
            "MdAE:  21.835417\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 18.47\n",
            "-\n",
            " Average eval MAE loss: 6.36\n",
            "===============================\n",
            "MAE:  6.405342\n",
            "MdAE:  6.524032\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 4.40\n",
            "-\n",
            " Average eval MAE loss: 1.56\n",
            "===============================\n",
            "MAE:  2.0064523\n",
            "MdAE:  1.1797074\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 5.76\n",
            "-\n",
            " Average eval MAE loss: 4.76\n",
            "===============================\n",
            "MAE:  4.8181124\n",
            "MdAE:  4.8410325\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 3.23\n",
            "-\n",
            " Average eval MAE loss: 1.97\n",
            "===============================\n",
            "MAE:  2.943227\n",
            "MdAE:  2.223536\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 2.89\n",
            "-\n",
            " Average eval MAE loss: 4.85\n",
            "===============================\n",
            "MAE:  4.586685\n",
            "MdAE:  4.776385\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 3.29\n",
            "-\n",
            " Average eval MAE loss: 2.23\n",
            "===============================\n",
            "MAE:  2.838091\n",
            "MdAE:  2.25555\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 3.62\n",
            "-\n",
            " Average eval MAE loss: 3.05\n",
            "===============================\n",
            "MAE:  2.984318\n",
            "MdAE:  2.5723853\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 3.24\n",
            "-\n",
            " Average eval MAE loss: 4.85\n",
            "===============================\n",
            "MAE:  2.9450326\n",
            "MdAE:  2.6905394\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 2.76\n",
            "-\n",
            " Average eval MAE loss: 4.48\n",
            "===============================\n",
            "MAE:  3.33518\n",
            "MdAE:  3.3240032\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 2.57\n",
            "-\n",
            " Average eval MAE loss: 2.88\n",
            "===============================\n",
            "MAE:  2.215452\n",
            "MdAE:  1.6305623\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 1.91\n",
            "-\n",
            " Average eval MAE loss: 1.64\n",
            "===============================\n",
            "MAE:  2.3546975\n",
            "MdAE:  1.4361669\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 2.13\n",
            "-\n",
            " Average eval MAE loss: 2.08\n",
            "===============================\n",
            "MAE:  2.0865963\n",
            "MdAE:  1.5968509\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 2.41\n",
            "-\n",
            " Average eval MAE loss: 1.69\n",
            "===============================\n",
            "MAE:  1.7815695\n",
            "MdAE:  1.2482693\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 2.08\n",
            "-\n",
            " Average eval MAE loss: 3.55\n",
            "===============================\n",
            "MAE:  2.366534\n",
            "MdAE:  1.9834375\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 1.61\n",
            "-\n",
            " Average eval MAE loss: 2.54\n",
            "===============================\n",
            "MAE:  2.1695347\n",
            "MdAE:  1.9991012\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 1.32\n",
            "-\n",
            " Average eval MAE loss: 2.35\n",
            "===============================\n",
            "MAE:  2.0110571\n",
            "MdAE:  1.5147868\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 0.96\n",
            "-\n",
            " Average eval MAE loss: 2.08\n",
            "===============================\n",
            "MAE:  1.8663967\n",
            "MdAE:  1.4309746\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 0.85\n",
            "-\n",
            " Average eval MAE loss: 2.25\n",
            "===============================\n",
            "MAE:  1.9542947\n",
            "MdAE:  1.4863626\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 0.90\n",
            "-\n",
            " Average eval MAE loss: 2.50\n",
            "===============================\n",
            "MAE:  2.0428057\n",
            "MdAE:  1.5841191\n",
            "all done for one project\n",
            "results have been written into a text file!\n",
            "n embd ::  768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2SPEN were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight', 'transformer_description.h.0.attn.c_attn.bias', 'transformer_description.h.0.attn.c_attn.weight', 'transformer_description.h.0.attn.c_proj.bias', 'transformer_description.h.0.attn.c_proj.weight', 'transformer_description.h.0.ln_1.bias', 'transformer_description.h.0.ln_1.weight', 'transformer_description.h.0.ln_2.bias', 'transformer_description.h.0.ln_2.weight', 'transformer_description.h.0.mlp.c_fc.bias', 'transformer_description.h.0.mlp.c_fc.weight', 'transformer_description.h.0.mlp.c_proj.bias', 'transformer_description.h.0.mlp.c_proj.weight', 'transformer_description.h.1.attn.c_attn.bias', 'transformer_description.h.1.attn.c_attn.weight', 'transformer_description.h.1.attn.c_proj.bias', 'transformer_description.h.1.attn.c_proj.weight', 'transformer_description.h.1.ln_1.bias', 'transformer_description.h.1.ln_1.weight', 'transformer_description.h.1.ln_2.bias', 'transformer_description.h.1.ln_2.weight', 'transformer_description.h.1.mlp.c_fc.bias', 'transformer_description.h.1.mlp.c_fc.weight', 'transformer_description.h.1.mlp.c_proj.bias', 'transformer_description.h.1.mlp.c_proj.weight', 'transformer_description.h.10.attn.c_attn.bias', 'transformer_description.h.10.attn.c_attn.weight', 'transformer_description.h.10.attn.c_proj.bias', 'transformer_description.h.10.attn.c_proj.weight', 'transformer_description.h.10.ln_1.bias', 'transformer_description.h.10.ln_1.weight', 'transformer_description.h.10.ln_2.bias', 'transformer_description.h.10.ln_2.weight', 'transformer_description.h.10.mlp.c_fc.bias', 'transformer_description.h.10.mlp.c_fc.weight', 'transformer_description.h.10.mlp.c_proj.bias', 'transformer_description.h.10.mlp.c_proj.weight', 'transformer_description.h.11.attn.c_attn.bias', 'transformer_description.h.11.attn.c_attn.weight', 'transformer_description.h.11.attn.c_proj.bias', 'transformer_description.h.11.attn.c_proj.weight', 'transformer_description.h.11.ln_1.bias', 'transformer_description.h.11.ln_1.weight', 'transformer_description.h.11.ln_2.bias', 'transformer_description.h.11.ln_2.weight', 'transformer_description.h.11.mlp.c_fc.bias', 'transformer_description.h.11.mlp.c_fc.weight', 'transformer_description.h.11.mlp.c_proj.bias', 'transformer_description.h.11.mlp.c_proj.weight', 'transformer_description.h.2.attn.c_attn.bias', 'transformer_description.h.2.attn.c_attn.weight', 'transformer_description.h.2.attn.c_proj.bias', 'transformer_description.h.2.attn.c_proj.weight', 'transformer_description.h.2.ln_1.bias', 'transformer_description.h.2.ln_1.weight', 'transformer_description.h.2.ln_2.bias', 'transformer_description.h.2.ln_2.weight', 'transformer_description.h.2.mlp.c_fc.bias', 'transformer_description.h.2.mlp.c_fc.weight', 'transformer_description.h.2.mlp.c_proj.bias', 'transformer_description.h.2.mlp.c_proj.weight', 'transformer_description.h.3.attn.c_attn.bias', 'transformer_description.h.3.attn.c_attn.weight', 'transformer_description.h.3.attn.c_proj.bias', 'transformer_description.h.3.attn.c_proj.weight', 'transformer_description.h.3.ln_1.bias', 'transformer_description.h.3.ln_1.weight', 'transformer_description.h.3.ln_2.bias', 'transformer_description.h.3.ln_2.weight', 'transformer_description.h.3.mlp.c_fc.bias', 'transformer_description.h.3.mlp.c_fc.weight', 'transformer_description.h.3.mlp.c_proj.bias', 'transformer_description.h.3.mlp.c_proj.weight', 'transformer_description.h.4.attn.c_attn.bias', 'transformer_description.h.4.attn.c_attn.weight', 'transformer_description.h.4.attn.c_proj.bias', 'transformer_description.h.4.attn.c_proj.weight', 'transformer_description.h.4.ln_1.bias', 'transformer_description.h.4.ln_1.weight', 'transformer_description.h.4.ln_2.bias', 'transformer_description.h.4.ln_2.weight', 'transformer_description.h.4.mlp.c_fc.bias', 'transformer_description.h.4.mlp.c_fc.weight', 'transformer_description.h.4.mlp.c_proj.bias', 'transformer_description.h.4.mlp.c_proj.weight', 'transformer_description.h.5.attn.c_attn.bias', 'transformer_description.h.5.attn.c_attn.weight', 'transformer_description.h.5.attn.c_proj.bias', 'transformer_description.h.5.attn.c_proj.weight', 'transformer_description.h.5.ln_1.bias', 'transformer_description.h.5.ln_1.weight', 'transformer_description.h.5.ln_2.bias', 'transformer_description.h.5.ln_2.weight', 'transformer_description.h.5.mlp.c_fc.bias', 'transformer_description.h.5.mlp.c_fc.weight', 'transformer_description.h.5.mlp.c_proj.bias', 'transformer_description.h.5.mlp.c_proj.weight', 'transformer_description.h.6.attn.c_attn.bias', 'transformer_description.h.6.attn.c_attn.weight', 'transformer_description.h.6.attn.c_proj.bias', 'transformer_description.h.6.attn.c_proj.weight', 'transformer_description.h.6.ln_1.bias', 'transformer_description.h.6.ln_1.weight', 'transformer_description.h.6.ln_2.bias', 'transformer_description.h.6.ln_2.weight', 'transformer_description.h.6.mlp.c_fc.bias', 'transformer_description.h.6.mlp.c_fc.weight', 'transformer_description.h.6.mlp.c_proj.bias', 'transformer_description.h.6.mlp.c_proj.weight', 'transformer_description.h.7.attn.c_attn.bias', 'transformer_description.h.7.attn.c_attn.weight', 'transformer_description.h.7.attn.c_proj.bias', 'transformer_description.h.7.attn.c_proj.weight', 'transformer_description.h.7.ln_1.bias', 'transformer_description.h.7.ln_1.weight', 'transformer_description.h.7.ln_2.bias', 'transformer_description.h.7.ln_2.weight', 'transformer_description.h.7.mlp.c_fc.bias', 'transformer_description.h.7.mlp.c_fc.weight', 'transformer_description.h.7.mlp.c_proj.bias', 'transformer_description.h.7.mlp.c_proj.weight', 'transformer_description.h.8.attn.c_attn.bias', 'transformer_description.h.8.attn.c_attn.weight', 'transformer_description.h.8.attn.c_proj.bias', 'transformer_description.h.8.attn.c_proj.weight', 'transformer_description.h.8.ln_1.bias', 'transformer_description.h.8.ln_1.weight', 'transformer_description.h.8.ln_2.bias', 'transformer_description.h.8.ln_2.weight', 'transformer_description.h.8.mlp.c_fc.bias', 'transformer_description.h.8.mlp.c_fc.weight', 'transformer_description.h.8.mlp.c_proj.bias', 'transformer_description.h.8.mlp.c_proj.weight', 'transformer_description.h.9.attn.c_attn.bias', 'transformer_description.h.9.attn.c_attn.weight', 'transformer_description.h.9.attn.c_proj.bias', 'transformer_description.h.9.attn.c_proj.weight', 'transformer_description.h.9.ln_1.bias', 'transformer_description.h.9.ln_1.weight', 'transformer_description.h.9.ln_2.bias', 'transformer_description.h.9.ln_2.weight', 'transformer_description.h.9.mlp.c_fc.bias', 'transformer_description.h.9.mlp.c_fc.weight', 'transformer_description.h.9.mlp.c_proj.bias', 'transformer_description.h.9.mlp.c_proj.weight', 'transformer_description.ln_f.bias', 'transformer_description.ln_f.weight', 'transformer_description.wpe.weight', 'transformer_description.wte.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data feed :::  dict_keys(['title', 'description', 'label'])\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-55aa6fcdda15>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "using pretrained gpt-2 tokenizer\n",
            "using pretrained gpt-2 tokenizer\n",
            "BATCH_SIZE :  100\n",
            "BATCH_SIZE :  100\n",
            "using pretrained gpt-2 tokenizer\n",
            "using pretrained gpt-2 tokenizer\n",
            "BATCH_SIZE :  100\n",
            "Start training for  {'train': ['mesos'], 'test': ['mesos']} .....\n",
            ">>> epoch  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Average training MAE loss: 64.03\n",
            "-\n",
            " Average eval MAE loss: 17.77\n",
            "===============================\n",
            "MAE:  16.045145\n",
            "MdAE:  16.186935\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 8.93\n",
            "-\n",
            " Average eval MAE loss: 2.37\n",
            "===============================\n",
            "MAE:  2.634709\n",
            "MdAE:  2.6862524\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 3.27\n",
            "-\n",
            " Average eval MAE loss: 1.35\n",
            "===============================\n",
            "MAE:  1.2211775\n",
            "MdAE:  0.8306389\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 2.58\n",
            "-\n",
            " Average eval MAE loss: 2.76\n",
            "===============================\n",
            "MAE:  2.5130439\n",
            "MdAE:  1.9953842\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 1.84\n",
            "-\n",
            " Average eval MAE loss: 1.66\n",
            "===============================\n",
            "MAE:  1.6801354\n",
            "MdAE:  1.4256918\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 1.89\n",
            "-\n",
            " Average eval MAE loss: 1.56\n",
            "===============================\n",
            "MAE:  1.3462827\n",
            "MdAE:  1.2128196\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 2.37\n",
            "-\n",
            " Average eval MAE loss: 2.35\n",
            "===============================\n",
            "MAE:  2.1457179\n",
            "MdAE:  2.112069\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 1.85\n",
            "-\n",
            " Average eval MAE loss: 2.66\n",
            "===============================\n",
            "MAE:  2.29335\n",
            "MdAE:  2.268663\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 2.18\n",
            "-\n",
            " Average eval MAE loss: 1.42\n",
            "===============================\n",
            "MAE:  1.2959521\n",
            "MdAE:  1.0614386\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 1.70\n",
            "-\n",
            " Average eval MAE loss: 1.57\n",
            "===============================\n",
            "MAE:  1.6504385\n",
            "MdAE:  1.257446\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 1.52\n",
            "-\n",
            " Average eval MAE loss: 1.50\n",
            "===============================\n",
            "MAE:  1.3017796\n",
            "MdAE:  1.0036147\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 1.43\n",
            "-\n",
            " Average eval MAE loss: 1.47\n",
            "===============================\n",
            "MAE:  1.4147782\n",
            "MdAE:  1.0214112\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 1.22\n",
            "-\n",
            " Average eval MAE loss: 1.59\n",
            "===============================\n",
            "MAE:  1.3358546\n",
            "MdAE:  1.1211915\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 1.09\n",
            "-\n",
            " Average eval MAE loss: 1.43\n",
            "===============================\n",
            "MAE:  1.3369405\n",
            "MdAE:  0.9243532\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 1.09\n",
            "-\n",
            " Average eval MAE loss: 1.47\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "[enforce fail at inline_container.cc:595] . unexpected pos 492340288 vs 492340176",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:764] . PytorchStreamWriter failed writing file data/170: file write failed",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-27c6adfc83f6>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-27c6adfc83f6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mfile_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_test_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mtrain_eval_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_test_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-55aa6fcdda15>\u001b[0m in \u001b[0;36mtrain_eval_test\u001b[0;34m(file_pair, train_dataloader, val_dataloader, all_test_dataloader, model, test_file_names)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mavg_eval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_eval_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m# save model state to dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./models/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'epo_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===============================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:595] . unexpected pos 492340288 vs 492340176"
          ]
        }
      ],
      "source": [
        "global WITHIN_PROJECT\n",
        "WITHIN_PROJECT = True\n",
        "\n",
        "TRAIN_TEST_FILE_PAIRS = [\n",
        "                        # {'train': ['appceleratorstudio'], 'test': ['appceleratorstudio']},\n",
        "                        # {'train': ['aptanastudio'], 'test': ['aptanastudio']},\n",
        "                        # {'train': ['bamboo'], 'test': ['bamboo']},\n",
        "                        # {'train': ['clover'], 'test': ['clover']},\n",
        "                        # {'train': ['datamanagement'], 'test': ['datamanagement']},\n",
        "                        {'train': ['duracloud'], 'test': ['duracloud']},\n",
        "                        {'train': ['jirasoftware'], 'test': ['jirasoftware']},\n",
        "                        {'train': ['mesos'], 'test': ['mesos']},\n",
        "                        {'train': ['moodle'], 'test': ['moodle']},\n",
        "                        {'train': ['mule'], 'test': ['mule']},\n",
        "                        {'train': ['mulestudio'], 'test': ['mulestudio']},\n",
        "                        # {'train': ['springxd'], 'test': ['springxd']},\n",
        "                        # {'train': ['talenddataquality'], 'test': ['talenddataquality']},\n",
        "                        # {'train': ['talendesb'], 'test': ['talendesb']},\n",
        "                        # {'train': ['titanium'], 'test': ['titanium']},\n",
        "                        # {'train': ['usergrid'], 'test': ['usergrid']},\n",
        "                        ]\n",
        "\n",
        "\n",
        "def main():\n",
        "    global TRAIN_TEST_FILE_PAIRS, MODEL, TOKENIZER, MODEL_NAME\n",
        "    for file in TRAIN_TEST_FILE_PAIRS:\n",
        "        if TOKENIZER == 'bbpe':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=50257)\n",
        "        elif TOKENIZER == 'gpt2':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=50256)\n",
        "        elif TOKENIZER == 'wordpiece':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
        "        elif TOKENIZER == 'sentencepiece':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
        "        elif TOKENIZER == 'wordlevel':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=3)\n",
        "        if MODEL_NAME == 'gpt2':\n",
        "            MODEL = LinearGPT2.from_pretrained('gpt2', config=config)\n",
        "            if torch.cuda.is_available() :\n",
        "              MODEL.cuda()\n",
        "        elif MODEL_NAME == 'gpt2sp':\n",
        "            MODEL = GPT2SP.from_pretrained('gpt2', config=config)\n",
        "            if torch.cuda.is_available():\n",
        "              MODEL.cuda()\n",
        "        elif MODEL_NAME == 'gpt2spen':\n",
        "            MODEL = GPT2SPEN.from_pretrained('gpt2', config=config)\n",
        "            if torch.cuda.is_available():\n",
        "              MODEL.cuda()\n",
        "\n",
        "\n",
        "\n",
        "        file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names = data_processing(file_pair=file)\n",
        "        train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, MODEL, test_file_names)\n",
        "        del MODEL\n",
        "        torch.cuda.empty_cache()\n",
        "        global OUTPUT\n",
        "        with open('./results/' + str(file['train'][0]) + '_' + str(file['test'][0]) +'.txt', 'w+') as f:\n",
        "            f.writelines(OUTPUT)\n",
        "            print('results have been written into a text file!')\n",
        "            OUTPUT = \"\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdb off"
      ],
      "metadata": {
        "id": "NV0eL_3rAEbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSte0lR_hfbo"
      },
      "source": [
        "### Cross Project Training Script - Within Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij9vp2J2hfbo"
      },
      "outputs": [],
      "source": [
        "global WITHIN_PROJECT\n",
        "WITHIN_PROJECT = False\n",
        "\n",
        "# within repo\n",
        "TRAIN_TEST_FILE_PAIRS = [\n",
        "                        {'train': ['mesos'], 'test': ['usergrid']},\n",
        "                        {'train': ['usergrid'], 'test': ['mesos']},\n",
        "                        {'train': ['appceleratorstudio'], 'test': ['aptanastudio']},\n",
        "                        {'train': ['appceleratorstudio'], 'test': ['titanium']},\n",
        "                        {'train': ['titanium'], 'test': ['appceleratorstudio']},\n",
        "                        {'train': ['aptanastudio'], 'test': ['titanium']},\n",
        "                        {'train': ['mule'], 'test': ['mulestudio']},\n",
        "                        {'train': ['mulestudio'], 'test': ['mule']}\n",
        "                        ]\n",
        "\n",
        "\n",
        "def main():\n",
        "    global TRAIN_TEST_FILE_PAIRS, MODEL, TOKENIZER, MODEL_NAME\n",
        "    for file in TRAIN_TEST_FILE_PAIRS:\n",
        "        if TOKENIZER == 'bbpe':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=50257)\n",
        "        elif TOKENIZER == 'gpt2':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=50256)\n",
        "        elif TOKENIZER == 'wordpiece':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
        "        elif TOKENIZER == 'sentencepiece':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
        "        elif TOKENIZER == 'wordlevel':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=3)\n",
        "        if MODEL_NAME == 'gpt2':\n",
        "            MODEL = LinearGPT2.from_pretrained('gpt2', config=config)\n",
        "            MODEL.cuda()\n",
        "        elif MODEL_NAME == 'gpt2sp':\n",
        "            MODEL = GPT2SP.from_pretrained('gpt2', config=config)\n",
        "            MODEL.cuda()\n",
        "        file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names = data_processing(file_pair=file)\n",
        "        train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, MODEL, test_file_names)\n",
        "        del MODEL\n",
        "        torch.cuda.empty_cache()\n",
        "        global OUTPUT\n",
        "        with open('./results/' + str(file['train'][0]) + '_' + str(file['test'][0]) +'.txt', 'w+') as f:\n",
        "            f.writelines(OUTPUT)\n",
        "            print('results have been written into a text file!')\n",
        "            OUTPUT = \"\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMcxbMB7hfbp"
      },
      "source": [
        "### Cross Project Training Script - Cross Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35iJqeeNhfbp"
      },
      "outputs": [],
      "source": [
        "global WITHIN_PROJECT\n",
        "WITHIN_PROJECT = False\n",
        "\n",
        "# cross repo\n",
        "TRAIN_TEST_FILE_PAIRS = [\n",
        "                        {'train': ['clover'], 'test': ['usergrid']},\n",
        "                        {'train': ['talendesb'], 'test': ['mesos']},\n",
        "                        {'train': ['talenddataquality'], 'test': ['aptanastudio']},\n",
        "                        {'train': ['mule'], 'test': ['titanium']},\n",
        "                        {'train': ['talenddataquality'], 'test': ['appceleratorstudio']},\n",
        "                        {'train': ['mulestudio'], 'test': ['titanium']},\n",
        "                        {'train': ['appceleratorstudio'], 'test': ['mulestudio']},\n",
        "                        {'train': ['appceleratorstudio'], 'test': ['mule']}\n",
        "                        ]\n",
        "\n",
        "\n",
        "def main():\n",
        "    global TRAIN_TEST_FILE_PAIRS, MODEL, TOKENIZER, MODEL_NAME\n",
        "    for file in TRAIN_TEST_FILE_PAIRS:\n",
        "        if TOKENIZER == 'gpt2':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=50256)\n",
        "        elif TOKENIZER == 'wordpiece':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
        "        elif TOKENIZER == 'sentencepiece':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
        "        elif TOKENIZER == 'wordlevel':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=3)\n",
        "        if MODEL_NAME == 'gpt2':\n",
        "            MODEL = LinearGPT2.from_pretrained('gpt2', config=config)\n",
        "            MODEL.cuda()\n",
        "        elif MODEL_NAME == 'gpt2sp':\n",
        "            MODEL = GPT2SP.from_pretrained('gpt2', config=config)\n",
        "            MODEL.cuda()\n",
        "        file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names = data_processing(file_pair=file)\n",
        "        train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, MODEL, test_file_names)\n",
        "        del MODEL\n",
        "        torch.cuda.empty_cache()\n",
        "        global OUTPUT\n",
        "        with open('./results/' + str(file['train'][0]) + '_' + str(file['test'][0]) +'.txt', 'w+') as f:\n",
        "            f.writelines(OUTPUT)\n",
        "            print('results have been written into a text file!')\n",
        "            OUTPUT = \"\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "conda-root-py",
      "name": "workbench-notebooks.m117",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m117"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel) (Local)",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "95502c86ed2e8b82df6e58f8450b4387aca3c902602792f25ea2aa6818e861bc"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4ffffaf36024348bdaa6249f25ebc2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0a97e9cadd248b690d9ab5543bba68c",
              "IPY_MODEL_b3c8511daa5b4468a01c17ee7edabe42",
              "IPY_MODEL_d046d93760924c15b2d2255679453eae"
            ],
            "layout": "IPY_MODEL_6dcff16d2a2b44ed8158e080f93a6aff"
          }
        },
        "c0a97e9cadd248b690d9ab5543bba68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3bf5fd2a4414c9f9b4bb405ac6dd74f",
            "placeholder": "",
            "style": "IPY_MODEL_6ff6bcacd22b441c8acf22981e0af00a",
            "value": "model.safetensors:100%"
          }
        },
        "b3c8511daa5b4468a01c17ee7edabe42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac0ba7793639442b8b2831f85a9dda95",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45c75277604e4e6abe159524ac3751b5",
            "value": 548105171
          }
        },
        "d046d93760924c15b2d2255679453eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c26923bf2a8243e491c0ca5c03bd5b87",
            "placeholder": "",
            "style": "IPY_MODEL_1274b971fa5748b9b7c849bbcc9b7e5d",
            "value": "548M/548M[00:06&lt;00:00,98.7MB/s]"
          }
        },
        "6dcff16d2a2b44ed8158e080f93a6aff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3bf5fd2a4414c9f9b4bb405ac6dd74f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff6bcacd22b441c8acf22981e0af00a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac0ba7793639442b8b2831f85a9dda95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c75277604e4e6abe159524ac3751b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c26923bf2a8243e491c0ca5c03bd5b87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1274b971fa5748b9b7c849bbcc9b7e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b4d06ecb81e460aaa329c654224f42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_817a0b00ee6f4f44b215ac553bb45974",
              "IPY_MODEL_01bce2f5e54e4beaae521e51f0a0b655",
              "IPY_MODEL_4c710b472c67480da4952a4ee2c15e33"
            ],
            "layout": "IPY_MODEL_f8bfbc71b3604bcf9a230b0f006bc21e"
          }
        },
        "817a0b00ee6f4f44b215ac553bb45974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cd4ab3fc488409aba11978457338148",
            "placeholder": "",
            "style": "IPY_MODEL_57c66773182a4e089079a9cd71961fab",
            "value": "tokenizer_config.json:100%"
          }
        },
        "01bce2f5e54e4beaae521e51f0a0b655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed246449def2450f8a3e2595d6c64fb3",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a42df29cefd4d83a95389cb2d94d37e",
            "value": 26
          }
        },
        "4c710b472c67480da4952a4ee2c15e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0050d6e82f041f98063f89edee0900e",
            "placeholder": "",
            "style": "IPY_MODEL_643cbf4768fe424ba717b86c4a779365",
            "value": "26.0/26.0[00:00&lt;00:00,1.02kB/s]"
          }
        },
        "f8bfbc71b3604bcf9a230b0f006bc21e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd4ab3fc488409aba11978457338148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57c66773182a4e089079a9cd71961fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed246449def2450f8a3e2595d6c64fb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a42df29cefd4d83a95389cb2d94d37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0050d6e82f041f98063f89edee0900e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "643cbf4768fe424ba717b86c4a779365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86d9324ba51a4baf875698254f8a5e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcec0bbe0dfd4eac90c6cd0b28f4689b",
              "IPY_MODEL_49e88bfdc1f3461aa5e8b1e8ad9e266f",
              "IPY_MODEL_e5a01c6ec3c741a3a48e30f63a75d607"
            ],
            "layout": "IPY_MODEL_1c0a38953d064d56a09d9cb150306187"
          }
        },
        "dcec0bbe0dfd4eac90c6cd0b28f4689b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a555f8569e4142b8c530f152597397",
            "placeholder": "",
            "style": "IPY_MODEL_ea204766ccfc454ba0dc8084066ff377",
            "value": "vocab.json:100%"
          }
        },
        "49e88bfdc1f3461aa5e8b1e8ad9e266f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3405f57f417b4781b3cef8bb17ba0243",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_279d5204c8a542748d70d38082a1aeaf",
            "value": 1042301
          }
        },
        "e5a01c6ec3c741a3a48e30f63a75d607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c47b4f0b4f8d41aeabb739b7f95b43d3",
            "placeholder": "",
            "style": "IPY_MODEL_21e5bc2fba2a43eda7e4b17ff328fbe3",
            "value": "1.04M/1.04M[00:00&lt;00:00,8.89MB/s]"
          }
        },
        "1c0a38953d064d56a09d9cb150306187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a555f8569e4142b8c530f152597397": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea204766ccfc454ba0dc8084066ff377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3405f57f417b4781b3cef8bb17ba0243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "279d5204c8a542748d70d38082a1aeaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c47b4f0b4f8d41aeabb739b7f95b43d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21e5bc2fba2a43eda7e4b17ff328fbe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d44459a090994330ab09216a07e24dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_672256d9aaee41268844e0484b9abe36",
              "IPY_MODEL_51b0d1c682a54dabb6f74137276420f1",
              "IPY_MODEL_e2ce808ce8f94337bae09db0de40ae88"
            ],
            "layout": "IPY_MODEL_8c6ee65dbd7c4c83a3548972ab449beb"
          }
        },
        "672256d9aaee41268844e0484b9abe36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6606cc47ab845cdb972525df2895269",
            "placeholder": "",
            "style": "IPY_MODEL_30cd635f27f34212a2662e75414decca",
            "value": "merges.txt:100%"
          }
        },
        "51b0d1c682a54dabb6f74137276420f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f813b55fcbbc4c3894b64ac5b3520ee2",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39236b1b25ec48fc9a406dfb26831448",
            "value": 456318
          }
        },
        "e2ce808ce8f94337bae09db0de40ae88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb570f7319cf46a79cf0f3309b3bd8ae",
            "placeholder": "",
            "style": "IPY_MODEL_69e22f3a46e54fd4901790805bd3f901",
            "value": "456k/456k[00:00&lt;00:00,16.1MB/s]"
          }
        },
        "8c6ee65dbd7c4c83a3548972ab449beb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6606cc47ab845cdb972525df2895269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30cd635f27f34212a2662e75414decca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f813b55fcbbc4c3894b64ac5b3520ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39236b1b25ec48fc9a406dfb26831448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb570f7319cf46a79cf0f3309b3bd8ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69e22f3a46e54fd4901790805bd3f901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c65660de51e54844aba5e351f4cca351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b444dd97f5134b20bbffedcb1924afa2",
              "IPY_MODEL_53a66a8d49ed40f1a644560f4e60d832",
              "IPY_MODEL_4da0a6100d1347c0984cdf0f38dac085"
            ],
            "layout": "IPY_MODEL_59761fcd467e4ceba81f159437f87041"
          }
        },
        "b444dd97f5134b20bbffedcb1924afa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b15ddd79917b409da989761389840aef",
            "placeholder": "",
            "style": "IPY_MODEL_6734704bea6b45288f966e53c5a10f02",
            "value": "tokenizer.json:100%"
          }
        },
        "53a66a8d49ed40f1a644560f4e60d832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0ace0b243af420187bbb21fcbcdb82b",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60db5bb4041f4e899408426eda5e5252",
            "value": 1355256
          }
        },
        "4da0a6100d1347c0984cdf0f38dac085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dc731d72e9a4dfca01f10efc188b956",
            "placeholder": "",
            "style": "IPY_MODEL_afa5b38b5ab64623bde56048a376922d",
            "value": "1.36M/1.36M[00:00&lt;00:00,13.1MB/s]"
          }
        },
        "59761fcd467e4ceba81f159437f87041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b15ddd79917b409da989761389840aef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6734704bea6b45288f966e53c5a10f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0ace0b243af420187bbb21fcbcdb82b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60db5bb4041f4e899408426eda5e5252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dc731d72e9a4dfca01f10efc188b956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afa5b38b5ab64623bde56048a376922d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7c05a3a34f34c718834bbbac1f3744a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de083215c76c4e71b8214bc3c573b4e4",
              "IPY_MODEL_ba597e2a8ef546b8a920eece50eab4b4",
              "IPY_MODEL_9e7f546dc88d4f23b6d0c7cadc98a2bb"
            ],
            "layout": "IPY_MODEL_194e9f2fc71e4e85b887d7d088955c89"
          }
        },
        "de083215c76c4e71b8214bc3c573b4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3342d2b5e79d48f1839dea1c3099c84c",
            "placeholder": "",
            "style": "IPY_MODEL_df818aaed0784ce28316acc4fdb2adbe",
            "value": "config.json:100%"
          }
        },
        "ba597e2a8ef546b8a920eece50eab4b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e252cde50dfb49e6a5e4d2cd54f08bb0",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43002142a6fb4522a2110bc6cc5e1d3c",
            "value": 665
          }
        },
        "9e7f546dc88d4f23b6d0c7cadc98a2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83dca60325f3457abf21e55cb813ec6f",
            "placeholder": "",
            "style": "IPY_MODEL_e7a3b6c564db4b21b5fce0b22af9e494",
            "value": "665/665[00:00&lt;00:00,46.8kB/s]"
          }
        },
        "194e9f2fc71e4e85b887d7d088955c89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3342d2b5e79d48f1839dea1c3099c84c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df818aaed0784ce28316acc4fdb2adbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e252cde50dfb49e6a5e4d2cd54f08bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43002142a6fb4522a2110bc6cc5e1d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83dca60325f3457abf21e55cb813ec6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a3b6c564db4b21b5fce0b22af9e494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}