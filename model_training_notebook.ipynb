{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sansith/gpt2sp/blob/bertsp/model_training_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyLoXxhlhfbk",
        "tags": []
      },
      "source": [
        "# Model Training Script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ren7VyEyhfbl",
        "tags": []
      },
      "source": [
        "### Necessary Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMyN0hhThfbl",
        "outputId": "f58d3ea1-ed98-48b9-d657-35d54091be98",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: pandas===1.5.3 in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Collecting koila\n",
            "  Downloading koila-0.1.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas===1.5.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas===1.5.3) (2023.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m982.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Collecting pynvml (from koila)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from koila) (13.7.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.43.0-py2.py3-none-any.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->koila) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->koila) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->koila) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, pynvml, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, docker-pycreds, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gitdb, nvidia-cusolver-cu12, GitPython, wandb, koila\n",
            "Successfully installed GitPython-3.1.42 docker-pycreds-0.4.0 gitdb-4.0.11 koila-0.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pynvml-11.5.0 sentry-sdk-1.43.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.4\n"
          ]
        }
      ],
      "source": [
        "pip install torch pandas===1.5.3 transformers numpy tokenizers koila tensorboard wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbfZ-HQu4S9U",
        "outputId": "a9edfd39-3a5e-480f-e659-3ceee7dbc246",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jupyter/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login 392e817af43c45fef2953b58c84ebb95d7dd31b5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIh96xVTiuIa",
        "outputId": "8165e267-5df5-4978-c0d0-41b8dc7463d4",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9x76OTPXIsz",
        "outputId": "261f6a7d-2474-4da4-9220-ff9191ffe2d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/gpt2sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3R16ZxuirGo",
        "outputId": "c28c1133-0223-4e63-fd36-876ede847983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/Year4/FYP/effort-estimation/gpt2sp'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/Year4/FYP/effort-estimation/gpt2sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bhcSAPbLhfbm",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup , BertTokenizer\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# from GPT2SP import GPT2ForSequenceClassification as GPT2SP\n",
        "from transformers import GPT2ForSequenceClassification as LinearGPT2\n",
        "from transformers import GPT2Config , BertConfig\n",
        "import os\n",
        "from tokenizers import Tokenizer\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vQnebv9YPJxH"
      },
      "outputs": [],
      "source": [
        "from transformers.modeling_outputs import SequenceClassifierOutputWithPast\n",
        "import torch.nn as nn\n",
        "from transformers import GPT2Model, GPT2PreTrainedModel\n",
        "import torch\n",
        "\n",
        "\n",
        "class GPT2SP(GPT2PreTrainedModel):\n",
        "    _keys_to_ignore_on_load_missing = [r\"h\\.\\d+\\.attn\\.masked_bias\", r\"lm_head\\.weight\"]\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.transformer = GPT2Model(config)\n",
        "        self.dense1 = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)\n",
        "        self.dense2 = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)\n",
        "        self.score = nn.Linear(config.n_embd, self.num_labels, bias=False)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        # Model parallel\n",
        "        self.model_parallel = False\n",
        "        self.device_map = None\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        past_key_values=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        use_cache=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
        "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
        "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        transformer_outputs = self.transformer(\n",
        "            input_ids,\n",
        "            past_key_values=past_key_values,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        hidden_states = transformer_outputs[0]\n",
        "\n",
        "        # MLP Layer\n",
        "        hidden_states = self.dense1(hidden_states)\n",
        "        hidden_states = self.dense2(hidden_states)\n",
        "\n",
        "        logits = self.score(hidden_states)\n",
        "\n",
        "        if input_ids is not None:\n",
        "            batch_size, sequence_length = input_ids.shape[:2]\n",
        "        else:\n",
        "            batch_size, sequence_length = inputs_embeds.shape[:2]\n",
        "\n",
        "        assert (\n",
        "            self.config.pad_token_id is not None or batch_size == 1\n",
        "        ), \"Cannot handle batch sizes > 1 if no padding token is defined.\"\n",
        "        if self.config.pad_token_id is None:\n",
        "            sequence_lengths = -1\n",
        "        else:\n",
        "            if input_ids is not None:\n",
        "                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1\n",
        "            else:\n",
        "                sequence_lengths = -1\n",
        "                logger.warning(\n",
        "                    f\"{self.__class__.__name__} will not detect padding tokens in `inputs_embeds`. Results may be \"\n",
        "                    f\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"\n",
        "                )\n",
        "\n",
        "        pooled_logits = logits[range(batch_size), sequence_lengths]\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = nn.L1Loss()\n",
        "                loss = loss_fct(pooled_logits.view(-1), labels.to(self.dtype).view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(pooled_logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (pooled_logits,) + transformer_outputs[1:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutputWithPast(\n",
        "            loss=loss,\n",
        "            logits=pooled_logits,\n",
        "            past_key_values=transformer_outputs.past_key_values,\n",
        "            hidden_states=transformer_outputs.hidden_states,\n",
        "            attentions=transformer_outputs.attentions,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cf6cpSnmvZcA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers.modeling_outputs import SequenceClassifierOutputWithPast\n",
        "import torch.nn as nn\n",
        "from transformers import  BertPreTrainedModel , BertModel\n",
        "import torch\n",
        "\n",
        "\n",
        "class BertSP(BertPreTrainedModel):\n",
        "    _keys_to_ignore_on_load_missing = [r\"h\\.\\d+\\.attn\\.masked_bias\", r\"lm_head\\.weight\"]\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.transformer = BertModel(config)\n",
        "        print(\"n_embd/hidden_size : \", config.hidden_size)\n",
        "        self.dense1 = nn.Linear(config.hidden_size, 4 * config.hidden_size, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dense2 = nn.Linear(4 * config.hidden_size, config.hidden_size, bias=False)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.score = nn.Linear(config.hidden_size, self.num_labels, bias=False)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        # Model parallel\n",
        "        self.model_parallel = False\n",
        "        self.device_map = None\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        past_key_values=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        use_cache=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
        "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
        "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        transformer_outputs = self.transformer(\n",
        "            input_ids,\n",
        "            past_key_values=past_key_values,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        hidden_states = transformer_outputs[0]\n",
        "\n",
        "        # MLP Layer\n",
        "        hidden_states = self.dense1(hidden_states)\n",
        "        hidden_states = self.relu1(hidden_states)\n",
        "\n",
        "        hidden_states = self.dense2(hidden_states)\n",
        "        hidden_states = self.relu2(hidden_states)\n",
        "        logits = self.score(hidden_states)\n",
        "\n",
        "        if input_ids is not None:\n",
        "            batch_size, sequence_length = input_ids.shape[:2]\n",
        "        else:\n",
        "            batch_size, sequence_length = inputs_embeds.shape[:2]\n",
        "\n",
        "        assert (\n",
        "            self.config.pad_token_id is not None or batch_size == 1\n",
        "        ), \"Cannot handle batch sizes > 1 if no padding token is defined.\"\n",
        "        if self.config.pad_token_id is None:\n",
        "            sequence_lengths = -1\n",
        "        else:\n",
        "            if input_ids is not None:\n",
        "                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1\n",
        "            else:\n",
        "                sequence_lengths = -1\n",
        "                logger.warning(\n",
        "                    f\"{self.__class__.__name__} will not detect padding tokens in `inputs_embeds`. Results may be \"\n",
        "                    f\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"\n",
        "                )\n",
        "\n",
        "        pooled_logits = logits[range(batch_size), sequence_lengths]\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = nn.L1Loss()\n",
        "                loss = loss_fct(pooled_logits.view(-1), labels.to(self.dtype).view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(pooled_logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (pooled_logits,) + transformer_outputs[1:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutputWithPast(\n",
        "            loss=loss,\n",
        "            logits=pooled_logits,\n",
        "            past_key_values=transformer_outputs.past_key_values,\n",
        "            hidden_states=transformer_outputs.hidden_states,\n",
        "            attentions=transformer_outputs.attentions,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbQNj41Ghfbn"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ch24eOM0hfbn",
        "tags": [
          "CONFIGS",
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "global EPOCHS, BATCH_SIZE_RATIO, SEQUENCE_LEN, LEARNING_RATE, TOKENIZER, MODEL_NAME , ADD_DESCRIPTION\n",
        "\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE_RATIO = 0.02 # within proj: 0.3 / cross proj: 0.4\n",
        "SEQUENCE_LEN = 100\n",
        "LEARNING_RATE = 5e-4\n",
        "TOKENIZER = 'gpt2' # available:bert, gpt2, wordlevel, sentencepiece, wordpiece\n",
        "MODEL_NAME = 'gpt2sp' # available: bert, gpt2sp, gpt2\n",
        "ADD_DESCRIPTION = True\n",
        "WANDB_SPECIAL_TAGS = ['with relu','description+title'] #'with relu'\n",
        "# define device\n",
        "global DEVICE\n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# define files to be used\n",
        "global DATA_PATH\n",
        "DATA_PATH = './sp_dataset/marked_data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH1j_lvmhfbn",
        "tags": []
      },
      "source": [
        "### Static Methods and Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "W1FZRuJ7hfbn",
        "tags": []
      },
      "outputs": [],
      "source": [
        "OUTPUT = '  '\n",
        "MODEL = None\n",
        "DYNAMIC_BATCH = True\n",
        "BATCH_SIZE = None\n",
        "WITHIN_PROJECT = None\n",
        "MAE_RECORDS = []\n",
        "MDAE_RECORDS = []\n",
        "\n",
        "def data_processing(file_pair):\n",
        "    global BATCH_SIZE, BATCH_SIZE_RATIO, DATA_PATH, WITHIN_PROJECT, DYNAMIC_BATCH\n",
        "\n",
        "    train_data = pd.DataFrame(columns=['text', 'label'])\n",
        "    for train_file_name in file_pair['train']:\n",
        "        fname = DATA_PATH + train_file_name + '.csv'\n",
        "        df = prepare_dataframe(fname)\n",
        "        train_data = train_data.append(df)\n",
        "\n",
        "    # data split\n",
        "    if WITHIN_PROJECT:\n",
        "        train_text, train_labels, val_text, val_labels, test_text, test_labels = within_project_split(train_data)\n",
        "    else:\n",
        "        train_text, train_labels, val_text, val_labels = train_val_split(train_data, 0.6)\n",
        "    # define batch size dynamically based on training length\n",
        "    if DYNAMIC_BATCH:\n",
        "        BATCH_SIZE = int(len(train_text) * BATCH_SIZE_RATIO)\n",
        "    # tokenization\n",
        "    tokens_train = tokenization(train_text.tolist())\n",
        "    tokens_val = tokenization(val_text.tolist())\n",
        "    print(tokens_train['input_ids'][:5])\n",
        "\n",
        "    train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "    train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "    train_y = torch.tensor(train_labels.tolist()).type(torch.LongTensor)\n",
        "    train_dataloader = prepare_dataloader(train_seq, train_y, sampler_type='random',attention_mask=train_att_mask)\n",
        "\n",
        "    val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "    val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "    val_y = torch.tensor(val_labels.tolist()).type(torch.LongTensor)\n",
        "    val_dataloader = prepare_dataloader(val_seq, val_y, sampler_type='sequential',attention_mask=val_att_mask)\n",
        "\n",
        "    # prepare testing datasets\n",
        "    all_test_dataloader = []\n",
        "    test_file_names = []\n",
        "    if WITHIN_PROJECT:\n",
        "        tokens_test = tokenization(test_text.tolist())\n",
        "        test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "        test_att_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "        test_y = torch.tensor(test_labels.tolist()).type(torch.LongTensor)\n",
        "        test_dataloader = prepare_dataloader(test_seq, test_y, sampler_type='sequential',attention_mask=test_att_mask)\n",
        "        all_test_dataloader.append(test_dataloader)\n",
        "        test_file_names.append(file_pair['test'][0])\n",
        "        return file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names\n",
        "\n",
        "    for test_file_name in file_pair['test']:\n",
        "        fname = DATA_PATH + test_file_name + '.csv'\n",
        "        test_data = prepare_dataframe(fname)\n",
        "\n",
        "        test_text = test_data['text']\n",
        "        test_labels = test_data['label']\n",
        "\n",
        "        # tokenization\n",
        "        tokens_test = tokenization(test_text.tolist())\n",
        "        test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "        test_att_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "        test_y = torch.tensor(test_labels.tolist()).type(torch.LongTensor)\n",
        "        test_dataloader = prepare_dataloader(test_seq, test_y, sampler_type='sequential',attention_mask=test_att_mask)\n",
        "\n",
        "        all_test_dataloader.append(test_dataloader)\n",
        "        test_file_names.append(test_file_name)\n",
        "    print('cross project data processing!')\n",
        "    return file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names\n",
        "\n",
        "\n",
        "def train_val_split(data, split_ratio):\n",
        "    print('cross project split!')\n",
        "    split_point = int(len(data) * split_ratio)\n",
        "    train_text = data['text'][:split_point]\n",
        "    train_labels = data['label'][:split_point]\n",
        "    val_text = data['text'][split_point:]\n",
        "    val_labels = data['label'][split_point:]\n",
        "    return train_text, train_labels, val_text, val_labels\n",
        "\n",
        "\n",
        "def tokenization(text_list):\n",
        "    global TOKENIZER, SEQUENCE_LEN, MODEL\n",
        "    # tokenization\n",
        "    if TOKENIZER == 'wordpiece':\n",
        "        print('using wordpiece tokenizer!')\n",
        "        tokenizer = BertTokenizer('all_tokenizers/word_piece/vocab.txt')\n",
        "    elif TOKENIZER == 'sentencepiece':\n",
        "        print('using sentencepiece tokenizer!')\n",
        "        tokenizer = XLNetTokenizer('all_tokenizers/sentence_piece/spm_tokenizer.model', padding_side='right')\n",
        "    elif TOKENIZER == 'wordlevel':\n",
        "        print('using wordlevel tokenizer!')\n",
        "        tokenizer = Tokenizer.from_file('all_tokenizers/word_level/wordlevel.json')\n",
        "        encoded_sentences = {'input_ids':[]}\n",
        "        for sentence in text_list:\n",
        "            encoded = tokenizer.encode(sentence)\n",
        "            encoded = encoded.ids\n",
        "            if len(encoded) > SEQUENCE_LEN:\n",
        "                encoded = encoded[:SEQUENCE_LEN]\n",
        "            elif len(encoded) < SEQUENCE_LEN:\n",
        "                padding = SEQUENCE_LEN - len(encoded)\n",
        "                for _ in range(padding):\n",
        "                    encoded.append(3)\n",
        "            encoded_sentences['input_ids'].append(encoded)\n",
        "        return encoded_sentences\n",
        "    elif TOKENIZER == 'gpt2':\n",
        "        print('using pretrained gpt-2 tokenizer')\n",
        "        tokenizer = GPT2Tokenizer.from_pretrained(TOKENIZER)\n",
        "        tokenizer.pad_token = '[PAD]'\n",
        "\n",
        "    elif TOKENIZER == 'bert':\n",
        "        print('usingbert tokenizer')\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        # tokenizer.pad_token = '[PAD]'\n",
        "    return tokenizer.batch_encode_plus(text_list, truncation=True, max_length=SEQUENCE_LEN, padding='max_length', return_tensors='pt')\n",
        "\n",
        "\n",
        "def prepare_dataframe(file_name):\n",
        "    data = pd.read_csv(file_name)\n",
        "    # some rows have no description, fill blank to avoid Null\n",
        "    data = data.fillna(' ')\n",
        "\n",
        "\n",
        "    if ADD_DESCRIPTION :\n",
        "      print(\"### text : title+description\")\n",
        "      d = {'text':('[CLS]' + data['title'] + '[SEP]' + data[\"description\"]+'[SEP]').tolist(), 'label': data['storypoint']}\n",
        "    else:\n",
        "      print(\"### text : title\")\n",
        "      d = {'text': (data['title']).tolist(), 'label': data['storypoint']}\n",
        "    print(\"Input data feed ::: \",d['text'][0])\n",
        "    return pd.DataFrame(data=d)\n",
        "\n",
        "\n",
        "def prepare_dataloader(seq, y, sampler_type, attention_mask):\n",
        "    global BATCH_SIZE\n",
        "    tensor_dataset = TensorDataset(seq, y,attention_mask)\n",
        "    if sampler_type == 'random':\n",
        "        sampler = RandomSampler(tensor_dataset)\n",
        "    elif sampler_type == 'sequential':\n",
        "        sampler = SequentialSampler(tensor_dataset)\n",
        "    print(\"BATCH_SIZE : \",BATCH_SIZE)\n",
        "    dataloader = DataLoader(tensor_dataset, sampler=sampler, batch_size=BATCH_SIZE)\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def within_project_split(data):\n",
        "    print('within project split!')\n",
        "    train_val_split_point = int(len(data) * 0.6)\n",
        "    val_test_split_point = int(len(data) * 0.8)\n",
        "    train_text = data['text'][:train_val_split_point]\n",
        "    train_labels = data['label'][:train_val_split_point]\n",
        "    val_text = data['text'][train_val_split_point:val_test_split_point]\n",
        "    val_labels = data['label'][train_val_split_point:val_test_split_point]\n",
        "    test_text = data['text'][val_test_split_point:]\n",
        "    test_labels = data['label'][val_test_split_point:]\n",
        "    return train_text, train_labels, val_text, val_labels, test_text, test_labels\n",
        "\n",
        "\n",
        "def train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, model, test_file_names):\n",
        "    global LEARNING_RATE, EPOCHS, MAE_RECORDS, MDAE_RECORDS, DEVICE ,ADD_DESCRIPTION,WANDB_SPECIAL_TAGS\n",
        "\n",
        "        # start a new wandb run to track this script\n",
        "    wandb.init(\n",
        "            # set the wandb project where this run will be logged\n",
        "            project = \"esti-mate\",\n",
        "            name = f\"{MODEL_NAME}_{file_pair['train'][0]}\",\n",
        "            tags = WANDB_SPECIAL_TAGS,\n",
        "\n",
        "            # track hyperparameters and run metadata\n",
        "            config={\n",
        "            \"learning_rate\": LEARNING_RATE,\n",
        "            \"sequence_len\": SEQUENCE_LEN,\n",
        "            \"batch_size_ratio\":BATCH_SIZE_RATIO,\n",
        "            \"tokenizer\":TOKENIZER,\n",
        "            \"model_name\":MODEL_NAME,\n",
        "            \"description_added\":ADD_DESCRIPTION,\n",
        "            \"epochs\": EPOCHS,\n",
        "            'data_set':file_pair[\"train\"][0]\n",
        "            }\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Optimizerrr -->\n",
        "    optimizer = AdamW(MODEL.parameters(), lr=LEARNING_RATE)\n",
        "    # Total number of training steps is [number of batches] x [number of epochs]\n",
        "    total_steps = len(train_dataloader) * EPOCHS\n",
        "    # Create the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "    print(\"Start training for \", file_pair, \".....\")\n",
        "    training_start_time = time.time()\n",
        "\n",
        "    # tensorboard writer\n",
        "    writer_path = 'tb/' + str(file_pair['train'][0]) + '_' + str(file_pair['test'][0])\n",
        "    writer = SummaryWriter(writer_path)\n",
        "\n",
        "    # vars for model selection\n",
        "    min_eval_loss_epoch = [10000, 0]\n",
        "\n",
        "    time_records = []\n",
        "    MAE_RECORDS = []\n",
        "    MDAE_RECORDS = []\n",
        "    start_time = time.time()\n",
        "    loss_fct = nn.L1Loss()\n",
        "    for e in range(EPOCHS):\n",
        "        # ---TRAINING---\n",
        "        # clean GPU memory\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\">>> epoch \", e)\n",
        "        # set model into train mode\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # pdb.set_trace()\n",
        "            b_input_ids = batch[0].to(DEVICE)\n",
        "            b_labels = batch[1].to(DEVICE)\n",
        "            b_attention_mask = batch[2].to(DEVICE)\n",
        "            model.zero_grad()\n",
        "            result = model(b_input_ids,\n",
        "                           labels=b_labels,\n",
        "                           attention_mask=b_attention_mask,\n",
        "                           return_dict=True)\n",
        "            loss = result.loss\n",
        "            logits = result.logits\n",
        "            total_train_loss += loss.item()\n",
        "            # Calculates the gradients\n",
        "            loss.backward()\n",
        "            # The clip_grad_norm_ function clips (limits) the norm (magnitude) of the gradients to a maximum value specified by the user.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            #updates the weights and bias accrding to the calculated gradients\n",
        "            optimizer.step()\n",
        "            # update learning rates\n",
        "            scheduler.step()\n",
        "            # clean memory\n",
        "            del step, batch, b_input_ids, b_labels, result, loss, logits\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "        wandb.log({f\"train_loss\": avg_train_loss} , step=e )\n",
        "        print(\" Average training MAE loss: {0:.2f}\".format(avg_train_loss))\n",
        "        writer.add_scalar('loss/train', avg_train_loss, e)\n",
        "\n",
        "        # clean memory\n",
        "        del avg_train_loss, total_train_loss\n",
        "\n",
        "        time_records.append(time.time() - start_time)\n",
        "\n",
        "        # ---EVAL---\n",
        "        print(\"-\")\n",
        "        # set model into eval mode\n",
        "        model.eval()\n",
        "        total_eval_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dataloader:\n",
        "                b_input_ids = batch[0].to(DEVICE)\n",
        "                b_labels = batch[1].to(DEVICE)\n",
        "                b_attention_mask = batch[2].to(DEVICE)\n",
        "                model.zero_grad()\n",
        "                result = model(b_input_ids,\n",
        "                            labels=b_labels,\n",
        "                            attention_mask=b_attention_mask,\n",
        "                            return_dict=True)\n",
        "                loss = result.loss\n",
        "                logits = result.logits\n",
        "                total_eval_loss += loss.item()\n",
        "                # clean memory\n",
        "                del b_input_ids, b_labels, batch, result, loss, logits\n",
        "        avg_eval_loss = total_eval_loss / len(val_dataloader)\n",
        "        wandb.log({f\"eval_loss\": avg_eval_loss}, step=e)\n",
        "        print(\" Average eval MAE loss: {0:.2f}\".format(avg_eval_loss))\n",
        "\n",
        "        if avg_eval_loss <= min_eval_loss_epoch[0]:\n",
        "            min_eval_loss_epoch[0] = avg_eval_loss\n",
        "            min_eval_loss_epoch[1] = e\n",
        "\n",
        "        writer.add_scalar('loss/eval', avg_eval_loss, e)\n",
        "        # clean memory\n",
        "        del avg_eval_loss, total_eval_loss\n",
        "        # save model state to dict\n",
        "        torch.save(model.state_dict(), './models/' + 'epo_' + str(e))\n",
        "\n",
        "        print(\"===============================\")\n",
        "        \n",
        "        # testing on holdout data\n",
        "        index = 0\n",
        "        for test_dataloader in all_test_dataloader:\n",
        "            test_file_name = test_file_names[index]\n",
        "            index += 1\n",
        "            testing_start_time = time.time()\n",
        "            predictions = []\n",
        "            true_labels = []\n",
        "            for batch in test_dataloader:\n",
        "                batch = tuple(t.to(DEVICE) for t in batch)\n",
        "                b_input_ids, b_labels, attention_mask = batch\n",
        "                with torch.no_grad():\n",
        "                    logits = model(b_input_ids,attention_mask=attention_mask)\n",
        "                logits = logits['logits'].detach().cpu().numpy()\n",
        "                label_ids = b_labels.to('cpu').numpy()\n",
        "                predictions.append(logits)\n",
        "                true_labels.append(label_ids)\n",
        "            # calculate errors\n",
        "            distance_records = []\n",
        "            for i in range(len(predictions)):\n",
        "                for j in range(len(predictions[i])):\n",
        "                    distance = abs(predictions[i][j] - true_labels[i][j])\n",
        "                    distance_records.append(distance)\n",
        "\n",
        "            ## MAE = mean value of all absolute errors (stored in distance_records)\n",
        "            MAE = np.mean(np.array(distance_records))\n",
        "            ## MdAE = median value of all absolute errors (stored in distance_records)\n",
        "            MdAE = np.median(np.array(distance_records))\n",
        "\n",
        "            MAE_RECORDS.append(MAE)\n",
        "            MDAE_RECORDS.append(MdAE)\n",
        "\n",
        "            wandb.log({f\"test_MAE\": MAE, f\"MdAE\": MdAE},step=e)\n",
        "\n",
        "            global OUTPUT\n",
        "            OUTPUT +=  'Epochs ' + str(e) + '\\n'\n",
        "            OUTPUT += 'MAE: ' + str(MAE) + '\\n'\n",
        "            OUTPUT += 'MdAE: ' + str(MdAE) + '\\n\\n'\n",
        "            print('MAE: ', MAE)\n",
        "            print('MdAE: ', MdAE)\n",
        "    writer.flush()\n",
        "    writer.close()\n",
        "\n",
        "    # select model\n",
        "    os.rename('models/epo_' + str(min_eval_loss_epoch[1]),'models/' + str(file_pair['train'][0]) + '_'+ str(file_pair['test'][0]) + '_epo_' + str(min_eval_loss_epoch[1]))\n",
        "\n",
        "    # del unwanted models\n",
        "    for i in range(20):\n",
        "        try:\n",
        "            os.remove(\"models/epo_\" + str(i))\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    OUTPUT += 'MAE: ' + str(MAE_RECORDS[min_eval_loss_epoch[1]]) \\\n",
        "                + '  MdAE: ' + str(MDAE_RECORDS[min_eval_loss_epoch[1]]) + '\\n'\n",
        "    OUTPUT += 'training time: ' + str(time_records[min_eval_loss_epoch[1]]) + '\\n'\n",
        "    OUTPUT += 'Epochs: ' + str(min_eval_loss_epoch[1]) +'\\n'\n",
        "    global BATCH_SIZE\n",
        "    OUTPUT += 'batch size: ' + str(BATCH_SIZE) + '\\n'\n",
        "    OUTPUT += 'Description added : ' + str(ADD_DESCRIPTION) + '\\n'\n",
        "\n",
        "    best_mae_index = min_eval_loss_epoch[1]\n",
        "    wandb.log({\"best_MAE\": MAE_RECORDS[best_mae_index],\n",
        "               \"best_MdAE\": MDAE_RECORDS[best_mae_index],\n",
        "               \"best_MAE_train_time\":time_records[min_eval_loss_epoch[1]]})\n",
        "    wandb.finish()\n",
        "\n",
        "    print('all done for one project')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDataLoader:\n",
        "    def __init__(self,dynamic_batch=True, batch_size_ratio=0.1, data_path='', within_project=False,tokenizer=None):\n",
        "        self.dynamic_batch = dynamic_batch\n",
        "        self.batch_size_ratio = batch_size_ratio\n",
        "        self.data_path = data_path\n",
        "        self.within_project = within_project\n",
        "        self.batch_size = None\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "\n",
        "    def prepare_dataframe(self, file_name):\n",
        "        data = pd.read_csv(file_name)\n",
        "        # some rows have no description, fill blank to avoid Null\n",
        "        data = data.fillna(' ')\n",
        "\n",
        "\n",
        "        if ADD_DESCRIPTION :\n",
        "            print(\"### text : title+description\")\n",
        "            d = {'text':('[CLS]' + data['title'] + '[SEP]' + data[\"description\"]+'[SEP]').tolist(), 'label': data['storypoint']}\n",
        "        else:\n",
        "            print(\"### text : title\")\n",
        "            d = {'text': (data['title']).tolist(), 'label': data['storypoint']}\n",
        "        \n",
        "        print(\"Input data feed ::: \",d['text'][0])\n",
        "        return pd.DataFrame(data=d)\n",
        "    \n",
        "\n",
        "    def tokenization(self, text_list):\n",
        "        tokenized =  self.tokenizer.batch_encode_plus(text_list, truncation=True, \n",
        "                                                 max_length=SEQUENCE_LEN, \n",
        "                                                 padding='max_length', \n",
        "                                                 return_tensors='pt')\n",
        "        return tokenized\n",
        "\n",
        "\n",
        "    def train_val_split(self, data, split_ratio):\n",
        "        print('cross project split!')\n",
        "        \n",
        "        split_point = int(len(data) * split_ratio)\n",
        "        train_text = data['text'][:split_point]\n",
        "        train_labels = data['label'][:split_point]\n",
        "        val_text = data['text'][split_point:]\n",
        "        val_labels = data['label'][split_point:]\n",
        "\n",
        "        return train_text, train_labels, val_text, val_labels\n",
        "\n",
        "\n",
        "    def within_project_split(self, data):\n",
        "        print('within project split!')\n",
        "        train_val_split_point = int(len(data) * 0.6)\n",
        "        val_test_split_point = int(len(data) * 0.8)\n",
        "\n",
        "        train_text = data['text'][:train_val_split_point]\n",
        "        train_labels = data['label'][:train_val_split_point]\n",
        "\n",
        "        val_text = data['text'][train_val_split_point:val_test_split_point]\n",
        "        val_labels = data['label'][train_val_split_point:val_test_split_point]\n",
        "        \n",
        "        test_text = data['text'][val_test_split_point:]\n",
        "        test_labels = data['label'][val_test_split_point:]\n",
        "        \n",
        "        return train_text, train_labels, val_text, val_labels, test_text, test_labels\n",
        "    \n",
        "\n",
        "    def prepare_dataloader(self, seq, y, sampler_type, attention_mask):\n",
        "        tensor_dataset = TensorDataset(seq, y,attention_mask)\n",
        "\n",
        "        if sampler_type == 'random':\n",
        "            sampler = RandomSampler(tensor_dataset)\n",
        "        elif sampler_type == 'sequential':\n",
        "            sampler = SequentialSampler(tensor_dataset)\n",
        "\n",
        "        print(\"BATCH_SIZE : \",BATCH_SIZE)\n",
        "        dataloader = DataLoader(tensor_dataset, sampler=sampler, batch_size=self.batch_size)\n",
        "        return dataloader\n",
        "\n",
        "    def get_dataloader(self,tokenized_result,labels , sampler_type='sequential'):\n",
        "\n",
        "        input_ids = torch.tensor(tokenized_result['input_ids'])\n",
        "        att_mask = torch.tensor(tokenized_result['attention_mask'])\n",
        "        y = torch.tensor(labels.tolist()).type(torch.LongTensor)\n",
        "        dataloader = self.prepare_dataloader(input_ids,y,\n",
        "                                             sampler_type=sampler_type,\n",
        "                                             attention_mask=att_mask)\n",
        "        return dataloader\n",
        "\n",
        "    def get_test_dataloader(self,file_pair,labels ,test_text=None, sampler_type='sequential'):\n",
        "        # prepare testing datasets\n",
        "        all_test_dataloader = []\n",
        "        test_file_names = []\n",
        "\n",
        "        if self.within_project :\n",
        "            tokens_test = self.tokenization(test_text.tolist())\n",
        "            dataloader = self.get_dataloader(tokens_test,labels,sampler_type=sampler_type)\n",
        "\n",
        "            all_test_dataloader.append(dataloader)\n",
        "            test_file_names.append(file_pair['test'][0])\n",
        "\n",
        "            return all_test_dataloader\n",
        "        else:\n",
        "\n",
        "            # to iterate over testing files\n",
        "            for test_file_name in file_pair['test']:\n",
        "                file_path = self.data_path + test_file_name + '.csv'\n",
        "                test_data = self.prepare_dataframe(file_path)\n",
        "\n",
        "                test_text = test_data['text']\n",
        "                test_labels = test_data['label']\n",
        "\n",
        "                # tokenization\n",
        "                tokens_test = tokenization(test_text.tolist())\n",
        "                data_loader = self.get_dataloader(tokens_test,test_labels,sampler_type=sampler_type)\n",
        "\n",
        "                all_test_dataloader.append(data_loader)\n",
        "                test_file_names.append(test_file_name)\n",
        "            return all_test_dataloader , test_file_names\n",
        "            \n",
        "\n",
        "    def data_processing(self,file_pair):\n",
        "\n",
        "        train_data = pd.DataFrame(columns=['text', 'label'])\n",
        "\n",
        "        for train_file_name in file_pair['train']:\n",
        "            file_path = self.data_path + train_file_name + '.csv'\n",
        "            df = self.prepare_dataframe(file_path)\n",
        "            train_data = train_data.append(df)\n",
        "\n",
        "\n",
        "        # Split the dataset for train | eval | test\n",
        "        if self.within_project:\n",
        "            train_text, train_labels, val_text, val_labels, test_text, test_labels = self.within_project_split(train_data)\n",
        "        else:\n",
        "            train_text, train_labels, val_text, val_labels = self.train_val_split(train_data, 0.6)\n",
        "\n",
        "\n",
        "        # split into batches\n",
        "        if self.dynamic_batch:\n",
        "            batch_size = int(len(train_text) * BATCH_SIZE_RATIO)    \n",
        "\n",
        "        # tokenization\n",
        "        train_tokenized_res = self.tokenization(train_text.tolist())\n",
        "        val_tokenizer_res = self.tokenization(val_text.tolist())\n",
        "        \n",
        "\n",
        "        train_dataloader = self.get_dataloader(train_tokenized_res,train_labels,sampler_type='random')\n",
        "        val_dataloader = self.get_dataloader(val_tokenizer_res,val_labels,sampler_type='sequential')\n",
        "        test_dataloaders, test_file_names = self.get_test_dataloader(file_pair,test_labels,test_text,sampler_type='sequential')\n",
        "\n",
        "        return train_dataloader, val_dataloader, test_dataloaders, test_file_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "expected ':' (3218982640.py, line 79)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 79\u001b[0;36m\u001b[0m\n\u001b[0;31m    with torch.no\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import wandb\n",
        "from transformers import PreTrainedModel\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.nn as nn\n",
        "\n",
        "class Trainer:\n",
        "    min_eval_loss_epoch = [10000, 0]\n",
        "    def __init__(self, model:PreTrainedModel,file_pair , device, learning_rate, epochs, batch_size, sequence_len, tokenizer,tokenizer_name, model_name, add_description, wandb_special_tags):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.sequence_len = sequence_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model_name = model_name\n",
        "        self.add_description = add_description\n",
        "        self.file_pair = file_pair\n",
        "        self.wandb_special_tags = wandb_special_tags\n",
        "        self.tokenizer_name= tokenizer_name\n",
        "    \n",
        "    def log_to_wandb(self,logs,step):\n",
        "        wandb.log(logs,step=step)    \n",
        "\n",
        "    def train(self, train_dataloader,epoch_step):\n",
        "\n",
        "\n",
        "        print(\"Start training for \", self.file_pair, \".....\")\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        for batch in enumerate(train_dataloader):\n",
        "            input_ids = batch[0].to(self.device)\n",
        "            labels = batch[1].to(self.device)\n",
        "            attention_mask = batch[2].to(self.device)\n",
        "            \n",
        "            #reset the gradients \n",
        "            self.model.zero_grad()\n",
        "            result = self.model(input_ids,\n",
        "                            labels=labels,\n",
        "                            attention_mask=attention_mask,\n",
        "                            return_dict=True)\n",
        "            \n",
        "            loss = result.loss\n",
        "            logits = result.logits\n",
        "            total_train_loss += loss.item()\n",
        "            \n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            del epoch_step, batch, input_ids, labels, result, loss, logits\n",
        "\n",
        "            # averaging train loss of each batch iteration\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "        self.log_to_wandb({f'train_loss':avg_train_loss},step=epoch_step)\n",
        "        print(\"Average train loss :{0:.2f}\".format(avg_train_loss))\n",
        "\n",
        "        del avg_train_loss, total_train_loss\n",
        "        time_records.append(time.time() - training_start_time)\n",
        "\n",
        "    def finalize_saved_models(self):\n",
        "        final_model_path = 'models/' + str(self.file_pair['train'][0]) + '_'+ str(self.file_pair['test'][0]) + '_epo_' + str(self.min_eval_loss_epoch[1])\n",
        "        os.rename('models/epo_' + str(self.min_eval_loss_epoch[1]),final_model_path)\n",
        "\n",
        "        for i in range(20):\n",
        "            try:\n",
        "                os.remove(\"models/epo_\" + str(i))\n",
        "            except:\n",
        "                continue \n",
        "\n",
        "        print(\"Saved best epoch/Cleared Model folder\")\n",
        "        return final_model_path\n",
        "\n",
        "    def evaluate(self, val_dataloader,step):\n",
        "        # Evaluation logic here\n",
        "        self.model.eval()\n",
        "        total_eval_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dataloader:\n",
        "                input_ids = batch[0].to(self.device)\n",
        "                labels = batch[1].to(self.device)\n",
        "                attention_mask = batch[2].to(self.device)\n",
        "\n",
        "                self.model.zero_grad()\n",
        "                result = self.model(input_ids,\n",
        "                            labels=labels,\n",
        "                            attention_mask=attention_mask,\n",
        "                            return_dict=True)\n",
        "                \n",
        "                loss = result.loss\n",
        "                logits = result.logits\n",
        "                total_eval_loss += loss.item()\n",
        "\n",
        "                # clean memory\n",
        "                del input_ids, labels, batch, result, loss, logits\n",
        "            \n",
        "        avg_eval_loss = total_eval_loss / len(val_dataloader)\n",
        "        self.log_to_wandb({f'eval_loss':avg_eval_loss},step=step)\n",
        "        print(\"Average eval loss :{0:.2f}\".format(avg_eval_loss))\n",
        "\n",
        "        # keeping the min eval loss epoch\n",
        "        if avg_eval_loss <= self.min_eval_loss_epoch[0]:\n",
        "            self.min_eval_loss_epoch[0] = avg_eval_loss\n",
        "            self.min_eval_loss_epoch[1] = step\n",
        "        \n",
        "        torch.save(self.model.state_dict(), './models/' + 'epo_' + str(step))\n",
        "\n",
        "    def load_model_from_epoch(self,epoch):\n",
        "        self.model.zero_grad()\n",
        "        self.model.load_state_dict(torch.load('models/epo_' + str(epoch)))\n",
        "\n",
        "\n",
        "    def test(self, test_dataloader,best_epoch):\n",
        "        predictions = []\n",
        "        true_labels = []\n",
        "        for batch in test_dataloader:\n",
        "            batch = tuple(t.to(self.device) for t in batch)\n",
        "            b_input_ids, b_labels, attention_mask = batch\n",
        "\n",
        "            with torch.no_grad():\n",
        "                self.load_model_from_epoch(best_epoch)\n",
        "                logits = self.model(b_input_ids,attention_mask=attention_mask)\n",
        "            \n",
        "            logits = logits['logits'].detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "            \n",
        "            predictions.append(logits)\n",
        "            true_labels.append(label_ids)\n",
        "        \n",
        "        # Calculate Errors\n",
        "        distance_records = []\n",
        "        for i in range(len(predictions)):\n",
        "            for j in range(len(predictions[i])):\n",
        "                distance = abs(predictions[i][j] - true_labels[i][j])\n",
        "                distance_records.append(distance)\n",
        "\n",
        "        MAE = np.mean(np.array(distance_records))\n",
        "        MADE = np.median(np.array(distance_records))\n",
        "        print(\"Testing MAE  : \",MAE)\n",
        "        print(\"Testing MdAE : \",MADE)\n",
        "        return MAE , MADE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def train_eval_test(self, file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names):\n",
        "              # start a new wandb run to track this script\n",
        "        wandb.init(\n",
        "                # set the wandb project where this run will be logged\n",
        "                project = \"esti-mate\",\n",
        "                name = f\"{self.model_name}_{file_pair['train'][0]}\",\n",
        "                tags = self.wandb_special_tags,\n",
        "\n",
        "                # track hyperparameters and run metadata\n",
        "                config={\n",
        "                \"learning_rate\": self.learning_rate,\n",
        "                \"sequence_len\": self.sequence_len,\n",
        "                \"batch_size_ratio\":self.batch_size,\n",
        "                \"tokenizer\":self.tokenizer_name,\n",
        "                \"model_name\":self.model_name,\n",
        "                \"description_added\":self.add_description,\n",
        "                \"epochs\": self.epochs,\n",
        "                'data_set':file_pair[\"train\"][0]\n",
        "                }\n",
        "        )\n",
        "\n",
        "        \n",
        "        optimizer = AdamW(self.model.parameters(), lr=self.learning_rate)\n",
        "        total_steps = len(train_dataloader) * self.epochs\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "        time_records = []\n",
        "\n",
        "        for e in range(self.epochs):\n",
        "\n",
        "            self.train(train_dataloader,e)\n",
        "            self.evaluate(val_dataloader,e)\n",
        "\n",
        "\n",
        "            wandb.finish()    \n",
        "\n",
        "        \n",
        "        print(\"Best epoch : \",self.min_eval_loss_epoch[1])\n",
        "        print(\"Best eval loss : \",self.min_eval_loss_epoch[0])\n",
        "        mae , made = self.test(all_test_dataloader,best_epoch=self.min_eval_loss_epoch[1])\n",
        "\n",
        "\n",
        "        print(\"Best testing MAE : \",mae)\n",
        "        self.log_to_wandb({\"best_MAE\": mae,\"best_MdAE\": made , \"best_MAR_train_time\":time_records[self.min_eval_loss_epoch[1]]  })\n",
        "        \n",
        "        self.finalize_saved_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn3yXK4lhfbo"
      },
      "source": [
        "### Within Project Training Script @"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-uMZ1Cfhfbo",
        "tags": []
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "573e87f50387468f976047ac393b8271",
            "ba1736ec9cfd4133b5fb867464be3918",
            "5702ef2ed33c42cb8b0b93759ac1a5c7",
            "ea1b7fece5e74fac91bee528b96f9e10",
            "7791cbc399d24694bde28aa2a90af944",
            "c2c271d5e1374554b872d4ba64e405d0",
            "63e926e182264d00acb2bb29aaf73913",
            "5a7441ec715249bd8e89309435a35d6d",
            "f9773def0f374478a42a8cf03dfeece7",
            "7e07c948be5742c89658a4147639ed21",
            "4edc237f84c54800b8cd8243cb3a8226",
            "f6e55e3131c545aaad90faa445ab3e3c",
            "1c8ec90fde33447babae9c4fb09e9331",
            "1d4aff476ee144e9b2e17a29513f97cc",
            "ee651a0f23654004941a06e413ea4f6c",
            "479cf1fec8fe4fdd83ec688e0bdd17d8",
            "838bcdeb28a54763a3dd6c438bf94b3d",
            "260ad22af63148b38b2e353879636bd2",
            "c65c576ebb224dcabb3ec30d59d8d545",
            "635caca8542a463c83c8f15efb5cbaac",
            "f8373d7d9d864bcba0ac4b5f5877a075",
            "7afc519903b04b7485ab6f03feb04d74",
            "e0755a3df4bf48a483f7f6c1f5999362",
            "e5576d70ef564bd18deb9b81b03e558a",
            "a4e7ad14a2f64c36b7b8973712738aea",
            "f8acbce3273d4066a1b0bd56abdcba95",
            "c0cab96d29174c0daf1900d26d49fbda",
            "b95cf308a3c54a4e8a465a0198b47432",
            "2ddb31a17608440fae7962afafe8c88f",
            "eb59731354724d299ec4873c62ac9e53",
            "37d41c0a59224a01beea870c74fbd37e",
            "71389490ec39416fb0e99b5abcc808d4",
            "228d17aa6e014ab5a36ea8348a4eb84b",
            "3db5a7481933410cb1047b8b382696ae",
            "4bdb7554d90c4f85a58e043978f51454",
            "d1efe380258c43f3b089776a48a05be3",
            "fa8e2dcc4e534b61bfef5316147990d8",
            "632e7b8571e6408c8ca2277e19f3517f",
            "f1a3d6c8155c4f9e96bc92ee1debb60e",
            "d79aee464ca04177af160a6aa3a8ea0e",
            "419e416342bc4e3db0093822bda005d2",
            "784a0d7728fc44f1bfd6461409f7cf3d",
            "acb75eb759f240e0a1395448dc914ea0",
            "9f1f18dd978f49579ab87f452f2e9998",
            "0c80b7dcfd12460da74e8115547e072a",
            "2727f27a3c9f43bab89938650ff5fed8",
            "92555e18a4eb4eacae773321ed48373f",
            "2185bdb998844e1391c4d5d778fc6bc4",
            "38344ffd15a34db7b4b8688b4d87df97",
            "ffe771e64b274b1099ce1da39acf752f",
            "52878ae904dd4110b7b90b1a4e8e2008",
            "687ab8f448cc4dd6a1d258a40905bff2",
            "caf6b5951a184e19ac222c4189819126",
            "952c3aafdc444ec09ea42c1923aa2d60",
            "d7ebea85079e4dd696abec2dfc27469e",
            "9d4b865cfb3a4200bdf96852043e1521",
            "4af00ac2cb8146739c876ca696b23a8a",
            "82cb807c840b480e8a722809e0190e75",
            "39b59d26602a4277aea403c42e9b2be0",
            "10fba9f8c47d49199e5f6cd92a959605",
            "bd0e565198d14263b63c44d2ebd5efd6",
            "12b33fa4f9a4431a9a3c1dd08abba5d9",
            "a9ecf2f838a74737aca9bd4dcb798671",
            "e5936854533746119b295dc10f6c2249",
            "49ec2bcb77974bd48ab9d28cf7c2ed40",
            "3332852aeb5a4a47b5ebd9af1a257b8a",
            "1aa0a7599ae14b1f998c6e06a6c84b8f",
            "5f537674bc42433db1907d6f62b948d4",
            "579f54a0073a44deb0df85e71561e54d",
            "0f9da33a2cc84db8be2e67a40a32a26a",
            "f370309c69f142b79bc15711fd38518d",
            "bf37e7dd527f4b87b30b12a23be06848",
            "cb07a4a1c8d94bf791090604431ab2ba",
            "084acb6fd39a4f6f92544332a3433c24",
            "bfd01714a88c4f6791782b9e3125accd",
            "7ff9fa541010440bad59b61625f04b62",
            "66cc0762331b4514a71145d444f32290",
            "8563a68bbd594317ba22bb974347f4ce",
            "f54935aed1b84973bf1dbe21a301e099",
            "d707fd40d9214188a27b7703267c0cc9",
            "97c6742cdeba44a1bf80e9549ff27a40",
            "f7518835420c44b7a54861ed125443e1",
            "c76912e2f63e470d986c4ae3dda3eca5",
            "34ef5a5f91544775863e3b8919ba552b",
            "06087a2af6e6483ab983514ec45beeb3",
            "f1dc83712ef543ef9ad800150fd5457b",
            "4ce4f2638fd64e77aead69f9603f39ca",
            "1759f0c458324755b498fd3744ef3790",
            "1df88403827d45dbb64af4400d7b150b",
            "c51151425ddf417ab1bd28a7455492cc",
            "662fc05e70e8476fbd72db6477a31223",
            "cfeb5dbcde374e189ce8d7a815aa1297",
            "8d7c60f53b0041bd82885143695514be",
            "af0de9edcf574846830d71e62405b7d2",
            "e0e29f4c3b594af8ac5adfb659f1670d",
            "20fa29929dc04340b2c81750f4b0b5cf",
            "ceede187c7c6484385b5fb11324334fc",
            "9f606b99f32644d686c3d186c55b8ede",
            "b92ec0352f66492cb9d54e83f72096c4",
            "cea6ac475d044a99a62e72f45dd1877e",
            "0e8c5bc9cf1c413db2dffa6ce06d0575",
            "538b3d53bbb54fd0a85d7ad37de044d4",
            "04aafc0534aa4d0881ad79f392646413",
            "b274b038ec8b406b81b33b21eeac6246",
            "423fb6e288064bac8d06c694b00a3168",
            "56b4a78911f549c996049329139e0d72",
            "ae3d0a1a78874b6197fe75733b51cdf4",
            "96da3738bdcb4be0baa85ebd06a0a720",
            "0a3a1969eefe459592e51a87d0dee41b",
            "784c2822b6a8491690ba37b45e8225ab",
            "dce8ee5deb814a8ba2bfcefaaf0fb49f",
            "bd4472bcc9404363ab96d2759f9cb8c6",
            "e029ba5bc6154434a64e77a32bf43cb1",
            "cc91e5dcec594a5cbb961f0273551a54",
            "a7673f7f3d374c5d9c2910245ac391aa",
            "c978de7d63d947d18d99bb4eef225d08",
            "c725abcc6a0242fc9704c56d485b52d0",
            "6350eafd020c46a69bf68660f24accc4",
            "cb17d9abc0b348d692e097406758a9d2",
            "973b5b6999354e46b719446124d953b5",
            "7b2661e3f17b496080a0d0549283aef5",
            "99b63c9ef68d47578ca46b6c9f298059",
            "baaef81242324e5cb94c464f36b48589",
            "f3e1b4e1d7ac40f8b6567a49e4d68583",
            "e053838091cb46a29ac7346e25f682b0",
            "638cd8ad49b54753a577bb51d100000f",
            "99dbc264370b4b538118b08983505fea",
            "d2b0b90e1f674cf691cebfda537c127c",
            "417676e00b8b482bbc218b300a46dd5f",
            "c78abd161eac43b686464170b74c4417",
            "37a41afb7d2840aea2e97c18eff6c188",
            "32388a9e0c3146d782f32d3ff06a475c",
            "88bebac6f0444c7abbc8f79c64267482",
            "58549ff3e860424db6642f6fd342c8dd",
            "3f09cbb0590e4b78bab6d01fd8b532a6",
            "4c8d98fd49094961955b4a003ef23f36",
            "ba29c3558db04748bd9516f3f9254199",
            "9b372ba8076e486ba4cdb690f25dacb5",
            "54c3d5b2fe2d47e88685a228ce8cd5a4",
            "d065dcee8d5e4936a766ed81bc6ca09c",
            "78f4ef0bbb44439cb46b584a1507a945",
            "73be493298ce443aaa2eaa46bee5a0ae",
            "5891e1de423c4962a3bc50311ad6e69a",
            "8970d535a3424ac29673606790f17c1b",
            "5ef38ca56caa471fbf32a3c07093fa5f",
            "8af45e16443b4fea9455477e48507ecf",
            "3d36079092b04317995afe187e502531",
            "02fb1e44540a425ea493213281da8992",
            "3ed8abd2ae574437aac866f040ab9437",
            "a10ea8bf63194463acbada483e4203a8",
            "9467d8c2c5f84f819508a577af58ec15",
            "49c5aa52537947cbae5e95f3d0241be7",
            "8a7db69f700546719f42ee550e98e029",
            "7b90a9bf0cb3434d8c27866fc8809c62",
            "a4a5b43775634974ba557e356a2ad0eb",
            "002225fa34a54e929ab295964871a941",
            "321db1f2f0f543e5a0068c919415467c",
            "b5d0d1d5d03144c8a34372dea92f6464",
            "2f1ddebfaacd43e28547413a88d2b6a0"
          ]
        },
        "id": "MwmBk2BPhfbo",
        "outputId": "afbebd0c-bece-46f8-9b4b-fec48cf549b0",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2SP were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### text : title+description\n",
            "Input data feed :::  [CLS]Transition git repositories to Stash[SEP]Transition gitolite-managed repositories to Atlassian Stash.[SEP]\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "573e87f50387468f976047ac393b8271",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6e55e3131c545aaad90faa445ab3e3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0755a3df4bf48a483f7f6c1f5999362",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3db5a7481933410cb1047b8b382696ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c80b7dcfd12460da74e8115547e072a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "tensor([[   58,  5097,    50,    60,  8291,   653, 17606, 38072,   284,   520,\n",
            "          1077,    58,  5188,    47,    60,  8291,   653,   308, 11650,   578,\n",
            "            12, 39935, 38072,   284,  5234, 46091,   520,  1077,  3693,  5188,\n",
            "            47,    60, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 19006,  1096, 14848,  4365,  2643,    58,\n",
            "          5188,    47,    60,   464,  5150,  4365,  2643,   329,   262, 30948,\n",
            "          2257, 10442, 23881,  2478,    25,  1391, 22708,    92,  2039, 11716,\n",
            "         30948,  2257,  3783,   416,  4441,   257,   880, 12395,    11,  1181,\n",
            "            12,  1659,    12,  1169,    12,   433,    11,  1029,    12, 26585,\n",
            "            11, 43865,    11,  5021,    12, 25695,    11,  1280,  2723,    11,\n",
            "           440,    14,  4663,  5526,  1366,  7587,   290,  3781,  1080,  1391,\n",
            "         22708,    92,   351,   262,  1708, 25738,    25,   220,  1635,   880,\n",
            "         12395,  1377,   355,  4306,   340,   481,   307,  5340,   284,  5529,\n",
            "           393,   307, 24284,   329,  5684,   513,  1635,  1181,    12,  1659],\n",
            "        [   58,  5097,    50,    60, 11505,   510, 30948,  2257,  3788, 21898,\n",
            "          8341,    58,  5188,    47,    60,  1135,   477,  4414,   422,  1642,\n",
            "         30948,  2257,  3788,  2478,   355,  1280,   355,  1744,   290, 45645,\n",
            "           284,  2354, 13904,  9284, 20789,   737,  1881,   835,   284,  2620,\n",
            "          2055,  9750,   318,   284,  1280,   510,   674,  2478, 21898,  8341,\n",
            "           284,   262,  1171,    11, 34657,   284,   262,   835,   584,  1280,\n",
            "          2723,  4493,   466,    13,  1114,  1672,    11,   356,   714,   423,\n",
            "            25,   220,  1635,  3788,    12,  2934,   626,    31,  7278,   301,\n",
            "         10215,    79,    13,  2398,    25,   262,  2478, 21898,  1351,    11,\n",
            "          7548,   284,  1459, 43979,   301,    12,  7890,  1635,  3788,    12],\n",
            "        [   58,  5097,    50,    60,  8291,   653,   284,  7326, 23079, 20396,\n",
            "            58,  5188,    47,    60, 11505,   262,  7326, 23079, 20396,  2524,\n",
            "            11,   329, 10375,   351,   262,  2055,   357,   392,   284,  7139,\n",
            "          2055,  2116,    12, 16794,   737,   220,   685,  5188,    47,    60,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60,  4550, 28486,    12,  3106,  6436,  7509,\n",
            "           284,  2212,    62, 16680,   361,   270,    58,  5188,    47,    60,\n",
            "          6214,  3740,  1378,  7959,    13,  7278,   301, 10215,    79,    13,\n",
            "          2398,    14,  2213,   330,    14, 43350,    14,    18, 20964,   220,\n",
            "          8362,  2173,  8636,   318,   329,  5637,   670,   691,   357,  3137,\n",
            "           262,  2438,  2423,    11,   543,   318,   991,  8904, 42669,  5188,\n",
            "            47,    60, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
            "BATCH_SIZE :  56\n",
            "BATCH_SIZE :  56\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_att_mask = torch.tensor(tokens_test['attention_mask'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH_SIZE :  56\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp/wandb/run-20240322_133335-0mbr4e8z</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/0mbr4e8z' target=\"_blank\">gpt2sp_datamanagement</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/0mbr4e8z' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/0mbr4e8z</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training for  {'train': ['datamanagement'], 'test': ['datamanagement']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 11.40\n",
            "-\n",
            " Average eval MAE loss: 7.20\n",
            "===============================\n",
            "MAE:  6.7252474\n",
            "MdAE:  3.1723907\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 8.53\n",
            "-\n",
            " Average eval MAE loss: 6.89\n",
            "===============================\n",
            "MAE:  6.911571\n",
            "MdAE:  3.2266629\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 6.75\n",
            "-\n",
            " Average eval MAE loss: 5.45\n",
            "===============================\n",
            "MAE:  5.4938617\n",
            "MdAE:  2.6168084\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 5.89\n",
            "-\n",
            " Average eval MAE loss: 5.52\n",
            "===============================\n",
            "MAE:  5.9422693\n",
            "MdAE:  2.3159876\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 5.29\n",
            "-\n",
            " Average eval MAE loss: 5.96\n",
            "===============================\n",
            "MAE:  6.4381003\n",
            "MdAE:  2.4552367\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 4.62\n",
            "-\n",
            " Average eval MAE loss: 5.45\n",
            "===============================\n",
            "MAE:  5.67633\n",
            "MdAE:  2.534536\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 4.33\n",
            "-\n",
            " Average eval MAE loss: 5.39\n",
            "===============================\n",
            "MAE:  5.5260806\n",
            "MdAE:  2.2326455\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 3.97\n",
            "-\n",
            " Average eval MAE loss: 5.72\n",
            "===============================\n",
            "MAE:  6.0142155\n",
            "MdAE:  2.6775212\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 3.52\n",
            "-\n",
            " Average eval MAE loss: 5.42\n",
            "===============================\n",
            "MAE:  5.7048564\n",
            "MdAE:  2.5173428\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 3.03\n",
            "-\n",
            " Average eval MAE loss: 5.53\n",
            "===============================\n",
            "MAE:  5.7892885\n",
            "MdAE:  2.6185338\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 3.04\n",
            "-\n",
            " Average eval MAE loss: 5.49\n",
            "===============================\n",
            "MAE:  5.732065\n",
            "MdAE:  2.6219783\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 2.77\n",
            "-\n",
            " Average eval MAE loss: 5.38\n",
            "===============================\n",
            "MAE:  5.677133\n",
            "MdAE:  2.4383605\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 2.65\n",
            "-\n",
            " Average eval MAE loss: 5.74\n",
            "===============================\n",
            "MAE:  6.0479717\n",
            "MdAE:  2.7694795\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 2.21\n",
            "-\n",
            " Average eval MAE loss: 5.44\n",
            "===============================\n",
            "MAE:  5.764517\n",
            "MdAE:  2.5616024\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 2.01\n",
            "-\n",
            " Average eval MAE loss: 5.38\n",
            "===============================\n",
            "MAE:  5.746572\n",
            "MdAE:  2.5188832\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 1.93\n",
            "-\n",
            " Average eval MAE loss: 5.62\n",
            "===============================\n",
            "MAE:  5.9069514\n",
            "MdAE:  2.601727\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 1.79\n",
            "-\n",
            " Average eval MAE loss: 5.51\n",
            "===============================\n",
            "MAE:  5.8795033\n",
            "MdAE:  2.5503757\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 1.73\n",
            "-\n",
            " Average eval MAE loss: 5.52\n",
            "===============================\n",
            "MAE:  5.8708754\n",
            "MdAE:  2.5613782\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 1.51\n",
            "-\n",
            " Average eval MAE loss: 5.45\n",
            "===============================\n",
            "MAE:  5.8568563\n",
            "MdAE:  2.5542874\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 1.48\n",
            "-\n",
            " Average eval MAE loss: 5.50\n",
            "===============================\n",
            "MAE:  5.8693924\n",
            "MdAE:  2.6272807\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d4b865cfb3a4200bdf96852043e1521",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>██▄▂▃▃▁▄▃▄▄▂▅▃▃▄▃▃▃▄</td></tr><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>█▇▁▂▃▁▁▂▁▂▁▁▂▁▁▂▁▂▁▁</td></tr><tr><td>test_MAE</td><td>▇█▁▃▆▂▁▄▂▂▂▂▄▂▂▃▃▃▃▃</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>2.62728</td></tr><tr><td>best_MAE</td><td>5.67713</td></tr><tr><td>best_MAE_train_time</td><td>837.30904</td></tr><tr><td>best_MdAE</td><td>2.43836</td></tr><tr><td>eval_loss</td><td>5.50258</td></tr><tr><td>test_MAE</td><td>5.86939</td></tr><tr><td>train_loss</td><td>1.47633</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gpt2sp_datamanagement</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/0mbr4e8z' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/0mbr4e8z</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240322_133335-0mbr4e8z/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all done for one project\n",
            "results have been written into a text file!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2SP were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### text : title+description\n",
            "Input data feed :::  [CLS]Document logging framework[SEP]Store-client: Whenever used, creates a c:/ directory and several directories underneath it to store its log files.  Sending logs to STDOUT by default and/or having a documented way to changes this would be good.[SEP]\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "tensor([[   58,  5097,    50,    60, 24941, 18931,  9355,    58,  5188,    47,\n",
            "            60, 22658,    12, 16366,    25, 21326,   973,    11,  8075,   257,\n",
            "           269, 14079,  8619,   290,  1811, 29196, 14638,   340,   284,  3650,\n",
            "           663,  2604,  3696,    13,   220, 32038, 17259,   284, 48571, 12425,\n",
            "           416,  4277,   290,    14,   273,  1719,   257, 12395,   835,   284,\n",
            "          2458,   428,   561,   307,   922,  3693,  5188,    47,    60, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 35265,   329,  2829, 19698,   286,  1628,\n",
            "          2196,  3146,    58,  5188,    47,    60,  1026,   815,   307,  2562,\n",
            "            14, 36439,   284,  4296,   262,  2196,  1271,   286,   477,  3354,\n",
            "           286,   262, 14805,   329,  1123,  2650,  3693,  5188,    47,    60,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60,    33, 12171,  3440,    25, 49899,  4388,\n",
            "           360,  5330, 18839, 26151,   286,   838, 22737,   286,   347,  6581,\n",
            "          2695,    58,  5188,    47,    60,   685,  5188,    47,    60, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 12889,  7156,    17,    42,    25,  7412,\n",
            "         11315,  2139,    58,  5188,    47,    60, 16177, 29908,   290,  2139,\n",
            "           284,  1620, 11315,   286,  4263,   422,   309, 29267,   284, 48561,\n",
            "            17,    42,  3693,  5188,    47,    60, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 12889,  7156,    17,    42,    25,  7412,\n",
            "          4382,  2139,    58,  5188,    47,    60, 16177, 29908,   290,  2139,\n",
            "           284,  4691, 48561,    17,    42,  4263,  3693,  5188,    47,    60,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
            "BATCH_SIZE :  7\n",
            "BATCH_SIZE :  7\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_att_mask = torch.tensor(tokens_test['attention_mask'])\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseniyas\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH_SIZE :  7\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp/wandb/run-20240322_135732-aos6va6s</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/aos6va6s' target=\"_blank\">gpt2sp_duracloud</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/aos6va6s' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/aos6va6s</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training for  {'train': ['duracloud'], 'test': ['duracloud']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 7.14\n",
            "-\n",
            " Average eval MAE loss: 0.80\n",
            "===============================\n",
            "MAE:  0.78798544\n",
            "MdAE:  0.53915834\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 1.55\n",
            "-\n",
            " Average eval MAE loss: 0.85\n",
            "===============================\n",
            "MAE:  0.87553394\n",
            "MdAE:  0.7827703\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 1.42\n",
            "-\n",
            " Average eval MAE loss: 1.01\n",
            "===============================\n",
            "MAE:  0.9997421\n",
            "MdAE:  0.5474262\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 1.37\n",
            "-\n",
            " Average eval MAE loss: 1.64\n",
            "===============================\n",
            "MAE:  1.5225668\n",
            "MdAE:  1.3984804\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 1.34\n",
            "-\n",
            " Average eval MAE loss: 1.05\n",
            "===============================\n",
            "MAE:  0.86653966\n",
            "MdAE:  0.5330496\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 1.20\n",
            "-\n",
            " Average eval MAE loss: 0.91\n",
            "===============================\n",
            "MAE:  0.83492744\n",
            "MdAE:  0.64478016\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 1.03\n",
            "-\n",
            " Average eval MAE loss: 0.78\n",
            "===============================\n",
            "MAE:  0.8257665\n",
            "MdAE:  0.73135006\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 0.88\n",
            "-\n",
            " Average eval MAE loss: 0.85\n",
            "===============================\n",
            "MAE:  0.868782\n",
            "MdAE:  0.56880975\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 0.80\n",
            "-\n",
            " Average eval MAE loss: 0.73\n",
            "===============================\n",
            "MAE:  0.76595396\n",
            "MdAE:  0.4512046\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 0.80\n",
            "-\n",
            " Average eval MAE loss: 0.78\n",
            "===============================\n",
            "MAE:  0.8223593\n",
            "MdAE:  0.53559697\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 0.69\n",
            "-\n",
            " Average eval MAE loss: 0.87\n",
            "===============================\n",
            "MAE:  0.8840716\n",
            "MdAE:  0.8218813\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 0.60\n",
            "-\n",
            " Average eval MAE loss: 0.77\n",
            "===============================\n",
            "MAE:  0.7969873\n",
            "MdAE:  0.5253239\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 0.56\n",
            "-\n",
            " Average eval MAE loss: 0.89\n",
            "===============================\n",
            "MAE:  0.91238594\n",
            "MdAE:  0.83811027\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 0.55\n",
            "-\n",
            " Average eval MAE loss: 0.87\n",
            "===============================\n",
            "MAE:  0.86105525\n",
            "MdAE:  0.7410346\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 0.52\n",
            "-\n",
            " Average eval MAE loss: 0.79\n",
            "===============================\n",
            "MAE:  0.76977515\n",
            "MdAE:  0.64275825\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 0.42\n",
            "-\n",
            " Average eval MAE loss: 0.80\n",
            "===============================\n",
            "MAE:  0.789671\n",
            "MdAE:  0.6919776\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 0.36\n",
            "-\n",
            " Average eval MAE loss: 0.84\n",
            "===============================\n",
            "MAE:  0.8636596\n",
            "MdAE:  0.77246714\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 0.36\n",
            "-\n",
            " Average eval MAE loss: 0.76\n",
            "===============================\n",
            "MAE:  0.74676186\n",
            "MdAE:  0.70747113\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 0.33\n",
            "-\n",
            " Average eval MAE loss: 0.78\n",
            "===============================\n",
            "MAE:  0.7679766\n",
            "MdAE:  0.6619394\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 0.29\n",
            "-\n",
            " Average eval MAE loss: 0.79\n",
            "===============================\n",
            "MAE:  0.79243654\n",
            "MdAE:  0.68226314\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5936854533746119b295dc10f6c2249",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>▂▃▂█▂▂▃▂▁▂▄▂▄▃▂▃▃▃▃▃</td></tr><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▂▂▃█▃▂▁▂▁▁▂▁▂▂▂▂▂▁▁▁</td></tr><tr><td>test_MAE</td><td>▁▂▃█▂▂▂▂▁▂▂▁▂▂▁▁▂▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>0.68226</td></tr><tr><td>best_MAE</td><td>0.76595</td></tr><tr><td>best_MAE_train_time</td><td>133.37879</td></tr><tr><td>best_MdAE</td><td>0.4512</td></tr><tr><td>eval_loss</td><td>0.79216</td></tr><tr><td>test_MAE</td><td>0.79244</td></tr><tr><td>train_loss</td><td>0.28534</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gpt2sp_duracloud</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/aos6va6s' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/aos6va6s</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240322_135732-aos6va6s/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all done for one project\n",
            "results have been written into a text file!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2SP were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### text : title+description\n",
            "Input data feed :::  [CLS]As a JIRA Administrator I would like to be able to change the trigger of the night service[SEP] [SEP]\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "tensor([[   58,  5097,    50,    60,  1722,   257,   449,    40,  3861, 22998,\n",
            "           314,   561,   588,   284,   307,  1498,   284,  1487,   262,  7616,\n",
            "           286,   262,  1755,  2139,    58,  5188,    47,    60,   685,  5188,\n",
            "            47,    60, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60,  1722,   257,   449,    40,  3861, 22998,\n",
            "           314,   561,   588,   284,   307,  1498,   284,  1487,   262,  7616,\n",
            "           286,   262,  1755,  2139,    58,  5188,    47,    60,   685,  5188,\n",
            "            47,    60, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 46189,  3992,  1818, 47217,   743, 19122,\n",
            "           351,   584, 20652,    58,  5188,    47,    60,  4366,  3992,   670,\n",
            "          4028,   423,  9729,   326,   423,   845, 14276, 47217,    11,   884,\n",
            "           355,   366, 10260,  1600,   366, 21774,     1,   290,   366, 29934,\n",
            "           354,     1,  3503,    13,  2312, 47217,   423,   257,   922,  2863,\n",
            "           284, 19122,   351,   262,  2223,  1438,   393, 47217,   973,   416,\n",
            "           584, 20652,    13,   220,  2312, 47217,   815,   307,  1813,   257,\n",
            "          1438,  2176,   284,   262, 13877,    11,   884,   355,   366, 10260,\n",
            "         13719, 28900,  2848, 26932, 29828, 26214, 25929,    11,   262, 20188,\n",
            "         15582,   460,   307,   973,   287,  1295,   286,  3141, 47217,    11],\n",
            "        [   58,  5097,    50,    60, 46189,  3992,  1818, 47217,   743, 19122,\n",
            "           351,   584, 20652,    58,  5188,    47,    60,  4366,  3992,   670,\n",
            "          4028,   423,  9729,   326,   423,   845, 14276, 47217,    11,   884,\n",
            "           355,   366, 10260,  1600,   366, 21774,     1,   290,   366, 29934,\n",
            "           354,     1,  3503,    13,  2312, 47217,   423,   257,   922,  2863,\n",
            "           284, 19122,   351,   262,  2223,  1438,   393, 47217,   973,   416,\n",
            "           584, 20652,    13,   220,  2312, 47217,   815,   307,  1813,   257,\n",
            "          1438,  2176,   284,   262, 13877,    11,   884,   355,   366, 10260,\n",
            "         13719, 28900,  2848, 26932, 29828, 26214, 25929,    11,   262, 20188,\n",
            "         15582,   460,   307,   973,   287,  1295,   286,  3141, 47217,    11],\n",
            "        [   58,  5097,    50,    60,  4550,  2420,   284,   262,  2449,   576,\n",
            "         39266,   366, 44651,  4935,     1,  3275,    58,  5188,    47,    60,\n",
            "          2215,   262,  4049,   318,   366, 44651,  4935,     1,   751,  3307,\n",
            "           326,   262,  1628,   318,   407, 17839,   329,   779,   351,  3469,\n",
            "         28900,  2848,   532,   366, 44651,  4935,   532,   685,  3673, 17839,\n",
            "           329,   779,   351,  3469, 28900,  2848,    91,  4023,  1378, 10414,\n",
            "         23079,    13, 25864, 46091,    13,   785,    14, 13812,    14, 17511,\n",
            "            14, 16934,   870,    10, 14108,    10, 13719, 28900,  2848,    10,\n",
            "         22289,    10, 26232,     2, 16934,   870, 14108, 13719, 28900,  2848,\n",
            "         22289, 26232,    12, 22866,    60, 17912,  5188,    47,    60, 50256]])\n",
            "BATCH_SIZE :  4\n",
            "BATCH_SIZE :  4\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_att_mask = torch.tensor(tokens_test['attention_mask'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH_SIZE :  4\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf37e7dd527f4b87b30b12a23be06848",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113441111117735, max=1.0…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp/wandb/run-20240322_140244-wdib6hx6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/wdib6hx6' target=\"_blank\">gpt2sp_jirasoftware</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/wdib6hx6' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/wdib6hx6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training for  {'train': ['jirasoftware'], 'test': ['jirasoftware']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 4.87\n",
            "-\n",
            " Average eval MAE loss: 4.77\n",
            "===============================\n",
            "MAE:  3.9797032\n",
            "MdAE:  4.0143404\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 3.40\n",
            "-\n",
            " Average eval MAE loss: 2.38\n",
            "===============================\n",
            "MAE:  2.2716525\n",
            "MdAE:  2.2791238\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 3.16\n",
            "-\n",
            " Average eval MAE loss: 3.31\n",
            "===============================\n",
            "MAE:  3.2539287\n",
            "MdAE:  3.1988382\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 2.92\n",
            "-\n",
            " Average eval MAE loss: 3.52\n",
            "===============================\n",
            "MAE:  2.8652935\n",
            "MdAE:  2.9310875\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 2.44\n",
            "-\n",
            " Average eval MAE loss: 3.39\n",
            "===============================\n",
            "MAE:  2.860274\n",
            "MdAE:  2.9042788\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 2.06\n",
            "-\n",
            " Average eval MAE loss: 2.46\n",
            "===============================\n",
            "MAE:  2.3273964\n",
            "MdAE:  1.8516169\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 1.77\n",
            "-\n",
            " Average eval MAE loss: 2.40\n",
            "===============================\n",
            "MAE:  2.4508257\n",
            "MdAE:  2.1175313\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 1.63\n",
            "-\n",
            " Average eval MAE loss: 2.41\n",
            "===============================\n",
            "MAE:  2.2561278\n",
            "MdAE:  1.6456103\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 1.35\n",
            "-\n",
            " Average eval MAE loss: 2.68\n",
            "===============================\n",
            "MAE:  2.5229871\n",
            "MdAE:  2.102293\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 1.31\n",
            "-\n",
            " Average eval MAE loss: 1.90\n",
            "===============================\n",
            "MAE:  2.0147913\n",
            "MdAE:  1.6611648\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 1.10\n",
            "-\n",
            " Average eval MAE loss: 1.71\n",
            "===============================\n",
            "MAE:  1.8049731\n",
            "MdAE:  1.4163992\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 0.99\n",
            "-\n",
            " Average eval MAE loss: 1.82\n",
            "===============================\n",
            "MAE:  1.7481804\n",
            "MdAE:  1.610388\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 0.95\n",
            "-\n",
            " Average eval MAE loss: 2.37\n",
            "===============================\n",
            "MAE:  2.103267\n",
            "MdAE:  1.7624068\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 0.83\n",
            "-\n",
            " Average eval MAE loss: 2.33\n",
            "===============================\n",
            "MAE:  2.125817\n",
            "MdAE:  1.6699114\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 0.81\n",
            "-\n",
            " Average eval MAE loss: 2.93\n",
            "===============================\n",
            "MAE:  2.419577\n",
            "MdAE:  2.019783\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 0.69\n",
            "-\n",
            " Average eval MAE loss: 2.21\n",
            "===============================\n",
            "MAE:  1.9409083\n",
            "MdAE:  1.3119583\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 0.69\n",
            "-\n",
            " Average eval MAE loss: 2.41\n",
            "===============================\n",
            "MAE:  2.1868887\n",
            "MdAE:  1.6737971\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 0.65\n",
            "-\n",
            " Average eval MAE loss: 2.06\n",
            "===============================\n",
            "MAE:  1.964919\n",
            "MdAE:  1.6592097\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 0.54\n",
            "-\n",
            " Average eval MAE loss: 2.09\n",
            "===============================\n",
            "MAE:  2.0139914\n",
            "MdAE:  1.6494422\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 0.45\n",
            "-\n",
            " Average eval MAE loss: 2.04\n",
            "===============================\n",
            "MAE:  1.9782747\n",
            "MdAE:  1.6123228\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d707fd40d9214188a27b7703267c0cc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>█▄▆▅▅▂▃▂▃▂▁▂▂▂▃▁▂▂▂▂</td></tr><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>█▃▅▅▅▃▃▃▃▁▁▁▃▂▄▂▃▂▂▂</td></tr><tr><td>test_MAE</td><td>█▃▆▅▄▃▃▃▃▂▁▁▂▂▃▂▂▂▂▂</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>1.61232</td></tr><tr><td>best_MAE</td><td>1.80497</td></tr><tr><td>best_MAE_train_time</td><td>114.38739</td></tr><tr><td>best_MdAE</td><td>1.4164</td></tr><tr><td>eval_loss</td><td>2.04347</td></tr><tr><td>test_MAE</td><td>1.97827</td></tr><tr><td>train_loss</td><td>0.44974</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gpt2sp_jirasoftware</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/wdib6hx6' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/wdib6hx6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240322_140244-wdib6hx6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all done for one project\n",
            "results have been written into a text file!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2SP were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### text : title+description\n",
            "Input data feed :::  [CLS]Report executor terminations to framework schedulers.[SEP]The Scheduler interface has a callback for executorLost, but currently it is never called.[SEP]\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "tensor([[   58,  5097,    50,    60, 19100,  3121,   273,  5651,   602,   284,\n",
            "          9355,  6038,   377,   364,  3693,  5188,    47,    60,   464, 27774,\n",
            "         18173,  7071,   468,   257, 23838,   329,  3121,   273, 31042,    11,\n",
            "           475,  3058,   340,   318,  1239,  1444,  3693,  5188,    47,    60,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60,    44,   274,   418, 11778,   815, 12940,\n",
            "          3121,   669,    58,  5188,    47,    60,   464, 11778,   815,   307,\n",
            "         23714,   546,   703,   340, 17105, 10427,   866,  3121,   669,    13,\n",
            "           220,   554,   674,  2858,    11,  3121,   669,  8365,  1487,   475,\n",
            "           262, 11778,   481,  1464,  2834,   340,   866,   422,  7692,  5572,\n",
            "         10652,    13,   220,   770,  7584, 38826,  5503,   319,   674,  5572,\n",
            "         10652, 23163,    11,   290,   318,   407, 30738,   284,  5322,  5572,\n",
            "         10652, 11500,  3693,  5188,    47,    60, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60,  3109,  3455,   309,  1921,    42,    62,\n",
            "          7708,  4146,  1961,  1738,   284, 15183, 19653,  3693,  5188,    47,\n",
            "            60,  1135,   783,   423,   257,  3275,  4731,  2641, 15941, 19580,\n",
            "           326,  3769,  1692, 31744,  1321,   546,   309,  1921,    42,    62,\n",
            "          7708,  4146,  1961,    13,   220,   220,   220,   632,   561,   307,\n",
            "           922,   284,   751,   617,  4645,   284,   262,  5287,  3840,    11,\n",
            "           329,  9355,  6038,   377,   364,   284,   719,   319,  1430, 49454,\n",
            "            13,   220,   220,   220,   412,    13,    70,    13,   220,   220,\n",
            "           220, 33829, 15941, 50015,  1391,   220,   220,   220,  7788,  2943,\n",
            "          3843,  1581,    62,    46,  2662,    26,   220,   220,   220,  7788],\n",
            "        [   58,  5097,    50,    60, 23410,  2049,  9355, 10143,   284,  1057,\n",
            "          2233,   284,  2089,  9701,    58,  5188,    47,    60,    40,  4099,\n",
            "           428,   468,   284,   466,   351,   262,  3452,  9701,  1006, 11218,\n",
            "            13,   220,   220,   220,   685,  7114,   375,    31,  5796, 16344,\n",
            "            12,    65,    74,    80,    12,  3070,    12, 27891,    19,  1382,\n",
            "            60,     3,   220, 21061, 10188,  7730,    62,    85,    28,    16,\n",
            "         24457,  8800,    14,  6880,   418,    12, 41989,    13,  1477,  1377,\n",
            "            70,  9288,    62, 24455,  2625,     9, 23410,  2049,     9,     1,\n",
            "          1377, 19011,   577,   220, 39410,    25,  5972,  2667,   878, 44707,\n",
            "         11708, 11187,  2667,  3419,   318,  3194,   284,  3563, 49643,   220],\n",
            "        [   58,  5097,    50,    60,  7583,  2198,   705, 18300,   814,  1377,\n",
            "         19509, 14269,  1377,   301,  1886,     6,   287,  1281,    12, 19023,\n",
            "            82,    13,  9078,  3693,  5188,    47,    60,  1135,  1459,  2198,\n",
            "           611,   345,   423,   597,  2458,   878,   356,  1057,  1281,    12,\n",
            "         19023,    82,    13,  9078,   475,   356,   836,   470,  2198,   329,\n",
            "         23393,  2458,   543,  2873,  9598,   714,   651,  2626,  3693,  5188,\n",
            "            47,    60, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
            "BATCH_SIZE :  20\n",
            "BATCH_SIZE :  20\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_att_mask = torch.tensor(tokens_test['attention_mask'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH_SIZE :  20\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp/wandb/run-20240322_140635-uy7glm55</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/uy7glm55' target=\"_blank\">gpt2sp_mesos</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/uy7glm55' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/uy7glm55</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training for  {'train': ['mesos'], 'test': ['mesos']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 6.53\n",
            "-\n",
            " Average eval MAE loss: 1.33\n",
            "===============================\n",
            "MAE:  1.2021842\n",
            "MdAE:  0.80338037\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 1.85\n",
            "-\n",
            " Average eval MAE loss: 1.85\n",
            "===============================\n",
            "MAE:  1.7155297\n",
            "MdAE:  1.7298281\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 1.76\n",
            "-\n",
            " Average eval MAE loss: 1.29\n",
            "===============================\n",
            "MAE:  1.1770154\n",
            "MdAE:  0.89032656\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 1.53\n",
            "-\n",
            " Average eval MAE loss: 1.31\n",
            "===============================\n",
            "MAE:  1.2837799\n",
            "MdAE:  0.98685676\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 1.38\n",
            "-\n",
            " Average eval MAE loss: 1.30\n",
            "===============================\n",
            "MAE:  1.283996\n",
            "MdAE:  0.9252076\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 1.30\n",
            "-\n",
            " Average eval MAE loss: 1.35\n",
            "===============================\n",
            "MAE:  1.3726785\n",
            "MdAE:  1.0448613\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 1.05\n",
            "-\n",
            " Average eval MAE loss: 1.24\n",
            "===============================\n",
            "MAE:  1.2506475\n",
            "MdAE:  0.95256406\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 1.05\n",
            "-\n",
            " Average eval MAE loss: 1.27\n",
            "===============================\n",
            "MAE:  1.2455422\n",
            "MdAE:  0.8732142\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 0.91\n",
            "-\n",
            " Average eval MAE loss: 1.40\n",
            "===============================\n",
            "MAE:  1.3929002\n",
            "MdAE:  0.89430577\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 0.78\n",
            "-\n",
            " Average eval MAE loss: 1.25\n",
            "===============================\n",
            "MAE:  1.1917002\n",
            "MdAE:  0.84559435\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 0.75\n",
            "-\n",
            " Average eval MAE loss: 1.47\n",
            "===============================\n",
            "MAE:  1.4413892\n",
            "MdAE:  0.9568282\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 0.68\n",
            "-\n",
            " Average eval MAE loss: 1.39\n",
            "===============================\n",
            "MAE:  1.3385851\n",
            "MdAE:  0.8757169\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 0.59\n",
            "-\n",
            " Average eval MAE loss: 1.38\n",
            "===============================\n",
            "MAE:  1.2991844\n",
            "MdAE:  0.93118334\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 0.59\n",
            "-\n",
            " Average eval MAE loss: 1.35\n",
            "===============================\n",
            "MAE:  1.2944527\n",
            "MdAE:  0.8663277\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 0.51\n",
            "-\n",
            " Average eval MAE loss: 1.41\n",
            "===============================\n",
            "MAE:  1.3340981\n",
            "MdAE:  0.92647856\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 0.48\n",
            "-\n",
            " Average eval MAE loss: 1.51\n",
            "===============================\n",
            "MAE:  1.4555092\n",
            "MdAE:  0.98747665\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 0.43\n",
            "-\n",
            " Average eval MAE loss: 1.41\n",
            "===============================\n",
            "MAE:  1.3177238\n",
            "MdAE:  0.9264857\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 0.39\n",
            "-\n",
            " Average eval MAE loss: 1.45\n",
            "===============================\n",
            "MAE:  1.3936886\n",
            "MdAE:  0.93843114\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 0.36\n",
            "-\n",
            " Average eval MAE loss: 1.42\n",
            "===============================\n",
            "MAE:  1.3284261\n",
            "MdAE:  0.94758856\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 0.35\n",
            "-\n",
            " Average eval MAE loss: 1.42\n",
            "===============================\n",
            "MAE:  1.3320578\n",
            "MdAE:  0.9618786\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1759f0c458324755b498fd3744ef3790",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>▁█▂▂▂▃▂▂▂▁▂▂▂▁▂▂▂▂▂▂</td></tr><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▂█▂▂▂▂▁▁▃▁▄▃▃▂▃▄▃▃▃▃</td></tr><tr><td>test_MAE</td><td>▁█▁▂▂▄▂▂▄▁▄▃▃▃▃▅▃▄▃▃</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>0.96188</td></tr><tr><td>best_MAE</td><td>1.25065</td></tr><tr><td>best_MAE_train_time</td><td>196.9433</td></tr><tr><td>best_MdAE</td><td>0.95256</td></tr><tr><td>eval_loss</td><td>1.42118</td></tr><tr><td>test_MAE</td><td>1.33206</td></tr><tr><td>train_loss</td><td>0.34619</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gpt2sp_mesos</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/uy7glm55' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/uy7glm55</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240322_140635-uy7glm55/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all done for one project\n",
            "results have been written into a text file!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2SP were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### text : title+description\n",
            "Input data feed :::  [CLS]Forum: Per-discussion subscription[SEP]I am finding that my inbox is absolutely flooded with unwanted moodle mails off the forum script. This is very annoying and I know it will similarly annoy my users. In fact it will put them off the system.    The problem arises because unlike other discussion boards moodle messages are emailed to me from the entire forum, not just the thread I have started or responded to. The overwhelming of people's inboxes is a serious business: it could be said that moodle is generating spam because the email feature is so unfocused.    Is there any chance this is going to be improved please?[SEP]\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "tensor([[   58,  5097,    50,    60,  1890,   388,    25,  2448,    12, 15410,\n",
            "         11956, 14569,    58,  5188,    47,    60,    40,   716,  4917,   326,\n",
            "           616, 13734,   318,  5543, 21050,   351, 19125, 10038,   293,   285,\n",
            "          1768,   572,   262, 10041,  4226,    13,   770,   318,   845, 15774,\n",
            "           290,   314,   760,   340,   481, 12470, 10072,   616,  2985,    13,\n",
            "           554,  1109,   340,   481,  1234,   606,   572,   262,  1080,    13,\n",
            "           220,   220,   220,   383,  1917, 22068,   780,  5023,   584,  5114,\n",
            "         11490, 10038,   293,  6218,   389, 24315,   284,   502,   422,   262,\n",
            "          2104, 10041,    11,   407,   655,   262,  4704,   314,   423,  2067,\n",
            "           393,  7082,   284,    13,   383,  9721,   286,   661,   338, 13734],\n",
            "        [   58,  5097,    50,    60,  1890,   388,    25, 14883,   416,   304,\n",
            "            12,  4529,    58,  5188,    47,    60,  2437,   546,   262,  2694,\n",
            "           284,  1281,   284,   262, 14216,  2884,  3053,    30,    58,  5188,\n",
            "            47,    60, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 12154,  7799,   284, 11986,  1728,  7032,\n",
            "           287,  6831,  3842,   355,  2672,    58,  5188,    47,    60,  2215,\n",
            "          4441,   257,  6831,    11,  1249,   262,  4701,   284, 11986,  1771,\n",
            "           257,  2214,  1276,   307,  5901,   287,   393,   407,  3693,  5188,\n",
            "            47,    60, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60,  1890,   388,    25,  5120,   284,  1306,\n",
            "          4704,  2792,    58,  5188,    47,    60,  5492,  1234,   257,  2792,\n",
            "           284,  4391,   284,   262,  1306,  4704,   287,   262, 10041,  7071,\n",
            "           986, 38592,   389,   845,  3608,   475,   262, 12660,  1429,   318,\n",
            "           640, 18587,   290,    11,   329,   257,  4701,    11,   640,   318,\n",
            "          2279,   618, 22232,  1802,    82,   286,  2444,   986,   220,   685,\n",
            "          5188,    47,    60, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60,    32,   779,  7034,   338,  1781,  1351,\n",
            "           318,  9277,  3093,  3614,   351,   645,   835,   286,  4379,  1844,\n",
            "          1351,    58,  5188,    47,    60,  2215, 11681,   257,  2836,   338,\n",
            "          7034,    11,   611,   262,  1351,   286,   511, 10902, 21695,  2310,\n",
            "           357,    40,   892,     8,   281, 30004,  2419,   271,   318,  9066,\n",
            "            13,   770,  2331,   257,  1643, 13894,   780,   986,   257,     8,\n",
            "           921,   460,   470,  3904,   319,   262, 30004,  2419,   271,   284,\n",
            "           766,   262,  1334,   286,   262, 10902,   275,     8,   383,  1351,\n",
            "          2125,   470,   772,   287,   435,   746, 33312,  1502,   523,   340,\n",
            "          4329,   772,   517, 14977,   269,     8,   262, 30004,  2419,   271]])\n",
            "BATCH_SIZE :  13\n",
            "BATCH_SIZE :  13\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_att_mask = torch.tensor(tokens_test['attention_mask'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH_SIZE :  13\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp/wandb/run-20240322_141635-u2p3jar9</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/u2p3jar9' target=\"_blank\">gpt2sp_moodle</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/u2p3jar9' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/u2p3jar9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training for  {'train': ['moodle'], 'test': ['moodle']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 16.43\n",
            "-\n",
            " Average eval MAE loss: 13.86\n",
            "===============================\n",
            "MAE:  10.913737\n",
            "MdAE:  9.815087\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 12.90\n",
            "-\n",
            " Average eval MAE loss: 14.61\n",
            "===============================\n",
            "MAE:  11.437588\n",
            "MdAE:  12.011488\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 12.55\n",
            "-\n",
            " Average eval MAE loss: 13.62\n",
            "===============================\n",
            "MAE:  6.844298\n",
            "MdAE:  5.927812\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 11.66\n",
            "-\n",
            " Average eval MAE loss: 14.24\n",
            "===============================\n",
            "MAE:  9.731143\n",
            "MdAE:  8.611148\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 10.29\n",
            "-\n",
            " Average eval MAE loss: 15.42\n",
            "===============================\n",
            "MAE:  13.706873\n",
            "MdAE:  12.270888\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 9.39\n",
            "-\n",
            " Average eval MAE loss: 14.18\n",
            "===============================\n",
            "MAE:  10.634279\n",
            "MdAE:  9.203393\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 8.41\n",
            "-\n",
            " Average eval MAE loss: 13.98\n",
            "===============================\n",
            "MAE:  9.921752\n",
            "MdAE:  6.268848\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 7.71\n",
            "-\n",
            " Average eval MAE loss: 13.44\n",
            "===============================\n",
            "MAE:  9.553426\n",
            "MdAE:  7.758059\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 6.55\n",
            "-\n",
            " Average eval MAE loss: 12.67\n",
            "===============================\n",
            "MAE:  7.863746\n",
            "MdAE:  6.442788\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 5.97\n",
            "-\n",
            " Average eval MAE loss: 12.51\n",
            "===============================\n",
            "MAE:  6.7756166\n",
            "MdAE:  4.543271\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 5.45\n",
            "-\n",
            " Average eval MAE loss: 12.53\n",
            "===============================\n",
            "MAE:  8.043584\n",
            "MdAE:  6.6917844\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 4.36\n",
            "-\n",
            " Average eval MAE loss: 12.77\n",
            "===============================\n",
            "MAE:  8.237423\n",
            "MdAE:  5.684823\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 3.27\n",
            "-\n",
            " Average eval MAE loss: 12.39\n",
            "===============================\n",
            "MAE:  7.369197\n",
            "MdAE:  5.5088634\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 2.99\n",
            "-\n",
            " Average eval MAE loss: 12.39\n",
            "===============================\n",
            "MAE:  6.7437224\n",
            "MdAE:  5.0218716\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 3.05\n",
            "-\n",
            " Average eval MAE loss: 12.52\n",
            "===============================\n",
            "MAE:  7.71936\n",
            "MdAE:  6.6168785\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 2.67\n",
            "-\n",
            " Average eval MAE loss: 12.57\n",
            "===============================\n",
            "MAE:  7.7029896\n",
            "MdAE:  5.963377\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 2.28\n",
            "-\n",
            " Average eval MAE loss: 12.60\n",
            "===============================\n",
            "MAE:  7.414385\n",
            "MdAE:  5.998882\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 2.23\n",
            "-\n",
            " Average eval MAE loss: 12.57\n",
            "===============================\n",
            "MAE:  6.8692355\n",
            "MdAE:  5.0272427\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 1.82\n",
            "-\n",
            " Average eval MAE loss: 12.44\n",
            "===============================\n",
            "MAE:  7.2483487\n",
            "MdAE:  5.3190103\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 1.75\n",
            "-\n",
            " Average eval MAE loss: 12.46\n",
            "===============================\n",
            "MAE:  7.531498\n",
            "MdAE:  5.7944736\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20fa29929dc04340b2c81750f4b0b5cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>▆█▂▅█▅▃▄▃▁▃▂▂▁▃▂▂▁▂▂</td></tr><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▄▆▄▅█▅▅▃▂▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>test_MAE</td><td>▅▆▁▄█▅▄▄▂▁▂▃▂▁▂▂▂▁▂▂</td></tr><tr><td>train_loss</td><td>█▆▆▆▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>5.79447</td></tr><tr><td>best_MAE</td><td>7.3692</td></tr><tr><td>best_MAE_train_time</td><td>283.67915</td></tr><tr><td>best_MdAE</td><td>5.50886</td></tr><tr><td>eval_loss</td><td>12.46396</td></tr><tr><td>test_MAE</td><td>7.5315</td></tr><tr><td>train_loss</td><td>1.74956</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gpt2sp_moodle</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/u2p3jar9' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/u2p3jar9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240322_141635-u2p3jar9/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all done for one project\n",
            "results have been written into a text file!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2SP were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### text : title+description\n",
            "Input data feed :::  [CLS]Implement true multicast functionality for <all> processor[SEP]Currently <all> processes messages sequentially. It could be an issue if message processors inside <all> take long time to respond (e.g. multiple request-response endpoints). We discussed it with MikeS and agreed that the behavior should be configurable (e.g. <all multicast=\"true\">) - if set to true, <all> will spawn multiple threads inside. If one of the MPs inside <all> throws an Exception, it should return MuleExceptionMessage which should be included in the response collection, then Exception Strategy should be invoked.  [SEP]\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "tensor([[   58,  5097,    50,    60,  3546, 26908,  2081, 47368,   459, 11244,\n",
            "           329,  1279,   439,    29, 12649,    58,  5188,    47,    60, 21327,\n",
            "          1279,   439,    29,  7767,  6218,  4726,  3746,    13,   632,   714,\n",
            "           307,   281,  2071,   611,  3275, 20399,  2641,  1279,   439,    29,\n",
            "          1011,   890,   640,   284,  3031,   357,    68,    13,    70,    13,\n",
            "          3294,  2581,    12, 26209,   886, 13033,   737,   775,  6693,   340,\n",
            "           351,  4995,    50,   290,  4987,   326,   262,  4069,   815,   307,\n",
            "          4566, 11970,   357,    68,    13,    70,    13,  1279,   439, 47368,\n",
            "           459,  2625,  7942,  5320,     8,   532,   611,   900,   284,  2081,\n",
            "            11,  1279,   439,    29,   481, 10922,  3294, 14390,  2641,    13],\n",
            "        [   58,  5097,    50,    60, 13921,   337,  2261,  1104,  1395,    32,\n",
            "          8611,   319,  1395,    32,  4133,   973,   416,   257,  8225,  2134,\n",
            "          7515,  5633,    58,  5188,    47,    60,  1722,   345,   815,   760,\n",
            "            11,   257,  2219,   779,  1339,   318,   262,  7696,  3912,  1058,\n",
            "           220,  1635,  1100,   257,  3275,   422,   281,   287,  7784, 36123,\n",
            "           357,  6738,   257,   449,  5653, 16834,   393,    14,   392,   257,\n",
            "          6831,   832, 28591,  2749,   737,   220,  1635,  3597,   262,  3275,\n",
            "           284,   281,   503,  7784, 36123,   357,  1462,   257,   449,  5653,\n",
            "         16834,   393,    14,   392,   257,  6831,   832, 28591,  2749,   737,\n",
            "           220,   220,   220,  1391,  8189,    25, 19875,    92,   220,   220],\n",
            "        [   58,  5097,    50,    60,   818,  9152, 21201,  8265,   287,   337,\n",
            "          2261,  4755,  6082,    58,  5188,    47,    60, 10161,   346, 10115,\n",
            "          2727,   257, 21201,  8265,    11,  1223,   326,   338,  4814,  2641,\n",
            "           285,  2261,    13,   220,   220,   220,  3254, 24765,  8265,  1104,\n",
            "          3170,    12,   259,  4938,  2024,    13,  4418,   340,  6971,  1180,\n",
            "          3858,   286, 13269,   329,  1123, 21201,  5086,   284,  7716,   257,\n",
            "          1180,  2882,   329,  1123,  1611,   286,  6631,    13,   220,   220,\n",
            "           220, 19937,    25,  2638,  1378,    76,  5028, 11205,    13, 12567,\n",
            "            13,   785,    14,    76,  2261,    12, 21412,    12, 12102,   341,\n",
            "            14,   220,   220,   220,   685,  5188,    47,    60, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 28446,    12, 17212,   815,   900,  6631,\n",
            "         21437,   351,   938,  6631,  2722,   878,  7216,   284, 23641,    48,\n",
            "            58,  5188,    47,    60,   464,  3670,  1139,   340,   477,   986,\n",
            "           220,  4091,   428,  4704,   329,  9984,    25,  2638,  1378, 27302,\n",
            "            13,    76,  5028, 11205,    13,  2398,    14,    76,  5028, 11205,\n",
            "            14,  4852,   873,    14, 28446,    62, 17212,    62,  1069, 11755,\n",
            "            62,  4993,  1359,   220,  2129,  8344,   378, 23641,    48,   357,\n",
            "         42813,  2205,  2458, 38381,  5188,    47,    60, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 28446,    12, 17212,   815,  1104, 18305,\n",
            "           516,   779,  2663,    58,  5188,    47,    60, 25153,   257,  2829,\n",
            "         18305,   516, 14626, 15741,   779,  1339,    11,   304,    13,    70,\n",
            "         11207,   220,   220,   220,  1279, 11125,    29,   220,   220,   220,\n",
            "           220,   220,  1279,  4023,    25,   259,  7784,    12,   437,  4122,\n",
            "           986, 15913,   220,   220,   220,   220,   220,  1279,  4023,    25,\n",
            "           448,  7784,    12,   437,  4122,   986, 15913,   220,  7359, 11125,\n",
            "            29,   220,   220,   220,  1002,   503,  7784, 36123,   318, 12908,\n",
            "           287,  1566,    12, 17212,    11,   262,  5202,  1839,   470,   670,\n",
            "          7471,    13,  1566,    12, 17212,  1276,  1104, 18305,   516, 13858]])\n",
            "BATCH_SIZE :  10\n",
            "BATCH_SIZE :  10\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_att_mask = torch.tensor(tokens_test['attention_mask'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH_SIZE :  10\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp/wandb/run-20240322_142417-e08l5q0u</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/e08l5q0u' target=\"_blank\">gpt2sp_mule</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/e08l5q0u' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/e08l5q0u</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training for  {'train': ['mule'], 'test': ['mule']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 6.57\n",
            "-\n",
            " Average eval MAE loss: 2.40\n",
            "===============================\n",
            "MAE:  2.5508451\n",
            "MdAE:  2.8049483\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 3.08\n",
            "-\n",
            " Average eval MAE loss: 4.38\n",
            "===============================\n",
            "MAE:  4.715927\n",
            "MdAE:  4.094591\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 3.27\n",
            "-\n",
            " Average eval MAE loss: 2.95\n",
            "===============================\n",
            "MAE:  3.243201\n",
            "MdAE:  3.106964\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 2.85\n",
            "-\n",
            " Average eval MAE loss: 2.84\n",
            "===============================\n",
            "MAE:  3.088597\n",
            "MdAE:  2.890365\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 2.42\n",
            "-\n",
            " Average eval MAE loss: 2.41\n",
            "===============================\n",
            "MAE:  2.4820774\n",
            "MdAE:  2.1987767\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 2.01\n",
            "-\n",
            " Average eval MAE loss: 2.48\n",
            "===============================\n",
            "MAE:  2.7579622\n",
            "MdAE:  2.3387482\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 1.60\n",
            "-\n",
            " Average eval MAE loss: 2.45\n",
            "===============================\n",
            "MAE:  2.756102\n",
            "MdAE:  2.1276588\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 1.40\n",
            "-\n",
            " Average eval MAE loss: 2.52\n",
            "===============================\n",
            "MAE:  2.8449125\n",
            "MdAE:  2.5792542\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 1.25\n",
            "-\n",
            " Average eval MAE loss: 2.67\n",
            "===============================\n",
            "MAE:  3.0328472\n",
            "MdAE:  2.5935059\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 1.16\n",
            "-\n",
            " Average eval MAE loss: 2.33\n",
            "===============================\n",
            "MAE:  2.6001346\n",
            "MdAE:  2.133744\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 1.13\n",
            "-\n",
            " Average eval MAE loss: 2.45\n",
            "===============================\n",
            "MAE:  2.799756\n",
            "MdAE:  2.472451\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 0.97\n",
            "-\n",
            " Average eval MAE loss: 2.42\n",
            "===============================\n",
            "MAE:  2.7000027\n",
            "MdAE:  2.2404122\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 0.86\n",
            "-\n",
            " Average eval MAE loss: 2.38\n",
            "===============================\n",
            "MAE:  2.6902761\n",
            "MdAE:  2.1943498\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 0.73\n",
            "-\n",
            " Average eval MAE loss: 2.43\n",
            "===============================\n",
            "MAE:  2.7535353\n",
            "MdAE:  2.2485452\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 0.67\n",
            "-\n",
            " Average eval MAE loss: 2.41\n",
            "===============================\n",
            "MAE:  2.7007887\n",
            "MdAE:  2.2683954\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 0.62\n",
            "-\n",
            " Average eval MAE loss: 2.41\n",
            "===============================\n",
            "MAE:  2.6931643\n",
            "MdAE:  2.2948723\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 0.53\n",
            "-\n",
            " Average eval MAE loss: 2.52\n",
            "===============================\n",
            "MAE:  2.8441787\n",
            "MdAE:  2.4061985\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 0.47\n",
            "-\n",
            " Average eval MAE loss: 2.40\n",
            "===============================\n",
            "MAE:  2.7217126\n",
            "MdAE:  2.2403808\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 0.47\n",
            "-\n",
            " Average eval MAE loss: 2.43\n",
            "===============================\n",
            "MAE:  2.7553387\n",
            "MdAE:  2.322926\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 0.43\n",
            "-\n",
            " Average eval MAE loss: 2.42\n",
            "===============================\n",
            "MAE:  2.745888\n",
            "MdAE:  2.3749206\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b274b038ec8b406b81b33b21eeac6246",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>▃█▄▄▁▂▁▃▃▁▂▁▁▁▂▂▂▁▂▂</td></tr><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁█▃▃▁▁▁▂▂▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>test_MAE</td><td>▁█▃▃▁▂▂▂▃▁▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>train_loss</td><td>█▄▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>2.37492</td></tr><tr><td>best_MAE</td><td>2.60013</td></tr><tr><td>best_MAE_train_time</td><td>173.59416</td></tr><tr><td>best_MdAE</td><td>2.13374</td></tr><tr><td>eval_loss</td><td>2.42202</td></tr><tr><td>test_MAE</td><td>2.74589</td></tr><tr><td>train_loss</td><td>0.43076</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gpt2sp_mule</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/e08l5q0u' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/e08l5q0u</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240322_142417-e08l5q0u/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all done for one project\n",
            "results have been written into a text file!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2SP were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### text : title+description\n",
            "Input data feed :::  [CLS]Support for request/reply[SEP]request/reply  http://www.mulesoft.org/documentation/display/current/Routing+Message+Processors#RoutingMessageProcessors-RequestReply  Mockups here: http://corp.wiki.mulesource.com/display/WP/Request-Reply#Request-Reply-Mockups [SEP]\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "tensor([[   58,  5097,    50,    60, 15514,   329,  2581,    14, 47768,    58,\n",
            "          5188,    47,    60, 25927,    14, 47768,   220,  2638,  1378,  2503,\n",
            "            13,    76,  5028, 11205,    13,  2398,    14, 22897,   341,    14,\n",
            "         13812,    14, 14421,    14,    49, 13660,    10, 12837,    10, 18709,\n",
            "           669,     2,    49, 13660, 12837, 18709,   669,    12, 18453, 36875,\n",
            "           220, 44123,  4739,   994,    25,  2638,  1378, 10215,    79,    13,\n",
            "         15466,    13,    76,  5028,  1668,    13,   785,    14, 13812,    14,\n",
            "         25527,    14, 18453,    12, 36875,     2, 18453,    12, 36875,    12,\n",
            "            44,   735,  4739,   685,  5188,    47,    60, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60,    34, 34574,  1330,   257, 11733,  1628,\n",
            "           422, 15151,  1231,  8563,    58,  5188,    47,    60,  8600,    82,\n",
            "           284, 22919,    25,   220,   220,   220,   352,    13, 13610,   257,\n",
            "          2829,   337,  2261, 11733,  1628,   357,  1640,  4554,    25,   262,\n",
            "         21455,  1672,     8,   220,   362,    13, 23691,   340,   656, 21722,\n",
            "            11,  2834,    14, 21018,   262, 16099,   656,   534,  1957,  4554,\n",
            "           220,   513,    13,  4946,   510,   257,  4508,   649, 44573,   220,\n",
            "           604,    13,   402,  2069, 17267,    14,    38,   270,    14, 16775,\n",
            "            82,   422, 15151,   220,   642,    13,  9683,   262,  1957,  4866,\n",
            "           286,   534, 21722, 16099,   220,   718,    13,  9683,  1330,  4683],\n",
            "        [   58,  5097,    50,    60, 29238,   284,  7349,  2438,   466,   407,\n",
            "           651,  3024, 12380,    58,  5188,    47,    60, 29584,  2723,  2458,\n",
            "           836,   470,   651,  6497,   510,   826,   783,  6338,   357,  3826,\n",
            "         49348,  9399,    12, 36626,     8,  2158,    11,   772,   611,   257,\n",
            "         21459,  1420,   318, 13973,   262,  3452, 20129,  2458,   389,   407,\n",
            "         12380,    58,  5188,    47,    60, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60,  3118,   540,   284,   751,   257,  2882,\n",
            "           618,  4441,   257,  1218,  5202,   287,   262,   976,   285, 11125,\n",
            "            58,  5188,    47,    60,  3118,   540,   284,   751,   257,  2882,\n",
            "           618,  4441,   257,  1218,  5202,    13,   220,   220,   220, 32144,\n",
            "           284, 22919,    25,   220,   220,   220,   352,     8,  4946, 11733,\n",
            "           290,  2251,   257,  1628,   422,   281,  4683, 11055,    25,  8284,\n",
            "          8444,  6828,    13,   220,   362,     8,   554,   326,   976,   285,\n",
            "         11125,  2393,  2251,  1194,  5202,    13, 12697,   290,  4268, 14626,\n",
            "           371,    48,    12,  6998,    11,  9809,    11,  5202,  4941,    11,\n",
            "          1439, 20264,   290,  7515,    11,  9809,   290,  2393,    11,   788],\n",
            "        [   58,  5097,    50,    60, 28531, 43076,   287,   262, 23735,  1570,\n",
            "           389,   407,   852,  4615,   618,   345,  4781,   477,   262,  4847,\n",
            "           286,   257,  1611,    58,  5188,    47,    60,  2215,   345,   751,\n",
            "           281,  5002,   290,   788,   345,  4781,   340,    11,   262,  4941,\n",
            "           284,   262, 32815,  2393,   318,   407,   852,  4615,   422,   262,\n",
            "         23735,  3891, 43076,    13,   220,   220,   220,   220,   220, 32144,\n",
            "           284, 22919,    25,   220,   220,   352,  7874, 13610,   257,  1628,\n",
            "           287, 11733,   351,   257,  5202,   287,   340,   290,   467,   284,\n",
            "           262,  8060, 26632,  7400,    13,   220,   220,   362,  7874,  3060,\n",
            "           329,  1672,   257,  3298, 19013,   774, 36123,   351,   262,  4277]])\n",
            "BATCH_SIZE :  8\n",
            "BATCH_SIZE :  8\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_att_mask = torch.tensor(tokens_test['attention_mask'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH_SIZE :  8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp/wandb/run-20240322_143031-e376wpif</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/e376wpif' target=\"_blank\">gpt2sp_mulestudio</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/e376wpif' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/e376wpif</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training for  {'train': ['mulestudio'], 'test': ['mulestudio']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 10.18\n",
            "-\n",
            " Average eval MAE loss: 4.83\n",
            "===============================\n",
            "MAE:  3.9201427\n",
            "MdAE:  3.175129\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 3.21\n",
            "-\n",
            " Average eval MAE loss: 4.87\n",
            "===============================\n",
            "MAE:  3.6713684\n",
            "MdAE:  2.6038923\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 2.92\n",
            "-\n",
            " Average eval MAE loss: 5.07\n",
            "===============================\n",
            "MAE:  3.8498793\n",
            "MdAE:  3.3527303\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 2.75\n",
            "-\n",
            " Average eval MAE loss: 4.70\n",
            "===============================\n",
            "MAE:  3.9232345\n",
            "MdAE:  2.9503412\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 2.59\n",
            "-\n",
            " Average eval MAE loss: 5.26\n",
            "===============================\n",
            "MAE:  4.299011\n",
            "MdAE:  3.0790129\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 2.42\n",
            "-\n",
            " Average eval MAE loss: 5.18\n",
            "===============================\n",
            "MAE:  4.6006665\n",
            "MdAE:  3.3923762\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 2.01\n",
            "-\n",
            " Average eval MAE loss: 5.23\n",
            "===============================\n",
            "MAE:  4.0784574\n",
            "MdAE:  3.0961561\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 1.83\n",
            "-\n",
            " Average eval MAE loss: 5.11\n",
            "===============================\n",
            "MAE:  4.1765037\n",
            "MdAE:  2.9374743\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 1.74\n",
            "-\n",
            " Average eval MAE loss: 4.90\n",
            "===============================\n",
            "MAE:  4.094881\n",
            "MdAE:  3.2195086\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 1.58\n",
            "-\n",
            " Average eval MAE loss: 5.31\n",
            "===============================\n",
            "MAE:  4.256933\n",
            "MdAE:  3.0581443\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 1.60\n",
            "-\n",
            " Average eval MAE loss: 5.10\n",
            "===============================\n",
            "MAE:  4.105127\n",
            "MdAE:  2.9112856\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 1.38\n",
            "-\n",
            " Average eval MAE loss: 5.30\n",
            "===============================\n",
            "MAE:  4.0075636\n",
            "MdAE:  3.0831175\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 1.18\n",
            "-\n",
            " Average eval MAE loss: 5.04\n",
            "===============================\n",
            "MAE:  3.9699554\n",
            "MdAE:  2.9051886\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 1.13\n",
            "-\n",
            " Average eval MAE loss: 4.98\n",
            "===============================\n",
            "MAE:  3.8839006\n",
            "MdAE:  2.7738848\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 1.14\n",
            "-\n",
            " Average eval MAE loss: 5.01\n",
            "===============================\n",
            "MAE:  3.9765356\n",
            "MdAE:  2.982388\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 1.00\n",
            "-\n",
            " Average eval MAE loss: 4.96\n",
            "===============================\n",
            "MAE:  3.9480457\n",
            "MdAE:  2.7056665\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 0.82\n",
            "-\n",
            " Average eval MAE loss: 4.99\n",
            "===============================\n",
            "MAE:  3.8803124\n",
            "MdAE:  2.5948644\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 0.87\n",
            "-\n",
            " Average eval MAE loss: 5.03\n",
            "===============================\n",
            "MAE:  3.9735453\n",
            "MdAE:  2.7013302\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 0.77\n",
            "-\n",
            " Average eval MAE loss: 4.91\n",
            "===============================\n",
            "MAE:  3.865217\n",
            "MdAE:  2.5552359\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 0.64\n",
            "-\n",
            " Average eval MAE loss: 4.92\n",
            "===============================\n",
            "MAE:  3.8383985\n",
            "MdAE:  2.7712765\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd4472bcc9404363ab96d2759f9cb8c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>▆▁█▄▅█▆▄▇▅▄▅▄▃▅▂▁▂▁▃</td></tr><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▃▃▅▁▇▆▇▆▃█▆█▅▄▅▄▄▅▃▄</td></tr><tr><td>test_MAE</td><td>▃▁▂▃▆█▄▅▄▅▄▄▃▃▃▃▃▃▂▂</td></tr><tr><td>train_loss</td><td>█▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>2.77128</td></tr><tr><td>best_MAE</td><td>3.92323</td></tr><tr><td>best_MAE_train_time</td><td>56.72602</td></tr><tr><td>best_MdAE</td><td>2.95034</td></tr><tr><td>eval_loss</td><td>4.92259</td></tr><tr><td>test_MAE</td><td>3.8384</td></tr><tr><td>train_loss</td><td>0.64341</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gpt2sp_mulestudio</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/e376wpif' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/e376wpif</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240322_143031-e376wpif/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all done for one project\n",
            "results have been written into a text file!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2SP were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### text : title+description\n",
            "Input data feed :::  [CLS]HDFS ItemWriter[SEP]Base integration of core HDFS writer functionality with Spring Batch.[SEP]\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "tensor([[   58,  5097,    50,    60,    39,  8068,    50,  9097, 34379,    58,\n",
            "          5188,    47,    60, 14881, 11812,   286,  4755,  5572, 10652,  6260,\n",
            "         11244,   351,  8225,   347,   963,  3693,  5188,    47,    60, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60,    39,  8068,    50,  7231,  3597, 31904,\n",
            "          6097,    58,  5188,    47,    60, 26437,  2393,  6260,   326,   468,\n",
            "         11196,   287,   262,  6076,   550, 11224,  8405,  3693,  5188,    47,\n",
            "            60, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 29239, 33432,    58,  5188,    47,    60,\n",
            "           685,  5188,    47,    60, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60,    51, 29291,  1366,  4645,    58,  5188,\n",
            "            47,    60,   464, 46545,  1366,  4645,   815,   307, 19528, 11670,\n",
            "           287, 11244,   329,   779,   287,  6076, 15458,    13,   220,  4347,\n",
            "           278,   625,  7663,  7248,  5254,   287,  6076, 15458,   284,   779,\n",
            "           262, 46545,  1366,  4645,   318,   530,   835,  1037,  4155,   326,\n",
            "         17764,  3693,  5188,    47,    60, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 44387,  6404,   554,  3495,   295,    58,\n",
            "          5188,    47,    60, 11980,   257, 25064,  6404,    13, 19875,  4566,\n",
            "          2393,   326,   460,   307,  2087,   284,   257,  8265,   290,  6823,\n",
            "           351,   257,  8265, 20478,  3693,  5188,    47,    60, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
            "BATCH_SIZE :  42\n",
            "BATCH_SIZE :  42\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_att_mask = torch.tensor(tokens_test['attention_mask'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH_SIZE :  42\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp/wandb/run-20240322_143604-rn0lm10t</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/rn0lm10t' target=\"_blank\">gpt2sp_springxd</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/rn0lm10t' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/rn0lm10t</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training for  {'train': ['springxd'], 'test': ['springxd']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 10.41\n",
            "-\n",
            " Average eval MAE loss: 2.15\n",
            "===============================\n",
            "MAE:  2.1101525\n",
            "MdAE:  1.8443364\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 2.28\n",
            "-\n",
            " Average eval MAE loss: 1.83\n",
            "===============================\n",
            "MAE:  1.6633246\n",
            "MdAE:  1.2380544\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 2.00\n",
            "-\n",
            " Average eval MAE loss: 1.90\n",
            "===============================\n",
            "MAE:  1.7260423\n",
            "MdAE:  1.0984745\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 1.73\n",
            "-\n",
            " Average eval MAE loss: 1.97\n",
            "===============================\n",
            "MAE:  1.9000632\n",
            "MdAE:  1.4826727\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 1.54\n",
            "-\n",
            " Average eval MAE loss: 1.92\n",
            "===============================\n",
            "MAE:  1.784901\n",
            "MdAE:  1.2570349\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 1.36\n",
            "-\n",
            " Average eval MAE loss: 1.98\n",
            "===============================\n",
            "MAE:  1.9474103\n",
            "MdAE:  1.4716427\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 1.26\n",
            "-\n",
            " Average eval MAE loss: 1.74\n",
            "===============================\n",
            "MAE:  1.7237223\n",
            "MdAE:  1.2824744\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 1.13\n",
            "-\n",
            " Average eval MAE loss: 1.88\n",
            "===============================\n",
            "MAE:  2.041784\n",
            "MdAE:  1.6083336\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 1.00\n",
            "-\n",
            " Average eval MAE loss: 1.90\n",
            "===============================\n",
            "MAE:  1.9265109\n",
            "MdAE:  1.1991231\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 0.95\n",
            "-\n",
            " Average eval MAE loss: 1.68\n",
            "===============================\n",
            "MAE:  1.6714704\n",
            "MdAE:  1.2633488\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 0.87\n",
            "-\n",
            " Average eval MAE loss: 1.72\n",
            "===============================\n",
            "MAE:  1.7295164\n",
            "MdAE:  1.2768629\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 0.82\n",
            "-\n",
            " Average eval MAE loss: 1.89\n",
            "===============================\n",
            "MAE:  1.9500321\n",
            "MdAE:  1.5488046\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 0.73\n",
            "-\n",
            " Average eval MAE loss: 1.87\n",
            "===============================\n",
            "MAE:  1.9703066\n",
            "MdAE:  1.4990243\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 0.68\n",
            "-\n",
            " Average eval MAE loss: 1.83\n",
            "===============================\n",
            "MAE:  1.9004356\n",
            "MdAE:  1.4832205\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 0.62\n",
            "-\n",
            " Average eval MAE loss: 2.01\n",
            "===============================\n",
            "MAE:  2.0615373\n",
            "MdAE:  1.4446007\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 0.59\n",
            "-\n",
            " Average eval MAE loss: 1.95\n",
            "===============================\n",
            "MAE:  2.0291922\n",
            "MdAE:  1.5112481\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 0.57\n",
            "-\n",
            " Average eval MAE loss: 1.88\n",
            "===============================\n",
            "MAE:  1.8931339\n",
            "MdAE:  1.3579926\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 0.52\n",
            "-\n",
            " Average eval MAE loss: 1.92\n",
            "===============================\n",
            "MAE:  1.9721825\n",
            "MdAE:  1.4861162\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 0.49\n",
            "-\n",
            " Average eval MAE loss: 1.89\n",
            "===============================\n",
            "MAE:  1.9277143\n",
            "MdAE:  1.4012682\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 0.47\n",
            "-\n",
            " Average eval MAE loss: 1.89\n",
            "===============================\n",
            "MAE:  1.9248426\n",
            "MdAE:  1.4072798\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "973b5b6999354e46b719446124d953b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>█▂▁▅▂▅▃▆▂▃▃▅▅▅▄▅▃▅▄▄</td></tr><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>█▃▄▅▅▆▂▄▄▁▂▄▄▃▆▅▄▅▄▄</td></tr><tr><td>test_MAE</td><td>█▁▂▅▃▅▂▇▅▁▂▅▆▅▇▇▅▆▅▅</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>1.40728</td></tr><tr><td>best_MAE</td><td>1.67147</td></tr><tr><td>best_MAE_train_time</td><td>520.46429</td></tr><tr><td>best_MdAE</td><td>1.26335</td></tr><tr><td>eval_loss</td><td>1.88598</td></tr><tr><td>test_MAE</td><td>1.92484</td></tr><tr><td>train_loss</td><td>0.47069</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gpt2sp_springxd</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/rn0lm10t' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/rn0lm10t</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240322_143604-rn0lm10t/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all done for one project\n",
            "results have been written into a text file!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2SP were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### text : title+description\n",
            "Input data feed :::  [CLS]SQL Server Single Sign On Support doesn't work in data profiler repository connections[SEP]In the data profiler perspective, you can't use the Single Sign on libraries to connect to SQL Server, even if the library is loaded.  We've used the Single Sign On capabilities in the job designer and haven't had any issues running jobs, using the data viewer, etc; however, when you switch to the data profiler, the connection returns that the library isn't loaded, and to check the java.library.path system property - which has the values appropriate for the library.  Everyone has installed the dll from the jtds project in their library paths.[SEP]\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "tensor([[   58,  5097,    50,    60, 17861,  9652, 14206,  5865,  1550,  7929,\n",
            "          1595,   470,   670,   287,  1366,  1534,  5329, 16099,  8787,    58,\n",
            "          5188,    47,    60,   818,   262,  1366,  1534,  5329,  6650,    11,\n",
            "           345,   460,   470,   779,   262, 14206,  5865,   319, 12782,   284,\n",
            "          2018,   284, 16363,  9652,    11,   772,   611,   262,  5888,   318,\n",
            "          9639,    13,   220,   775,  1053,   973,   262, 14206,  5865,  1550,\n",
            "          9889,   287,   262,  1693, 11915,   290,  4398,   470,   550,   597,\n",
            "          2428,  2491,  3946,    11,  1262,   262,  1366, 19091,    11,  3503,\n",
            "            26,  2158,    11,   618,   345,  5078,   284,   262,  1366,  1534,\n",
            "          5329,    11,   262,  4637,  5860,   326,   262,  5888,  2125,   470],\n",
            "        [   58,  5097,    50,    60, 27914,   734, 15180,   287,  8373,  8893,\n",
            "            58,  5188,    47,    60,   259,   262,   366,    65,   486,    62,\n",
            "         28665,    62, 35487,    13,    73,    81, 19875,     1,   989,    11,\n",
            "          8373,  8893,  1276,   407,   423,   262,  1708, 15180,    25,   220,\n",
            "           220,   366, 12115,  2149, 25633,  7477,     1,   290,   366, 12115,\n",
            "          2149, 25633, 19878,    34,  7477,     1,   220,   220,   220,  4091,\n",
            "         22032,    13,   220,   220,   220,   220, 16926,    46,    25,  4781,\n",
            "           777, 15180,   287,   477,  1611,   286,  8373,  3084,  3693,  5188,\n",
            "            47,    60, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 32048,  3781,  1058,  1321,    62, 15952,\n",
            "          2611,    58,  5188,    47,    60,  2215,   345,  2251,   281,  4637,\n",
            "          3781,   319, 48761,    11,   345,   460, 19818,  4175,   602,   422,\n",
            "           477, 20083,  2845,  1321,    62, 15952,  2611,   810,  1366,   389,\n",
            "           657,   393, 11013,    45,    13,   220,   220,   220,   887,  1312,\n",
            "           423,  8893,   290,  1366,   287,   428, 32815,    58,  5188,    47,\n",
            "            60, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 48101,  3781, 21337,   389,   366,  2164,\n",
            "         16548,   503,     1,   290,  2314,   307,   973,    58,  5188,    47,\n",
            "            60,  2215,  9361,   284, 16602, 20137,    17,  3084, 15180,    11,\n",
            "           407,   477,  3781, 21337,   389,  1695,    58,  5188,    47,    60,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50, 30866,  7680, 12515, 15274,     1,  6859,   857,\n",
            "           407,  3359,   319,   257,  3084,  3781,   357,  4480,   360,    48,\n",
            "         14330, 38381,  5188,    47,    60,  1532,   262,   360,    48, 14330,\n",
            "           468,   257,   366, 22179,  4006,  1600,   340,   318,  5340,   284,\n",
            "          1570,   262,   366,   259, 12102, 15274,     1,   422,   262,  3781,\n",
            "          2482,    25,   262,  3038,   318,   407,  9066,    13,   220,   220,\n",
            "           220,  4091,   262,  3159, 23007,  3693,  5188,    47,    60, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
            "BATCH_SIZE :  16\n",
            "BATCH_SIZE :  16\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_att_mask = torch.tensor(tokens_test['attention_mask'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH_SIZE :  16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp/wandb/run-20240322_145407-ssyna508</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/ssyna508' target=\"_blank\">gpt2sp_talenddataquality</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/ssyna508' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/ssyna508</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training for  {'train': ['talenddataquality'], 'test': ['talenddataquality']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 7.75\n",
            "-\n",
            " Average eval MAE loss: 4.29\n",
            "===============================\n",
            "MAE:  5.186439\n",
            "MdAE:  5.608237\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 4.40\n",
            "-\n",
            " Average eval MAE loss: 4.15\n",
            "===============================\n",
            "MAE:  4.676966\n",
            "MdAE:  5.025527\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 3.91\n",
            "-\n",
            " Average eval MAE loss: 3.46\n",
            "===============================\n",
            "MAE:  3.1610045\n",
            "MdAE:  3.0365925\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 3.36\n",
            "-\n",
            " Average eval MAE loss: 3.55\n",
            "===============================\n",
            "MAE:  3.912202\n",
            "MdAE:  3.890399\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 2.89\n",
            "-\n",
            " Average eval MAE loss: 3.41\n",
            "===============================\n",
            "MAE:  3.5511289\n",
            "MdAE:  3.1218414\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 2.50\n",
            "-\n",
            " Average eval MAE loss: 3.39\n",
            "===============================\n",
            "MAE:  3.1348903\n",
            "MdAE:  2.7338758\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 2.19\n",
            "-\n",
            " Average eval MAE loss: 4.20\n",
            "===============================\n",
            "MAE:  4.80862\n",
            "MdAE:  4.1552258\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 1.99\n",
            "-\n",
            " Average eval MAE loss: 3.45\n",
            "===============================\n",
            "MAE:  3.7214162\n",
            "MdAE:  3.1205373\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 1.74\n",
            "-\n",
            " Average eval MAE loss: 3.41\n",
            "===============================\n",
            "MAE:  3.4037263\n",
            "MdAE:  2.8176508\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 1.54\n",
            "-\n",
            " Average eval MAE loss: 3.55\n",
            "===============================\n",
            "MAE:  3.7958543\n",
            "MdAE:  3.3840957\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 1.44\n",
            "-\n",
            " Average eval MAE loss: 3.44\n",
            "===============================\n",
            "MAE:  3.6017683\n",
            "MdAE:  3.2124796\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 1.35\n",
            "-\n",
            " Average eval MAE loss: 3.53\n",
            "===============================\n",
            "MAE:  3.8172493\n",
            "MdAE:  3.4434395\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 1.23\n",
            "-\n",
            " Average eval MAE loss: 3.40\n",
            "===============================\n",
            "MAE:  3.179572\n",
            "MdAE:  2.5333576\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 1.22\n",
            "-\n",
            " Average eval MAE loss: 3.54\n",
            "===============================\n",
            "MAE:  3.4770596\n",
            "MdAE:  2.867043\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 1.11\n",
            "-\n",
            " Average eval MAE loss: 3.80\n",
            "===============================\n",
            "MAE:  4.493648\n",
            "MdAE:  4.27974\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 1.10\n",
            "-\n",
            " Average eval MAE loss: 3.59\n",
            "===============================\n",
            "MAE:  3.9050786\n",
            "MdAE:  3.5456924\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 0.93\n",
            "-\n",
            " Average eval MAE loss: 3.63\n",
            "===============================\n",
            "MAE:  3.9410505\n",
            "MdAE:  3.5031095\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 0.93\n",
            "-\n",
            " Average eval MAE loss: 3.59\n",
            "===============================\n",
            "MAE:  3.721072\n",
            "MdAE:  3.1881032\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 0.91\n",
            "-\n",
            " Average eval MAE loss: 3.58\n",
            "===============================\n",
            "MAE:  3.8100877\n",
            "MdAE:  3.3759313\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 0.82\n",
            "-\n",
            " Average eval MAE loss: 3.53\n",
            "===============================\n",
            "MAE:  3.5984697\n",
            "MdAE:  3.1434126\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2b0b90e1f674cf691cebfda537c127c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>█▇▂▄▂▁▅▂▂▃▃▃▁▂▅▃▃▂▃▂</td></tr><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>█▇▂▂▁▁▇▂▁▂▁▂▁▂▄▃▃▃▃▂</td></tr><tr><td>test_MAE</td><td>█▆▁▄▂▁▇▃▂▃▃▃▁▂▆▄▄▃▃▃</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>3.14341</td></tr><tr><td>best_MAE</td><td>3.13489</td></tr><tr><td>best_MAE_train_time</td><td>141.98563</td></tr><tr><td>best_MdAE</td><td>2.73388</td></tr><tr><td>eval_loss</td><td>3.53252</td></tr><tr><td>test_MAE</td><td>3.59847</td></tr><tr><td>train_loss</td><td>0.82104</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gpt2sp_talenddataquality</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/ssyna508' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/ssyna508</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240322_145407-ssyna508/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all done for one project\n",
            "results have been written into a text file!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2SP were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### text : title+description\n",
            "Input data feed :::  [CLS]Investigation: S1 Improved user experience with TOS/TIS/ESB Studio[SEP] [SEP]\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "tensor([[   58,  5097,    50,    60, 19070,  7065,    25,   311,    16, 24125,\n",
            "          2836,  1998,   351,   309,  2640,    14,    51,  1797,    14,  1546,\n",
            "            33, 11733,    58,  5188,    47,    60,   685,  5188,    47,    60,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 19070, 10055,    25,   311,    17,  7320,\n",
            "          4809, 46333,   290, 10131,  9352,   287,   309,  2640,    14,    51,\n",
            "          1797,    14, 41501,    58,  5188,    47,    60,   685,  5188,    47,\n",
            "            60, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 19070, 10055,    25,   311,    18, 24125,\n",
            "         23735,  6060, 49500, 36109,   287,   309,  2640,    14,    51,  1797,\n",
            "            14, 41501,    58,  5188,    47,    60,   685,  5188,    47,    60,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 19070, 10055,    25,   311,    22,   309,\n",
            "          1797, 11923,    87,  1912,   319,   262,  4809, 19239,    58,  5188,\n",
            "            47,    60,   685,  5188,    47,    60, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 19070, 10055,    25, 33084, 13472,   649,\n",
            "          6443,   290,  6459,    58,  5188,    47,    60,   685,  5188,    47,\n",
            "            60, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
            "BATCH_SIZE :  10\n",
            "BATCH_SIZE :  10\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_att_mask = torch.tensor(tokens_test['attention_mask'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH_SIZE :  10\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp/wandb/run-20240322_150233-0seftyeo</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/0seftyeo' target=\"_blank\">gpt2sp_talendesb</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/0seftyeo' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/0seftyeo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training for  {'train': ['talendesb'], 'test': ['talendesb']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 6.70\n",
            "-\n",
            " Average eval MAE loss: 1.01\n",
            "===============================\n",
            "MAE:  0.96066827\n",
            "MdAE:  1.0148021\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 1.53\n",
            "-\n",
            " Average eval MAE loss: 0.97\n",
            "===============================\n",
            "MAE:  0.9220787\n",
            "MdAE:  0.9164808\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 1.20\n",
            "-\n",
            " Average eval MAE loss: 1.12\n",
            "===============================\n",
            "MAE:  1.0506918\n",
            "MdAE:  1.0781603\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 1.03\n",
            "-\n",
            " Average eval MAE loss: 1.28\n",
            "===============================\n",
            "MAE:  1.2607213\n",
            "MdAE:  1.0283798\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 0.88\n",
            "-\n",
            " Average eval MAE loss: 1.11\n",
            "===============================\n",
            "MAE:  1.0275551\n",
            "MdAE:  0.72506404\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 0.78\n",
            "-\n",
            " Average eval MAE loss: 1.18\n",
            "===============================\n",
            "MAE:  1.1310639\n",
            "MdAE:  0.8511062\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 0.71\n",
            "-\n",
            " Average eval MAE loss: 1.00\n",
            "===============================\n",
            "MAE:  0.92070305\n",
            "MdAE:  0.6752168\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 0.59\n",
            "-\n",
            " Average eval MAE loss: 1.01\n",
            "===============================\n",
            "MAE:  0.9030311\n",
            "MdAE:  0.6464143\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 0.52\n",
            "-\n",
            " Average eval MAE loss: 1.02\n",
            "===============================\n",
            "MAE:  0.9526746\n",
            "MdAE:  0.70691013\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 0.50\n",
            "-\n",
            " Average eval MAE loss: 0.98\n",
            "===============================\n",
            "MAE:  0.9375114\n",
            "MdAE:  0.68039495\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 0.43\n",
            "-\n",
            " Average eval MAE loss: 1.03\n",
            "===============================\n",
            "MAE:  0.9976477\n",
            "MdAE:  0.8028145\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 0.38\n",
            "-\n",
            " Average eval MAE loss: 0.97\n",
            "===============================\n",
            "MAE:  0.9113203\n",
            "MdAE:  0.66631144\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 0.35\n",
            "-\n",
            " Average eval MAE loss: 0.95\n",
            "===============================\n",
            "MAE:  0.8764356\n",
            "MdAE:  0.7402255\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 0.31\n",
            "-\n",
            " Average eval MAE loss: 1.00\n",
            "===============================\n",
            "MAE:  0.9456971\n",
            "MdAE:  0.7560814\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 0.28\n",
            "-\n",
            " Average eval MAE loss: 0.94\n",
            "===============================\n",
            "MAE:  0.9251232\n",
            "MdAE:  0.78800285\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 0.26\n",
            "-\n",
            " Average eval MAE loss: 0.96\n",
            "===============================\n",
            "MAE:  0.92256886\n",
            "MdAE:  0.78688574\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 0.22\n",
            "-\n",
            " Average eval MAE loss: 0.94\n",
            "===============================\n",
            "MAE:  0.90866697\n",
            "MdAE:  0.75203794\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 0.20\n",
            "-\n",
            " Average eval MAE loss: 0.93\n",
            "===============================\n",
            "MAE:  0.8881155\n",
            "MdAE:  0.7155863\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 0.18\n",
            "-\n",
            " Average eval MAE loss: 0.93\n",
            "===============================\n",
            "MAE:  0.8889218\n",
            "MdAE:  0.7262532\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 0.17\n",
            "-\n",
            " Average eval MAE loss: 0.93\n",
            "===============================\n",
            "MAE:  0.89144653\n",
            "MdAE:  0.737191\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c8d98fd49094961955b4a003ef23f36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>▇▅█▇▂▄▁▁▂▂▄▁▃▃▃▃▃▂▂▂</td></tr><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▃▂▅█▅▆▃▃▃▂▃▂▁▂▁▂▁▁▁▁</td></tr><tr><td>test_MAE</td><td>▃▂▄█▄▆▂▁▂▂▃▂▁▂▂▂▂▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>0.73719</td></tr><tr><td>best_MAE</td><td>0.88892</td></tr><tr><td>best_MAE_train_time</td><td>333.7219</td></tr><tr><td>best_MdAE</td><td>0.72625</td></tr><tr><td>eval_loss</td><td>0.93013</td></tr><tr><td>test_MAE</td><td>0.89145</td></tr><tr><td>train_loss</td><td>0.16961</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gpt2sp_talendesb</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/0seftyeo' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/0seftyeo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240322_150233-0seftyeo/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all done for one project\n",
            "results have been written into a text file!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2SP were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### text : title+description\n",
            "Input data feed :::  [CLS]Android: While debugger is running, cannot back out and go back into an app[SEP]If you debug an Android app, you can't back out of that app and go back into it.  It hangs then at the splash screen, and shows both \"Bad Socket\" and \"Connection Refused\" errors in logcat.    Logcat:    [https://gist.github.com/43b1285ca8743eaaf672]    Screencast:    [http://screencast.com/t/m0C2c9Ojxo]  [SEP]\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "tensor([[   58,  5097,    50,    60, 25934,    25,  2893, 49518,   318,  2491,\n",
            "            11,  2314,   736,   503,   290,   467,   736,   656,   281,   598,\n",
            "            58,  5188,    47,    60,  1532,   345, 14257,   281,  5565,   598,\n",
            "            11,   345,   460,   470,   736,   503,   286,   326,   598,   290,\n",
            "           467,   736,   656,   340,    13,   220,   632, 28087,   788,   379,\n",
            "           262, 22870,  3159,    11,   290,  2523,  1111,   366, 22069, 47068,\n",
            "             1,   290,   366, 32048,  6524,  1484,     1,  8563,   287,  2604,\n",
            "          9246,    13,   220,   220,   220,  5972,  9246,    25,   220,   220,\n",
            "           220,   685,  5450,  1378,    70,   396,    13, 12567,    13,   785,\n",
            "            14,  3559,    65,  1065,  5332,  6888,  5774,  3559, 18213,  1878],\n",
            "        [   58,  5097,    50,    60, 25934,    25,  2034,  9641,  1239,  2077,\n",
            "           422,   256,   544,   381,    13, 19875,    58,  5188,    47,    60,\n",
            "            40,  1043,   428,  5434,   981,   314,  2727,   649,  2650,   329,\n",
            "          5565,  5991,    13,   220,   220,   220,   598,  9641,   318,  1239,\n",
            "          3421,   422,   256,   544,   381,    13, 19875,  2393,   357,  9641,\n",
            "          7621,   737,   314,  3758,   345,  8529,   284,  3376,   428,    11,\n",
            "           284,  4174,   319,   352,    13,    15,    13,    15,    14, 19411,\n",
            "            14, 19411,    13,  9078,    58,  5188,    47,    60, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 25934,    25, 15443,  6608,   389,  5445,\n",
            "           329,  7412,  7680,    58,  5188,    47,    60,    90,  8189,    92,\n",
            "           220,  3373,   554,  5565,    11,   262,  4865,  1088,   262,  2939,\n",
            "           318,   407,  7424,   220,  3373,   314,  3088, 10829,  4865, 15546,\n",
            "          3754,  3119,    11,   475,   262,  2071,   991,  3793,   220,  3373,\n",
            "           632,  2499,   319,  7133,   996,   220,   220,   220,  1401,  2939,\n",
            "          7680,   796, 49635,    13, 10080,    13, 17953,  5159,  7680, 15090,\n",
            "           220,   220,   220,   220,   220, 19016,    25, 12813,  6978,    14,\n",
            "          1462,    14,  9060,  1600,   220,   220,   220,   220,   220,  9647,\n",
            "            25, 21355,    11,   220,   220,   220,   220,   220,  6001,    25],\n",
            "        [   58,  5097,    50,    60, 25934,    25, 11851,  5657,   318,  9066,\n",
            "           618,  1336,  9612, 22870,  3159,   318,   973,  3693,  5188,    47,\n",
            "            60,    90,  6494,    92,    27,  7146,  6927,    79,    29,  1858,\n",
            "           389,   257,  3155,   286,  5457,  3519,  2761,   351,  2111,   284,\n",
            "           220,  1057,   257,  1336,  9612,  3586,   287,  5565,    13,   383,\n",
            "           717,   318,   351,   262,   220, 22870,  3159,    13,  1318,   815,\n",
            "           307,   257,   835,   284,   423,   262, 22870,  3159,   220,  3359,\n",
            "           319,   262,  2187,  3159,    11,   475,   428,   318,   407,   262,\n",
            "          1339,  3805,   262,   220,   256,   544,   381,    13, 19875,  8398,\n",
            "           287,   428, 22032,   543,  2523,  1111,   262,   220, 38274,   290],\n",
            "        [   58,  5097,    50,    60, 35742,    25, 12697,   290,  4268,  3975,\n",
            "          6757, 37647,    58,  5188,    47,    60,    90,  6494,    92,    27,\n",
            "          7146,  6927,    79,    29, 33907,  2025, 38983,  7680,   468,  1104,\n",
            "           329,  5086,   257,  3975, 23025,   284,   307,   220,  6715,    70,\n",
            "           540,   357,   259,  8969,   604,   737,    27,  1671,    29,   220,\n",
            "         41146,  3119,   319,  1052, 38983,  2134,   532,  6715,    70,   540,\n",
            "            25,  7942,    14,  9562,    27,  1671,    29,   220,  3060,  3917,\n",
            "         18715,   532,   304,    13,    70,    13, 12697, 10434,  1222,   696,\n",
            "            26, 12697, 12915,  3503, 25970,    79, 12240,  7146,    29,    90,\n",
            "          6494,    92,    58,  5188,    47,    60, 50256, 50256, 50256, 50256]])\n",
            "BATCH_SIZE :  27\n",
            "BATCH_SIZE :  27\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_att_mask = torch.tensor(tokens_test['attention_mask'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH_SIZE :  27\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp/wandb/run-20240322_150850-tsypld00</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/tsypld00' target=\"_blank\">gpt2sp_titanium</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/tsypld00' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/tsypld00</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training for  {'train': ['titanium'], 'test': ['titanium']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 11.39\n",
            "-\n",
            " Average eval MAE loss: 2.54\n",
            "===============================\n",
            "MAE:  2.1302524\n",
            "MdAE:  1.8834643\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 4.16\n",
            "-\n",
            " Average eval MAE loss: 2.47\n",
            "===============================\n",
            "MAE:  2.0994852\n",
            "MdAE:  1.2553525\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 3.73\n",
            "-\n",
            " Average eval MAE loss: 2.68\n",
            "===============================\n",
            "MAE:  2.4846613\n",
            "MdAE:  1.467459\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 3.39\n",
            "-\n",
            " Average eval MAE loss: 2.94\n",
            "===============================\n",
            "MAE:  2.7601876\n",
            "MdAE:  2.2226944\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 2.80\n",
            "-\n",
            " Average eval MAE loss: 2.74\n",
            "===============================\n",
            "MAE:  2.458387\n",
            "MdAE:  1.8106096\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 2.51\n",
            "-\n",
            " Average eval MAE loss: 2.79\n",
            "===============================\n",
            "MAE:  2.5448332\n",
            "MdAE:  1.9683795\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 2.17\n",
            "-\n",
            " Average eval MAE loss: 3.00\n",
            "===============================\n",
            "MAE:  2.837765\n",
            "MdAE:  2.2101545\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 1.86\n",
            "-\n",
            " Average eval MAE loss: 2.56\n",
            "===============================\n",
            "MAE:  2.3831015\n",
            "MdAE:  1.801583\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 1.77\n",
            "-\n",
            " Average eval MAE loss: 3.16\n",
            "===============================\n",
            "MAE:  2.8439236\n",
            "MdAE:  2.0335593\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 1.58\n",
            "-\n",
            " Average eval MAE loss: 2.62\n",
            "===============================\n",
            "MAE:  2.3687687\n",
            "MdAE:  1.6532087\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 1.51\n",
            "-\n",
            " Average eval MAE loss: 3.16\n",
            "===============================\n",
            "MAE:  2.9466631\n",
            "MdAE:  2.1356215\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 1.24\n",
            "-\n",
            " Average eval MAE loss: 2.69\n",
            "===============================\n",
            "MAE:  2.5081985\n",
            "MdAE:  1.7801747\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 1.26\n",
            "-\n",
            " Average eval MAE loss: 2.69\n",
            "===============================\n",
            "MAE:  2.5394485\n",
            "MdAE:  1.8459654\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 1.14\n",
            "-\n",
            " Average eval MAE loss: 3.00\n",
            "===============================\n",
            "MAE:  2.7639117\n",
            "MdAE:  1.9718204\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 0.98\n",
            "-\n",
            " Average eval MAE loss: 2.96\n",
            "===============================\n",
            "MAE:  2.7523367\n",
            "MdAE:  1.9132986\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 0.95\n",
            "-\n",
            " Average eval MAE loss: 2.84\n",
            "===============================\n",
            "MAE:  2.6695123\n",
            "MdAE:  1.9306087\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 0.88\n",
            "-\n",
            " Average eval MAE loss: 2.76\n",
            "===============================\n",
            "MAE:  2.5973039\n",
            "MdAE:  1.8579826\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 0.84\n",
            "-\n",
            " Average eval MAE loss: 2.76\n",
            "===============================\n",
            "MAE:  2.5680027\n",
            "MdAE:  1.8554115\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 0.75\n",
            "-\n",
            " Average eval MAE loss: 2.95\n",
            "===============================\n",
            "MAE:  2.742726\n",
            "MdAE:  2.0079575\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 0.72\n",
            "-\n",
            " Average eval MAE loss: 2.88\n",
            "===============================\n",
            "MAE:  2.6796207\n",
            "MdAE:  1.9516292\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8970d535a3424ac29673606790f17c1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>▆▁▃█▅▆█▅▇▄▇▅▅▆▆▆▅▅▆▆</td></tr><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▂▁▃▆▄▄▆▂█▃█▃▃▆▆▅▄▄▆▅</td></tr><tr><td>test_MAE</td><td>▁▁▄▆▄▅▇▃▇▃█▄▅▆▆▆▅▅▆▆</td></tr><tr><td>train_loss</td><td>█▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>1.95163</td></tr><tr><td>best_MAE</td><td>2.09949</td></tr><tr><td>best_MAE_train_time</td><td>67.6851</td></tr><tr><td>best_MdAE</td><td>1.25535</td></tr><tr><td>eval_loss</td><td>2.87857</td></tr><tr><td>test_MAE</td><td>2.67962</td></tr><tr><td>train_loss</td><td>0.71692</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gpt2sp_titanium</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/tsypld00' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/tsypld00</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240322_150850-tsypld00/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all done for one project\n",
            "results have been written into a text file!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2SP were not initialized from the model checkpoint at gpt2 and are newly initialized: ['dense1.weight', 'dense2.weight', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### text : title+description\n",
            "Input data feed :::  [CLS]Asset data does not correctly obey contextual ownership like the entity[SEP]\"The asset data endpoint     /assets/UUID/data does not correctly obey contextual ownership.     For instance, if the default role permission are set to this after removing all existing.     GET,PUT,POST,DELETE:/users/me/**     A user should only be able to perform the operations on their entity /users/me, and all sub collections. For instance the following scenario should work as described.     # App default role permissions are edited to match the path above   # User \"\"bob\"\" registers for app   # User \"\"bob\"\" creates the following asset and uploads data. /users/me/assets/myasset and /users/me/assets/myasset/data     # User \"\"fred\"\" registers for app   # User \"\"fred\"\" should get a 404 on both /users/bob/assets/myasset, and /users/bob/assets/myasset/data     # Anonymous user should get a 404 on both /users/bob/assets/myasset, and /users/bob/assets/myasset/data     See org.usergrid.rest.applications.users.OwnershipResourceIT for some examples.   \"[SEP]\n",
            "within project split!\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(df)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using pretrained gpt-2 tokenizer\n",
            "tensor([[   58,  5097,    50,    60, 45869,  1366,   857,   407,  9380, 22389,\n",
            "         38356,  9238,   588,   262,  9312,    58,  5188,    47, 30866,   464,\n",
            "         11171,  1366, 36123,   220,   220,   220,   220,  1220, 19668,    14,\n",
            "            52, 27586,    14,  7890,   857,   407,  9380, 22389, 38356,  9238,\n",
            "            13,   220,   220,   220,   220,  1114,  4554,    11,   611,   262,\n",
            "          4277,  2597,  7170,   389,   900,   284,   428,   706, 10829,   477,\n",
            "          4683,    13,   220,   220,   220,   220, 17151,    11, 30076,    11,\n",
            "         32782,    11,  7206,  2538,  9328, 14079, 18417,    14,  1326, 35343,\n",
            "           220,   220,   220,   220,   317,  2836,   815,   691,   307,  1498,\n",
            "           284,  1620,   262,  4560,   319,   511,  9312,  1220, 18417,    14],\n",
            "        [   58,  5097,    50,    60,  3109,  3455, 14976, 11241,   379,   262,\n",
            "         30617, 14249,    58,  5188,    47,    60, 23037,   284,   751, 14976,\n",
            "         11241, 12971,   284,   262,  1334, 14249,    13,   220,   220,   220,\n",
            "           220,   220,  1737,   307,  1498,   284,  4296,   674,   267, 18439,\n",
            "          4114,    13,   220,  4418,    11, 14976, 16326,   547,   287,   262,\n",
            "          4755,   475,   547,  4615,   617,   640,  2084,    13,   220, 24213,\n",
            "           307,  1498,   284,   467,   736,   284, 23463,  3161,   284,   340,\n",
            "           852,  4615,   284,   766,   340,    13,   220,   220,   220,   685,\n",
            "          5188,    47,    60, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "        [   58,  5097,    50,    60, 22069, 40087, 12405,  5860,  2104,  4947,\n",
            "            58,  5188,    47, 30866,  2215,   257, 11234,  7042, 40087, 12405,\n",
            "           318,  1908,   351,   257, 17151,    11,   262,  7824,  5860,   262,\n",
            "          2104,  4947,    11,   618,   340,   815,  1441,  2147,    11,   393,\n",
            "          1441,   617,  3297,   286, 12405, 21136,  4049,    13,   220,   220,\n",
            "           220,   220,  1114,  1672,    11,   428,   318,  4814,   262,   705,\n",
            "         24886,     6,  5772,   286,   262, 12405,  2643,    25,   220,   220,\n",
            "           220,   220,  1626,  1467,   830,   286,  5214,    13,  3324,  2920,\n",
            "          4531, 12095, 18376,    13,    19, 22913,  1485,   220,   220,   220,\n",
            "           220,   290,  5860,   262,   717,   838, 12066,   287,   262,  4947],\n",
            "        [   58,  5097,    50,    60, 40613,  4731,  1595,   470,  4781,   281,\n",
            "          9312,  3119,   357,  8423,  1595,   470,   670,  2035, 38381,  5188,\n",
            "            47, 30866, 14490,   815,   307,  1498,   284,  4781,  9312,  6608,\n",
            "          1262,  2035,  6565,  4731,   393,  9242,   220,   220,   220,   220,\n",
            "           352,    13,  6208,   284,   766,   611,  2035,  2499,   220,   220,\n",
            "           362,    13,   611,  6565,  4731,   857,   407,   670,    11,   788,\n",
            "          4634,  6565,  4731,   815,  1394,   262,  3119,   475,   900,   340,\n",
            "           284,   281,  6565,  4731,   220,   220,   513,    13,  9242,   815,\n",
            "          1464,  4781,   262,  1994,   220,   220,   220,   220,   220,   220,\n",
            "         29249,   532,    55, 24582,   532,    72,   532,    39, 13538, 13838],\n",
            "        [   58,  5097,    50,    60, 35857, 32053,  2836, 11241,  1839,   470,\n",
            "           670,   319,  1220, 27604,    14, 18417,    14,  1326,    58,  5188,\n",
            "            47, 30866,  3260, 18931,   319,    25,   220,   220,   220, 29249,\n",
            "           532,    55, 24582, 13538,  5450,  1378, 15042,    13,  7220, 25928,\n",
            "            13,   785,    14, 27604,    14, 30001, 15931,   532,    67,   705,\n",
            "          4895,     1,  2164,   415,    62,  4906,     1,  2404,     1, 28712,\n",
            "             1,  2430,     1, 29460,     1,  2404,     1,    69,  9310,  1878,\n",
            "          9310,    64,     1,  2430,     1, 28712,     1,  2404,     1,    69,\n",
            "          9310,  1878,  9310,  1878,  9310,    64, 15931,    92,     6,   220,\n",
            "           220,   220,   220,   220,   220,   383,  2836,   318,   407,  1498]])\n",
            "BATCH_SIZE :  5\n",
            "BATCH_SIZE :  5\n",
            "using pretrained gpt-2 tokenizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e5653a53a6a3>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
            "<ipython-input-9-e5653a53a6a3>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
            "<ipython-input-9-e5653a53a6a3>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_att_mask = torch.tensor(tokens_test['attention_mask'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH_SIZE :  5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1YObNZjwdIaLufXlBhNXVVkPCz4YQrBTV/gpt2sp/wandb/run-20240322_152150-0ej70zz2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/0ej70zz2' target=\"_blank\">gpt2sp_usergrid</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/0ej70zz2' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/0ej70zz2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training for  {'train': ['usergrid'], 'test': ['usergrid']} .....\n",
            ">>> epoch  0\n",
            " Average training MAE loss: 5.18\n",
            "-\n",
            " Average eval MAE loss: 1.01\n",
            "===============================\n",
            "MAE:  1.3309797\n",
            "MdAE:  0.7775638\n",
            ">>> epoch  1\n",
            " Average training MAE loss: 1.12\n",
            "-\n",
            " Average eval MAE loss: 1.04\n",
            "===============================\n",
            "MAE:  1.3241975\n",
            "MdAE:  0.81370306\n",
            ">>> epoch  2\n",
            " Average training MAE loss: 1.12\n",
            "-\n",
            " Average eval MAE loss: 0.99\n",
            "===============================\n",
            "MAE:  1.2672515\n",
            "MdAE:  0.77542377\n",
            ">>> epoch  3\n",
            " Average training MAE loss: 1.06\n",
            "-\n",
            " Average eval MAE loss: 0.91\n",
            "===============================\n",
            "MAE:  1.292863\n",
            "MdAE:  1.2902055\n",
            ">>> epoch  4\n",
            " Average training MAE loss: 0.94\n",
            "-\n",
            " Average eval MAE loss: 0.91\n",
            "===============================\n",
            "MAE:  1.2777659\n",
            "MdAE:  1.2615304\n",
            ">>> epoch  5\n",
            " Average training MAE loss: 0.88\n",
            "-\n",
            " Average eval MAE loss: 1.03\n",
            "===============================\n",
            "MAE:  1.3421162\n",
            "MdAE:  0.9799335\n",
            ">>> epoch  6\n",
            " Average training MAE loss: 0.94\n",
            "-\n",
            " Average eval MAE loss: 1.00\n",
            "===============================\n",
            "MAE:  1.3197453\n",
            "MdAE:  1.1356363\n",
            ">>> epoch  7\n",
            " Average training MAE loss: 0.80\n",
            "-\n",
            " Average eval MAE loss: 1.01\n",
            "===============================\n",
            "MAE:  1.2354449\n",
            "MdAE:  0.97408414\n",
            ">>> epoch  8\n",
            " Average training MAE loss: 0.77\n",
            "-\n",
            " Average eval MAE loss: 1.32\n",
            "===============================\n",
            "MAE:  1.5198439\n",
            "MdAE:  1.365233\n",
            ">>> epoch  9\n",
            " Average training MAE loss: 0.72\n",
            "-\n",
            " Average eval MAE loss: 1.30\n",
            "===============================\n",
            "MAE:  1.5060669\n",
            "MdAE:  1.2737446\n",
            ">>> epoch  10\n",
            " Average training MAE loss: 0.67\n",
            "-\n",
            " Average eval MAE loss: 1.23\n",
            "===============================\n",
            "MAE:  1.4726026\n",
            "MdAE:  1.088198\n",
            ">>> epoch  11\n",
            " Average training MAE loss: 0.51\n",
            "-\n",
            " Average eval MAE loss: 1.06\n",
            "===============================\n",
            "MAE:  1.3869038\n",
            "MdAE:  1.1235251\n",
            ">>> epoch  12\n",
            " Average training MAE loss: 0.42\n",
            "-\n",
            " Average eval MAE loss: 1.03\n",
            "===============================\n",
            "MAE:  1.3237113\n",
            "MdAE:  1.1230028\n",
            ">>> epoch  13\n",
            " Average training MAE loss: 0.35\n",
            "-\n",
            " Average eval MAE loss: 1.03\n",
            "===============================\n",
            "MAE:  1.3763276\n",
            "MdAE:  1.2446365\n",
            ">>> epoch  14\n",
            " Average training MAE loss: 0.31\n",
            "-\n",
            " Average eval MAE loss: 1.13\n",
            "===============================\n",
            "MAE:  1.524585\n",
            "MdAE:  1.3590121\n",
            ">>> epoch  15\n",
            " Average training MAE loss: 0.31\n",
            "-\n",
            " Average eval MAE loss: 0.97\n",
            "===============================\n",
            "MAE:  1.3286846\n",
            "MdAE:  1.2042146\n",
            ">>> epoch  16\n",
            " Average training MAE loss: 0.26\n",
            "-\n",
            " Average eval MAE loss: 0.89\n",
            "===============================\n",
            "MAE:  1.2902056\n",
            "MdAE:  1.1421385\n",
            ">>> epoch  17\n",
            " Average training MAE loss: 0.23\n",
            "-\n",
            " Average eval MAE loss: 0.91\n",
            "===============================\n",
            "MAE:  1.3082186\n",
            "MdAE:  1.2326984\n",
            ">>> epoch  18\n",
            " Average training MAE loss: 0.23\n",
            "-\n",
            " Average eval MAE loss: 0.88\n",
            "===============================\n",
            "MAE:  1.2891928\n",
            "MdAE:  1.1706302\n",
            ">>> epoch  19\n",
            " Average training MAE loss: 0.22\n",
            "-\n",
            " Average eval MAE loss: 0.88\n",
            "===============================\n",
            "MAE:  1.2896435\n",
            "MdAE:  1.2202787\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49c5aa52537947cbae5e95f3d0241be7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>▁▁▁▇▇▃▅▃█▇▅▅▅▇█▆▅▆▆▆</td></tr><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▃▄▃▂▂▃▃▃██▆▄▃▃▅▂▁▂▁▁</td></tr><tr><td>test_MAE</td><td>▃▃▂▂▂▄▃▁██▇▅▃▄█▃▂▃▂▂</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MdAE</td><td>1.22028</td></tr><tr><td>best_MAE</td><td>1.28919</td></tr><tr><td>best_MAE_train_time</td><td>239.15167</td></tr><tr><td>best_MdAE</td><td>1.17063</td></tr><tr><td>eval_loss</td><td>0.87782</td></tr><tr><td>test_MAE</td><td>1.28964</td></tr><tr><td>train_loss</td><td>0.21825</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gpt2sp_usergrid</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/0ej70zz2' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/0ej70zz2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240322_152150-0ej70zz2/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all done for one project\n",
            "results have been written into a text file!\n"
          ]
        }
      ],
      "source": [
        "global WITHIN_PROJECT\n",
        "WITHIN_PROJECT = True\n",
        "\n",
        "TRAIN_TEST_FILE_PAIRS = [\n",
        "    # {'train': ['appceleratorstudio'], 'test': ['appceleratorstudio']},\n",
        "    # {'train': ['aptanastudio'], 'test': ['aptanastudio']},\n",
        "    # {'train': ['bamboo'], 'test': ['bamboo']},\n",
        "    # {'train': ['clover'], 'test': ['clover']},\n",
        "    {\"train\": [\"datamanagement\"], \"test\": [\"datamanagement\"]},\n",
        "    {\"train\": [\"duracloud\"], \"test\": [\"duracloud\"]},\n",
        "    {\"train\": [\"jirasoftware\"], \"test\": [\"jirasoftware\"]},\n",
        "    {\"train\": [\"mesos\"], \"test\": [\"mesos\"]},\n",
        "    {\"train\": [\"moodle\"], \"test\": [\"moodle\"]},\n",
        "    {\"train\": [\"mule\"], \"test\": [\"mule\"]},\n",
        "    {\"train\": [\"mulestudio\"], \"test\": [\"mulestudio\"]},\n",
        "    {\"train\": [\"springxd\"], \"test\": [\"springxd\"]},\n",
        "    {\"train\": [\"talenddataquality\"], \"test\": [\"talenddataquality\"]},\n",
        "    {\"train\": [\"talendesb\"], \"test\": [\"talendesb\"]},\n",
        "    {\"train\": [\"titanium\"], \"test\": [\"titanium\"]},\n",
        "    {\"train\": [\"usergrid\"], \"test\": [\"usergrid\"]},\n",
        "]\n",
        "\n",
        "\n",
        "def create_tokenizer(tokenizer_name):\n",
        "    if tokenizer_name == \"gpt2\":\n",
        "        print(\"using pretrained gpt-2 tokenizer\")\n",
        "        tokenizer = GPT2Tokenizer.from_pretrained(TOKENIZER)\n",
        "        tokenizer.pad_token = \"[PAD]\"\n",
        "    elif tokenizer_name == \"bert\":\n",
        "        print(\"usingbert tokenizer\")\n",
        "        tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "def main():\n",
        "    global TRAIN_TEST_FILE_PAIRS, MODEL, TOKENIZER, MODEL_NAME\n",
        "    for file in TRAIN_TEST_FILE_PAIRS:\n",
        "        if TOKENIZER == \"bbpe\":\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=50257)\n",
        "        elif TOKENIZER == \"gpt2\":\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=50256)\n",
        "\n",
        "        elif TOKENIZER == \"bert\":\n",
        "            config = BertConfig(num_labels=1, pad_token_id=0)\n",
        "\n",
        "        if MODEL_NAME == \"gpt2\":\n",
        "            MODEL = LinearGPT2.from_pretrained(\"gpt2\", config=config)\n",
        "            MODEL.cuda()\n",
        "        elif MODEL_NAME == \"gpt2sp\":\n",
        "            MODEL = GPT2SP.from_pretrained(\"gpt2\", config=config)\n",
        "            MODEL.cuda()\n",
        "        elif MODEL_NAME == \"bert\":\n",
        "            MODEL = BertSP.from_pretrained(\"bert-base-uncased\", config=config)\n",
        "            MODEL.cuda()\n",
        "\n",
        "        tokenizer = create_tokenizer(TOKENIZER)\n",
        "\n",
        "        # file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names = data_processing(file_pair=file)\n",
        "        data_processor = CustomDataLoader(\n",
        "            dynamic_batch=True,\n",
        "            batch_size_ratio=0.02,\n",
        "            data_path=\"./sp_dataset/marked_data/\",\n",
        "            within_project=True,\n",
        "            tokenizer=tokenizer,\n",
        "        )\n",
        "        train_dataloader, val_dataloader, test_dataloaders, test_file_names = (\n",
        "            data_processor.data_processing(file_pair=file)\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=MODEL,\n",
        "            file_pair=file,\n",
        "            device=DEVICE,\n",
        "            learning_rate=LEARNING_RATE,\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            sequence_len=SEQUENCE_LEN,\n",
        "            tokenizer=tokenizer,\n",
        "            tokenizer_name=TOKENIZER,\n",
        "            model_name=MODEL_NAME,\n",
        "            add_description=ADD_DESCRIPTION,\n",
        "            wandb_special_tags=WANDB_SPECIAL_TAGS,\n",
        "        )\n",
        "        # train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, MODEL, test_file_names)\n",
        "\n",
        "        del MODEL , data_processor , trainer\n",
        "        torch.cuda.empty_cache()\n",
        "        # global OUTPUT\n",
        "        # with open(\n",
        "        #     \"./results/\" + str(file[\"train\"][0]) + \"_\" + str(file[\"test\"][0]) + \".txt\",\n",
        "        #     \"w+\",\n",
        "        # ) as f:\n",
        "        #     f.writelines(OUTPUT)\n",
        "        #     print(\"results have been written into a text file!\")\n",
        "        #     OUTPUT = \"\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSte0lR_hfbo"
      },
      "source": [
        "### Cross Project Training Script - Within Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij9vp2J2hfbo"
      },
      "outputs": [],
      "source": [
        "global WITHIN_PROJECT\n",
        "WITHIN_PROJECT = False\n",
        "\n",
        "# within repo\n",
        "TRAIN_TEST_FILE_PAIRS = [\n",
        "                        {'train': ['mesos'], 'test': ['usergrid']},\n",
        "                        {'train': ['usergrid'], 'test': ['mesos']},\n",
        "                        {'train': ['appceleratorstudio'], 'test': ['aptanastudio']},\n",
        "                        {'train': ['appceleratorstudio'], 'test': ['titanium']},\n",
        "                        {'train': ['titanium'], 'test': ['appceleratorstudio']},\n",
        "                        {'train': ['aptanastudio'], 'test': ['titanium']},\n",
        "                        {'train': ['mule'], 'test': ['mulestudio']},\n",
        "                        {'train': ['mulestudio'], 'test': ['mule']}\n",
        "                        ]\n",
        "\n",
        "\n",
        "def main():\n",
        "    global TRAIN_TEST_FILE_PAIRS, MODEL, TOKENIZER, MODEL_NAME\n",
        "    for file in TRAIN_TEST_FILE_PAIRS:\n",
        "        if TOKENIZER == 'bbpe':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=50257)\n",
        "        elif TOKENIZER == 'gpt2':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=50256)\n",
        "        elif TOKENIZER == 'wordpiece':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
        "        elif TOKENIZER == 'sentencepiece':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
        "        elif TOKENIZER == 'wordlevel':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=3)\n",
        "        if MODEL_NAME == 'gpt2':\n",
        "            MODEL = LinearGPT2.from_pretrained('gpt2', config=config)\n",
        "            MODEL.cuda()\n",
        "        elif MODEL_NAME == 'gpt2sp':\n",
        "            MODEL = GPT2SP.from_pretrained('gpt2', config=config)\n",
        "            MODEL.cuda()\n",
        "        file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names = data_processing(file_pair=file)\n",
        "        train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, MODEL, test_file_names)\n",
        "        del MODEL\n",
        "        torch.cuda.empty_cache()\n",
        "        global OUTPUT\n",
        "        with open('./results/' + str(file['train'][0]) + '_' + str(file['test'][0]) +'.txt', 'w+') as f:\n",
        "            f.writelines(OUTPUT)\n",
        "            print('results have been written into a text file!')\n",
        "            OUTPUT = \"\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMcxbMB7hfbp"
      },
      "source": [
        "### Cross Project Training Script - Cross Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35iJqeeNhfbp"
      },
      "outputs": [],
      "source": [
        "global WITHIN_PROJECT\n",
        "WITHIN_PROJECT = False\n",
        "\n",
        "# cross repo\n",
        "TRAIN_TEST_FILE_PAIRS = [\n",
        "                        {'train': ['clover'], 'test': ['usergrid']},\n",
        "                        {'train': ['talendesb'], 'test': ['mesos']},\n",
        "                        {'train': ['talenddataquality'], 'test': ['aptanastudio']},\n",
        "                        {'train': ['mule'], 'test': ['titanium']},\n",
        "                        {'train': ['talenddataquality'], 'test': ['appceleratorstudio']},\n",
        "                        {'train': ['mulestudio'], 'test': ['titanium']},\n",
        "                        {'train': ['appceleratorstudio'], 'test': ['mulestudio']},\n",
        "                        {'train': ['appceleratorstudio'], 'test': ['mule']}\n",
        "                        ]\n",
        "\n",
        "\n",
        "def main():\n",
        "    global TRAIN_TEST_FILE_PAIRS, MODEL, TOKENIZER, MODEL_NAME\n",
        "    for file in TRAIN_TEST_FILE_PAIRS:\n",
        "        if TOKENIZER == 'gpt2':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=50256)\n",
        "        elif TOKENIZER == 'wordpiece':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
        "        elif TOKENIZER == 'sentencepiece':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
        "        elif TOKENIZER == 'wordlevel':\n",
        "            config = GPT2Config(num_labels=1, pad_token_id=3)\n",
        "        if MODEL_NAME == 'gpt2':\n",
        "            MODEL = LinearGPT2.from_pretrained('gpt2', config=config)\n",
        "            MODEL.cuda()\n",
        "        elif MODEL_NAME == 'gpt2sp':\n",
        "            MODEL = GPT2SP.from_pretrained('gpt2', config=config)\n",
        "            MODEL.cuda()\n",
        "        file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names = data_processing(file_pair=file)\n",
        "        train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, MODEL, test_file_names)\n",
        "        del MODEL\n",
        "        torch.cuda.empty_cache()\n",
        "        global OUTPUT\n",
        "        with open('./results/' + str(file['train'][0]) + '_' + str(file['test'][0]) +'.txt', 'w+') as f:\n",
        "            f.writelines(OUTPUT)\n",
        "            print('results have been written into a text file!')\n",
        "            OUTPUT = \"\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "environment": {
      "kernel": "conda-root-py",
      "name": "workbench-notebooks.m117",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m117"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "002225fa34a54e929ab295964871a941": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02fb1e44540a425ea493213281da8992": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04aafc0534aa4d0881ad79f392646413": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06087a2af6e6483ab983514ec45beeb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "084acb6fd39a4f6f92544332a3433c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8563a68bbd594317ba22bb974347f4ce",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f54935aed1b84973bf1dbe21a301e099",
            "value": 1
          }
        },
        "0a3a1969eefe459592e51a87d0dee41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c80b7dcfd12460da74e8115547e072a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2727f27a3c9f43bab89938650ff5fed8",
              "IPY_MODEL_92555e18a4eb4eacae773321ed48373f",
              "IPY_MODEL_2185bdb998844e1391c4d5d778fc6bc4"
            ],
            "layout": "IPY_MODEL_38344ffd15a34db7b4b8688b4d87df97"
          }
        },
        "0e8c5bc9cf1c413db2dffa6ce06d0575": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f9da33a2cc84db8be2e67a40a32a26a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10fba9f8c47d49199e5f6cd92a959605": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b33fa4f9a4431a9a3c1dd08abba5d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1759f0c458324755b498fd3744ef3790": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1df88403827d45dbb64af4400d7b150b",
              "IPY_MODEL_c51151425ddf417ab1bd28a7455492cc"
            ],
            "layout": "IPY_MODEL_662fc05e70e8476fbd72db6477a31223"
          }
        },
        "1aa0a7599ae14b1f998c6e06a6c84b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c8ec90fde33447babae9c4fb09e9331": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_838bcdeb28a54763a3dd6c438bf94b3d",
            "placeholder": "​",
            "style": "IPY_MODEL_260ad22af63148b38b2e353879636bd2",
            "value": "vocab.json: 100%"
          }
        },
        "1d4aff476ee144e9b2e17a29513f97cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c65c576ebb224dcabb3ec30d59d8d545",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_635caca8542a463c83c8f15efb5cbaac",
            "value": 1042301
          }
        },
        "1df88403827d45dbb64af4400d7b150b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfeb5dbcde374e189ce8d7a815aa1297",
            "placeholder": "​",
            "style": "IPY_MODEL_8d7c60f53b0041bd82885143695514be",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "20fa29929dc04340b2c81750f4b0b5cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ceede187c7c6484385b5fb11324334fc",
              "IPY_MODEL_9f606b99f32644d686c3d186c55b8ede"
            ],
            "layout": "IPY_MODEL_b92ec0352f66492cb9d54e83f72096c4"
          }
        },
        "2185bdb998844e1391c4d5d778fc6bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_952c3aafdc444ec09ea42c1923aa2d60",
            "placeholder": "​",
            "style": "IPY_MODEL_d7ebea85079e4dd696abec2dfc27469e",
            "value": " 665/665 [00:00&lt;00:00, 52.2kB/s]"
          }
        },
        "228d17aa6e014ab5a36ea8348a4eb84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "260ad22af63148b38b2e353879636bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2727f27a3c9f43bab89938650ff5fed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe771e64b274b1099ce1da39acf752f",
            "placeholder": "​",
            "style": "IPY_MODEL_52878ae904dd4110b7b90b1a4e8e2008",
            "value": "config.json: 100%"
          }
        },
        "2ddb31a17608440fae7962afafe8c88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f1ddebfaacd43e28547413a88d2b6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "321db1f2f0f543e5a0068c919415467c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32388a9e0c3146d782f32d3ff06a475c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3332852aeb5a4a47b5ebd9af1a257b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f9da33a2cc84db8be2e67a40a32a26a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f370309c69f142b79bc15711fd38518d",
            "value": 1
          }
        },
        "34ef5a5f91544775863e3b8919ba552b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37a41afb7d2840aea2e97c18eff6c188": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37d41c0a59224a01beea870c74fbd37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38344ffd15a34db7b4b8688b4d87df97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39b59d26602a4277aea403c42e9b2be0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d36079092b04317995afe187e502531": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db5a7481933410cb1047b8b382696ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bdb7554d90c4f85a58e043978f51454",
              "IPY_MODEL_d1efe380258c43f3b089776a48a05be3",
              "IPY_MODEL_fa8e2dcc4e534b61bfef5316147990d8"
            ],
            "layout": "IPY_MODEL_632e7b8571e6408c8ca2277e19f3517f"
          }
        },
        "3ed8abd2ae574437aac866f040ab9437": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f09cbb0590e4b78bab6d01fd8b532a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "417676e00b8b482bbc218b300a46dd5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32388a9e0c3146d782f32d3ff06a475c",
            "placeholder": "​",
            "style": "IPY_MODEL_88bebac6f0444c7abbc8f79c64267482",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "419e416342bc4e3db0093822bda005d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423fb6e288064bac8d06c694b00a3168": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96da3738bdcb4be0baa85ebd06a0a720",
            "placeholder": "​",
            "style": "IPY_MODEL_0a3a1969eefe459592e51a87d0dee41b",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "479cf1fec8fe4fdd83ec688e0bdd17d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c5aa52537947cbae5e95f3d0241be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a7db69f700546719f42ee550e98e029",
              "IPY_MODEL_7b90a9bf0cb3434d8c27866fc8809c62"
            ],
            "layout": "IPY_MODEL_a4a5b43775634974ba557e356a2ad0eb"
          }
        },
        "49ec2bcb77974bd48ab9d28cf7c2ed40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f537674bc42433db1907d6f62b948d4",
            "placeholder": "​",
            "style": "IPY_MODEL_579f54a0073a44deb0df85e71561e54d",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "4af00ac2cb8146739c876ca696b23a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10fba9f8c47d49199e5f6cd92a959605",
            "placeholder": "​",
            "style": "IPY_MODEL_bd0e565198d14263b63c44d2ebd5efd6",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "4bdb7554d90c4f85a58e043978f51454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1a3d6c8155c4f9e96bc92ee1debb60e",
            "placeholder": "​",
            "style": "IPY_MODEL_d79aee464ca04177af160a6aa3a8ea0e",
            "value": "tokenizer.json: 100%"
          }
        },
        "4c8d98fd49094961955b4a003ef23f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba29c3558db04748bd9516f3f9254199",
              "IPY_MODEL_9b372ba8076e486ba4cdb690f25dacb5"
            ],
            "layout": "IPY_MODEL_54c3d5b2fe2d47e88685a228ce8cd5a4"
          }
        },
        "4ce4f2638fd64e77aead69f9603f39ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4edc237f84c54800b8cd8243cb3a8226": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52878ae904dd4110b7b90b1a4e8e2008": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "538b3d53bbb54fd0a85d7ad37de044d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54c3d5b2fe2d47e88685a228ce8cd5a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56b4a78911f549c996049329139e0d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_784c2822b6a8491690ba37b45e8225ab",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dce8ee5deb814a8ba2bfcefaaf0fb49f",
            "value": 1
          }
        },
        "5702ef2ed33c42cb8b0b93759ac1a5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a7441ec715249bd8e89309435a35d6d",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9773def0f374478a42a8cf03dfeece7",
            "value": 26
          }
        },
        "573e87f50387468f976047ac393b8271": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba1736ec9cfd4133b5fb867464be3918",
              "IPY_MODEL_5702ef2ed33c42cb8b0b93759ac1a5c7",
              "IPY_MODEL_ea1b7fece5e74fac91bee528b96f9e10"
            ],
            "layout": "IPY_MODEL_7791cbc399d24694bde28aa2a90af944"
          }
        },
        "579f54a0073a44deb0df85e71561e54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58549ff3e860424db6642f6fd342c8dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5891e1de423c4962a3bc50311ad6e69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a7441ec715249bd8e89309435a35d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef38ca56caa471fbf32a3c07093fa5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02fb1e44540a425ea493213281da8992",
            "placeholder": "​",
            "style": "IPY_MODEL_3ed8abd2ae574437aac866f040ab9437",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "5f537674bc42433db1907d6f62b948d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "632e7b8571e6408c8ca2277e19f3517f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6350eafd020c46a69bf68660f24accc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "635caca8542a463c83c8f15efb5cbaac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "638cd8ad49b54753a577bb51d100000f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e926e182264d00acb2bb29aaf73913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "662fc05e70e8476fbd72db6477a31223": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66cc0762331b4514a71145d444f32290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "687ab8f448cc4dd6a1d258a40905bff2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71389490ec39416fb0e99b5abcc808d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73be493298ce443aaa2eaa46bee5a0ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7791cbc399d24694bde28aa2a90af944": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "784a0d7728fc44f1bfd6461409f7cf3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "784c2822b6a8491690ba37b45e8225ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f4ef0bbb44439cb46b584a1507a945": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7afc519903b04b7485ab6f03feb04d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b2661e3f17b496080a0d0549283aef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3e1b4e1d7ac40f8b6567a49e4d68583",
            "placeholder": "​",
            "style": "IPY_MODEL_e053838091cb46a29ac7346e25f682b0",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "7b90a9bf0cb3434d8c27866fc8809c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5d0d1d5d03144c8a34372dea92f6464",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f1ddebfaacd43e28547413a88d2b6a0",
            "value": 1
          }
        },
        "7e07c948be5742c89658a4147639ed21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ff9fa541010440bad59b61625f04b62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82cb807c840b480e8a722809e0190e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12b33fa4f9a4431a9a3c1dd08abba5d9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9ecf2f838a74737aca9bd4dcb798671",
            "value": 1
          }
        },
        "838bcdeb28a54763a3dd6c438bf94b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8563a68bbd594317ba22bb974347f4ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88bebac6f0444c7abbc8f79c64267482": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8970d535a3424ac29673606790f17c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ef38ca56caa471fbf32a3c07093fa5f",
              "IPY_MODEL_8af45e16443b4fea9455477e48507ecf"
            ],
            "layout": "IPY_MODEL_3d36079092b04317995afe187e502531"
          }
        },
        "8a7db69f700546719f42ee550e98e029": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_002225fa34a54e929ab295964871a941",
            "placeholder": "​",
            "style": "IPY_MODEL_321db1f2f0f543e5a0068c919415467c",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "8af45e16443b4fea9455477e48507ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a10ea8bf63194463acbada483e4203a8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9467d8c2c5f84f819508a577af58ec15",
            "value": 1
          }
        },
        "8d7c60f53b0041bd82885143695514be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92555e18a4eb4eacae773321ed48373f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_687ab8f448cc4dd6a1d258a40905bff2",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_caf6b5951a184e19ac222c4189819126",
            "value": 665
          }
        },
        "9467d8c2c5f84f819508a577af58ec15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "952c3aafdc444ec09ea42c1923aa2d60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96da3738bdcb4be0baa85ebd06a0a720": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "973b5b6999354e46b719446124d953b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b2661e3f17b496080a0d0549283aef5",
              "IPY_MODEL_99b63c9ef68d47578ca46b6c9f298059"
            ],
            "layout": "IPY_MODEL_baaef81242324e5cb94c464f36b48589"
          }
        },
        "97c6742cdeba44a1bf80e9549ff27a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34ef5a5f91544775863e3b8919ba552b",
            "placeholder": "​",
            "style": "IPY_MODEL_06087a2af6e6483ab983514ec45beeb3",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "99b63c9ef68d47578ca46b6c9f298059": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638cd8ad49b54753a577bb51d100000f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99dbc264370b4b538118b08983505fea",
            "value": 1
          }
        },
        "99dbc264370b4b538118b08983505fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b372ba8076e486ba4cdb690f25dacb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73be493298ce443aaa2eaa46bee5a0ae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5891e1de423c4962a3bc50311ad6e69a",
            "value": 1
          }
        },
        "9d4b865cfb3a4200bdf96852043e1521": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4af00ac2cb8146739c876ca696b23a8a",
              "IPY_MODEL_82cb807c840b480e8a722809e0190e75"
            ],
            "layout": "IPY_MODEL_39b59d26602a4277aea403c42e9b2be0"
          }
        },
        "9f1f18dd978f49579ab87f452f2e9998": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f606b99f32644d686c3d186c55b8ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_538b3d53bbb54fd0a85d7ad37de044d4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04aafc0534aa4d0881ad79f392646413",
            "value": 1
          }
        },
        "a10ea8bf63194463acbada483e4203a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a5b43775634974ba557e356a2ad0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e7ad14a2f64c36b7b8973712738aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb59731354724d299ec4873c62ac9e53",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37d41c0a59224a01beea870c74fbd37e",
            "value": 456318
          }
        },
        "a7673f7f3d374c5d9c2910245ac391aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ecf2f838a74737aca9bd4dcb798671": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acb75eb759f240e0a1395448dc914ea0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae3d0a1a78874b6197fe75733b51cdf4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af0de9edcf574846830d71e62405b7d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b274b038ec8b406b81b33b21eeac6246": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_423fb6e288064bac8d06c694b00a3168",
              "IPY_MODEL_56b4a78911f549c996049329139e0d72"
            ],
            "layout": "IPY_MODEL_ae3d0a1a78874b6197fe75733b51cdf4"
          }
        },
        "b5d0d1d5d03144c8a34372dea92f6464": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b92ec0352f66492cb9d54e83f72096c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b95cf308a3c54a4e8a465a0198b47432": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba1736ec9cfd4133b5fb867464be3918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2c271d5e1374554b872d4ba64e405d0",
            "placeholder": "​",
            "style": "IPY_MODEL_63e926e182264d00acb2bb29aaf73913",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ba29c3558db04748bd9516f3f9254199": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d065dcee8d5e4936a766ed81bc6ca09c",
            "placeholder": "​",
            "style": "IPY_MODEL_78f4ef0bbb44439cb46b584a1507a945",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "baaef81242324e5cb94c464f36b48589": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0e565198d14263b63c44d2ebd5efd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd4472bcc9404363ab96d2759f9cb8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e029ba5bc6154434a64e77a32bf43cb1",
              "IPY_MODEL_cc91e5dcec594a5cbb961f0273551a54"
            ],
            "layout": "IPY_MODEL_a7673f7f3d374c5d9c2910245ac391aa"
          }
        },
        "bf37e7dd527f4b87b30b12a23be06848": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb07a4a1c8d94bf791090604431ab2ba",
              "IPY_MODEL_084acb6fd39a4f6f92544332a3433c24"
            ],
            "layout": "IPY_MODEL_bfd01714a88c4f6791782b9e3125accd"
          }
        },
        "bfd01714a88c4f6791782b9e3125accd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0cab96d29174c0daf1900d26d49fbda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c271d5e1374554b872d4ba64e405d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c51151425ddf417ab1bd28a7455492cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af0de9edcf574846830d71e62405b7d2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0e29f4c3b594af8ac5adfb659f1670d",
            "value": 1
          }
        },
        "c65c576ebb224dcabb3ec30d59d8d545": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c725abcc6a0242fc9704c56d485b52d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c76912e2f63e470d986c4ae3dda3eca5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c78abd161eac43b686464170b74c4417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58549ff3e860424db6642f6fd342c8dd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f09cbb0590e4b78bab6d01fd8b532a6",
            "value": 1
          }
        },
        "c978de7d63d947d18d99bb4eef225d08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caf6b5951a184e19ac222c4189819126": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb07a4a1c8d94bf791090604431ab2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff9fa541010440bad59b61625f04b62",
            "placeholder": "​",
            "style": "IPY_MODEL_66cc0762331b4514a71145d444f32290",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "cb17d9abc0b348d692e097406758a9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc91e5dcec594a5cbb961f0273551a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6350eafd020c46a69bf68660f24accc4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb17d9abc0b348d692e097406758a9d2",
            "value": 1
          }
        },
        "cea6ac475d044a99a62e72f45dd1877e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceede187c7c6484385b5fb11324334fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea6ac475d044a99a62e72f45dd1877e",
            "placeholder": "​",
            "style": "IPY_MODEL_0e8c5bc9cf1c413db2dffa6ce06d0575",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "cfeb5dbcde374e189ce8d7a815aa1297": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d065dcee8d5e4936a766ed81bc6ca09c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1efe380258c43f3b089776a48a05be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_419e416342bc4e3db0093822bda005d2",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_784a0d7728fc44f1bfd6461409f7cf3d",
            "value": 1355256
          }
        },
        "d2b0b90e1f674cf691cebfda537c127c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_417676e00b8b482bbc218b300a46dd5f",
              "IPY_MODEL_c78abd161eac43b686464170b74c4417"
            ],
            "layout": "IPY_MODEL_37a41afb7d2840aea2e97c18eff6c188"
          }
        },
        "d707fd40d9214188a27b7703267c0cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97c6742cdeba44a1bf80e9549ff27a40",
              "IPY_MODEL_f7518835420c44b7a54861ed125443e1"
            ],
            "layout": "IPY_MODEL_c76912e2f63e470d986c4ae3dda3eca5"
          }
        },
        "d79aee464ca04177af160a6aa3a8ea0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7ebea85079e4dd696abec2dfc27469e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dce8ee5deb814a8ba2bfcefaaf0fb49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e029ba5bc6154434a64e77a32bf43cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c978de7d63d947d18d99bb4eef225d08",
            "placeholder": "​",
            "style": "IPY_MODEL_c725abcc6a0242fc9704c56d485b52d0",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "e053838091cb46a29ac7346e25f682b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0755a3df4bf48a483f7f6c1f5999362": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5576d70ef564bd18deb9b81b03e558a",
              "IPY_MODEL_a4e7ad14a2f64c36b7b8973712738aea",
              "IPY_MODEL_f8acbce3273d4066a1b0bd56abdcba95"
            ],
            "layout": "IPY_MODEL_c0cab96d29174c0daf1900d26d49fbda"
          }
        },
        "e0e29f4c3b594af8ac5adfb659f1670d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5576d70ef564bd18deb9b81b03e558a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b95cf308a3c54a4e8a465a0198b47432",
            "placeholder": "​",
            "style": "IPY_MODEL_2ddb31a17608440fae7962afafe8c88f",
            "value": "merges.txt: 100%"
          }
        },
        "e5936854533746119b295dc10f6c2249": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49ec2bcb77974bd48ab9d28cf7c2ed40",
              "IPY_MODEL_3332852aeb5a4a47b5ebd9af1a257b8a"
            ],
            "layout": "IPY_MODEL_1aa0a7599ae14b1f998c6e06a6c84b8f"
          }
        },
        "ea1b7fece5e74fac91bee528b96f9e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e07c948be5742c89658a4147639ed21",
            "placeholder": "​",
            "style": "IPY_MODEL_4edc237f84c54800b8cd8243cb3a8226",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.72kB/s]"
          }
        },
        "eb59731354724d299ec4873c62ac9e53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee651a0f23654004941a06e413ea4f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8373d7d9d864bcba0ac4b5f5877a075",
            "placeholder": "​",
            "style": "IPY_MODEL_7afc519903b04b7485ab6f03feb04d74",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 14.9MB/s]"
          }
        },
        "f1a3d6c8155c4f9e96bc92ee1debb60e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1dc83712ef543ef9ad800150fd5457b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f370309c69f142b79bc15711fd38518d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3e1b4e1d7ac40f8b6567a49e4d68583": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f54935aed1b84973bf1dbe21a301e099": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6e55e3131c545aaad90faa445ab3e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c8ec90fde33447babae9c4fb09e9331",
              "IPY_MODEL_1d4aff476ee144e9b2e17a29513f97cc",
              "IPY_MODEL_ee651a0f23654004941a06e413ea4f6c"
            ],
            "layout": "IPY_MODEL_479cf1fec8fe4fdd83ec688e0bdd17d8"
          }
        },
        "f7518835420c44b7a54861ed125443e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1dc83712ef543ef9ad800150fd5457b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ce4f2638fd64e77aead69f9603f39ca",
            "value": 1
          }
        },
        "f8373d7d9d864bcba0ac4b5f5877a075": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8acbce3273d4066a1b0bd56abdcba95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71389490ec39416fb0e99b5abcc808d4",
            "placeholder": "​",
            "style": "IPY_MODEL_228d17aa6e014ab5a36ea8348a4eb84b",
            "value": " 456k/456k [00:00&lt;00:00, 11.7MB/s]"
          }
        },
        "f9773def0f374478a42a8cf03dfeece7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa8e2dcc4e534b61bfef5316147990d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb75eb759f240e0a1395448dc914ea0",
            "placeholder": "​",
            "style": "IPY_MODEL_9f1f18dd978f49579ab87f452f2e9998",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 36.3MB/s]"
          }
        },
        "ffe771e64b274b1099ce1da39acf752f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
