{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Sansith/gpt2sp/blob/bertsp/model_training_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyLoXxhlhfbk",
    "tags": []
   },
   "source": [
    "# Model Training Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ren7VyEyhfbl",
    "tags": []
   },
   "source": [
    "### Necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMyN0hhThfbl",
    "outputId": "59d1a743-5820-4aa9-b6ac-1400dc94a41c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: pandas===1.5.3 in /opt/conda/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.25.2)\n",
      "Requirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: koila in /opt/conda/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.16.2)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.16.4-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas===1.5.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas===1.5.3) (2024.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: pynvml in /opt/conda/lib/python3.10/site-packages (from koila) (11.5.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from koila) (13.7.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.60.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (69.0.3)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.42.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->koila) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->koila) (2.17.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->koila) (0.1.2)\n",
      "Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading sentry_sdk-1.42.0-py2.py3-none-any.whl (263 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.5/263.5 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Installing collected packages: appdirs, setproctitle, sentry-sdk, docker-pycreds, wandb\n",
      "Successfully installed appdirs-1.4.4 docker-pycreds-0.4.0 sentry-sdk-1.42.0 setproctitle-1.3.3 wandb-0.16.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch pandas===1.5.3 transformers numpy tokenizers koila tensorboard wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbfZ-HQu4S9U",
    "outputId": "a9edfd39-3a5e-480f-e659-3ceee7dbc246",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jupyter/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login 392e817af43c45fef2953b58c84ebb95d7dd31b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIh96xVTiuIa",
    "outputId": "f10d9876-acf4-4230-8a87-d9866dc88a3d",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3R16ZxuirGo",
    "outputId": "09e487e2-6993-44b5-ad0f-8cd48274ed6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'drive/MyDrive/Year4/FYP/effort-estimation/gpt2sp'\n",
      "/content/drive/MyDrive/Year4/FYP/effort-estimation/gpt2sp\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/Year4/FYP/effort-estimation/gpt2sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "bhcSAPbLhfbm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup , BertTokenizer\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from GPT2SP import GPT2ForSequenceClassification as GPT2SP\n",
    "from transformers import GPT2ForSequenceClassification as LinearGPT2\n",
    "from transformers import GPT2Config , BertConfig\n",
    "import os\n",
    "from tokenizers import Tokenizer\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "cf6cpSnmvZcA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers.modeling_outputs import SequenceClassifierOutputWithPast\n",
    "import torch.nn as nn\n",
    "from transformers import  BertPreTrainedModel , BertModel\n",
    "import torch\n",
    "\n",
    "\n",
    "class BertSP(BertPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"h\\.\\d+\\.attn\\.masked_bias\", r\"lm_head\\.weight\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.transformer = BertModel(config)\n",
    "        print(\"n_embd/hidden_size : \", config.hidden_size)\n",
    "        self.dense1 = nn.Linear(config.hidden_size, 4 * config.hidden_size, bias=False)\n",
    "        self.relu1 = nn.ReLU() \n",
    "        self.dense2 = nn.Linear(4 * config.hidden_size, config.hidden_size, bias=False)\n",
    "        self.relu2 = nn.ReLU() \n",
    "        self.score = nn.Linear(config.hidden_size, self.num_labels, bias=False)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        past_key_values=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
    "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        transformer_outputs = self.transformer(\n",
    "            input_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = transformer_outputs[0]\n",
    "\n",
    "        # MLP Layer\n",
    "        hidden_states = self.dense1(hidden_states)\n",
    "        hidden_states = self.relu1(hidden_states)\n",
    "        \n",
    "        hidden_states = self.dense2(hidden_states)\n",
    "        hidden_states = self.relu2(hidden_states)\n",
    "        logits = self.score(hidden_states)\n",
    "\n",
    "        if input_ids is not None:\n",
    "            batch_size, sequence_length = input_ids.shape[:2]\n",
    "        else:\n",
    "            batch_size, sequence_length = inputs_embeds.shape[:2]\n",
    "\n",
    "        assert (\n",
    "            self.config.pad_token_id is not None or batch_size == 1\n",
    "        ), \"Cannot handle batch sizes > 1 if no padding token is defined.\"\n",
    "        if self.config.pad_token_id is None:\n",
    "            sequence_lengths = -1\n",
    "        else:\n",
    "            if input_ids is not None:\n",
    "                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1\n",
    "            else:\n",
    "                sequence_lengths = -1\n",
    "                logger.warning(\n",
    "                    f\"{self.__class__.__name__} will not detect padding tokens in `inputs_embeds`. Results may be \"\n",
    "                    f\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"\n",
    "                )\n",
    "\n",
    "        pooled_logits = logits[range(batch_size), sequence_lengths]\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = nn.L1Loss()\n",
    "                loss = loss_fct(pooled_logits.view(-1), labels.to(self.dtype).view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(pooled_logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (pooled_logits,) + transformer_outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=pooled_logits,\n",
    "            past_key_values=transformer_outputs.past_key_values,\n",
    "            hidden_states=transformer_outputs.hidden_states,\n",
    "            attentions=transformer_outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbQNj41Ghfbn"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ch24eOM0hfbn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "global EPOCHS, BATCH_SIZE_RATIO, SEQUENCE_LEN, LEARNING_RATE, TOKENIZER, MODEL_NAME , ADD_DESCRIPTION\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE_RATIO = 0.05 # within proj: 0.3 / cross proj: 0.4\n",
    "SEQUENCE_LEN = 100\n",
    "LEARNING_RATE = 5e-4\n",
    "TOKENIZER = 'bert' # available:bert, gpt2, wordlevel, sentencepiece, wordpiece\n",
    "MODEL_NAME = 'bert' # available: bert, gpt2sp, gpt2\n",
    "ADD_DESCRIPTION = True\n",
    "WANDB_SPECIAL_TAGS = ['with relu','description+title'] #'with relu'\n",
    "# define device\n",
    "global DEVICE\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# define files to be used\n",
    "global DATA_PATH\n",
    "DATA_PATH = './sp_dataset/marked_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH1j_lvmhfbn",
    "tags": []
   },
   "source": [
    "### Static Methods and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "W1FZRuJ7hfbn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT = '  '\n",
    "MODEL = None\n",
    "DYNAMIC_BATCH = True\n",
    "BATCH_SIZE = None\n",
    "WITHIN_PROJECT = None\n",
    "MAE_RECORDS = []\n",
    "MDAE_RECORDS = []\n",
    "\n",
    "def data_processing(file_pair):\n",
    "    global BATCH_SIZE, BATCH_SIZE_RATIO, DATA_PATH, WITHIN_PROJECT, DYNAMIC_BATCH\n",
    "\n",
    "    train_data = pd.DataFrame(columns=['text', 'label'])\n",
    "    for train_file_name in file_pair['train']:\n",
    "        fname = DATA_PATH + train_file_name + '.csv'\n",
    "        df = prepare_dataframe(fname)\n",
    "        train_data = train_data.append(df)\n",
    "\n",
    "    # data split\n",
    "    if WITHIN_PROJECT:\n",
    "        train_text, train_labels, val_text, val_labels, test_text, test_labels = within_project_split(train_data)\n",
    "    else:\n",
    "        train_text, train_labels, val_text, val_labels = train_val_split(train_data, 0.6)\n",
    "    # define batch size dynamically based on training length\n",
    "    if DYNAMIC_BATCH:\n",
    "        BATCH_SIZE = int(len(train_text) * BATCH_SIZE_RATIO)\n",
    "    # tokenization\n",
    "    tokens_train = tokenization(train_text.tolist())\n",
    "    tokens_val = tokenization(val_text.tolist())\n",
    "    print(tokens_train['input_ids'][:5])\n",
    "\n",
    "    train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "    train_att_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "    train_y = torch.tensor(train_labels.tolist()).type(torch.LongTensor)\n",
    "    train_dataloader = prepare_dataloader(train_seq, train_y, sampler_type='random',attention_mask=train_att_mask)\n",
    "\n",
    "    val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "    val_att_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "    val_y = torch.tensor(val_labels.tolist()).type(torch.LongTensor)\n",
    "    val_dataloader = prepare_dataloader(val_seq, val_y, sampler_type='sequential',attention_mask=val_att_mask)\n",
    "\n",
    "    # prepare testing datasets\n",
    "    all_test_dataloader = []\n",
    "    test_file_names = []\n",
    "    if WITHIN_PROJECT:\n",
    "        tokens_test = tokenization(test_text.tolist())\n",
    "        test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "        test_att_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "        test_y = torch.tensor(test_labels.tolist()).type(torch.LongTensor)\n",
    "        test_dataloader = prepare_dataloader(test_seq, test_y, sampler_type='sequential',attention_mask=test_att_mask)\n",
    "        all_test_dataloader.append(test_dataloader)\n",
    "        test_file_names.append(file_pair['test'][0])\n",
    "        return file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names\n",
    "\n",
    "    for test_file_name in file_pair['test']:\n",
    "        fname = DATA_PATH + test_file_name + '.csv'\n",
    "        test_data = prepare_dataframe(fname)\n",
    "\n",
    "        test_text = test_data['text']\n",
    "        test_labels = test_data['label']\n",
    "\n",
    "        # tokenization\n",
    "        tokens_test = tokenization(test_text.tolist())\n",
    "        test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "        test_att_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "        test_y = torch.tensor(test_labels.tolist()).type(torch.LongTensor)\n",
    "        test_dataloader = prepare_dataloader(test_seq, test_y, sampler_type='sequential',attention_mask=test_att_mask)\n",
    "\n",
    "        all_test_dataloader.append(test_dataloader)\n",
    "        test_file_names.append(test_file_name)\n",
    "    print('cross project data processing!')\n",
    "    return file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names\n",
    "\n",
    "\n",
    "def train_val_split(data, split_ratio):\n",
    "    print('cross project split!')\n",
    "    split_point = int(len(data) * split_ratio)\n",
    "    train_text = data['text'][:split_point]\n",
    "    train_labels = data['label'][:split_point]\n",
    "    val_text = data['text'][split_point:]\n",
    "    val_labels = data['label'][split_point:]\n",
    "    return train_text, train_labels, val_text, val_labels\n",
    "\n",
    "\n",
    "def tokenization(text_list):\n",
    "    global TOKENIZER, SEQUENCE_LEN, MODEL\n",
    "    # tokenization\n",
    "    if TOKENIZER == 'wordpiece':\n",
    "        print('using wordpiece tokenizer!')\n",
    "        tokenizer = BertTokenizer('all_tokenizers/word_piece/vocab.txt')\n",
    "    elif TOKENIZER == 'sentencepiece':\n",
    "        print('using sentencepiece tokenizer!')\n",
    "        tokenizer = XLNetTokenizer('all_tokenizers/sentence_piece/spm_tokenizer.model', padding_side='right')\n",
    "    elif TOKENIZER == 'wordlevel':\n",
    "        print('using wordlevel tokenizer!')\n",
    "        tokenizer = Tokenizer.from_file('all_tokenizers/word_level/wordlevel.json')\n",
    "        encoded_sentences = {'input_ids':[]}\n",
    "        for sentence in text_list:\n",
    "            encoded = tokenizer.encode(sentence)\n",
    "            encoded = encoded.ids\n",
    "            if len(encoded) > SEQUENCE_LEN:\n",
    "                encoded = encoded[:SEQUENCE_LEN]\n",
    "            elif len(encoded) < SEQUENCE_LEN:\n",
    "                padding = SEQUENCE_LEN - len(encoded)\n",
    "                for _ in range(padding):\n",
    "                    encoded.append(3)\n",
    "            encoded_sentences['input_ids'].append(encoded)\n",
    "        return encoded_sentences\n",
    "    elif TOKENIZER == 'gpt2':\n",
    "        print('using pretrained gpt-2 tokenizer')\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(TOKENIZER)\n",
    "        tokenizer.pad_token = '[PAD]'\n",
    "\n",
    "    elif TOKENIZER == 'bert':\n",
    "        print('usingbert tokenizer')\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        # tokenizer.pad_token = '[PAD]'\n",
    "    return tokenizer.batch_encode_plus(text_list, truncation=True, max_length=SEQUENCE_LEN, padding='max_length', return_tensors='pt')\n",
    "\n",
    "\n",
    "def prepare_dataframe(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    # some rows have no description, fill blank to avoid Null\n",
    "    data = data.fillna(' ')\n",
    "\n",
    "\n",
    "    if ADD_DESCRIPTION :\n",
    "      print(\"### text : title+description\")\n",
    "      d = {'text':('[CLS]' + data['title'] + '[SEP]' + data[\"description\"]+'[SEP]').tolist(), 'label': data['storypoint']}\n",
    "    else:\n",
    "      print(\"### text : title\")\n",
    "      d = {'text': (data['title']).tolist(), 'label': data['storypoint']}\n",
    "    print(\"Input data feed ::: \",d['text'][0])\n",
    "    return pd.DataFrame(data=d)\n",
    "\n",
    "\n",
    "def prepare_dataloader(seq, y, sampler_type, attention_mask):\n",
    "    global BATCH_SIZE\n",
    "    tensor_dataset = TensorDataset(seq, y,attention_mask)\n",
    "    if sampler_type == 'random':\n",
    "        sampler = RandomSampler(tensor_dataset)\n",
    "    elif sampler_type == 'sequential':\n",
    "        sampler = SequentialSampler(tensor_dataset)\n",
    "    print(\"BATCH_SIZE : \",BATCH_SIZE)\n",
    "    dataloader = DataLoader(tensor_dataset, sampler=sampler, batch_size=BATCH_SIZE)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def within_project_split(data):\n",
    "    print('within project split!')\n",
    "    train_val_split_point = int(len(data) * 0.6)\n",
    "    val_test_split_point = int(len(data) * 0.8)\n",
    "    train_text = data['text'][:train_val_split_point]\n",
    "    train_labels = data['label'][:train_val_split_point]\n",
    "    val_text = data['text'][train_val_split_point:val_test_split_point]\n",
    "    val_labels = data['label'][train_val_split_point:val_test_split_point]\n",
    "    test_text = data['text'][val_test_split_point:]\n",
    "    test_labels = data['label'][val_test_split_point:]\n",
    "    return train_text, train_labels, val_text, val_labels, test_text, test_labels\n",
    "\n",
    "\n",
    "def train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, model, test_file_names):\n",
    "    global LEARNING_RATE, EPOCHS, MAE_RECORDS, MDAE_RECORDS, DEVICE ,ADD_DESCRIPTION,WANDB_SPECIAL_TAGS\n",
    "\n",
    "        # start a new wandb run to track this script\n",
    "    wandb.init(\n",
    "            # set the wandb project where this run will be logged\n",
    "            project = \"esti-mate\",\n",
    "            name = f\"{MODEL_NAME}_{file_pair['train'][0]}\",\n",
    "            tags = WANDB_SPECIAL_TAGS,\n",
    "\n",
    "            # track hyperparameters and run metadata\n",
    "            config={\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"sequence_len\": SEQUENCE_LEN,\n",
    "            \"batch_size_ratio\":BATCH_SIZE_RATIO,\n",
    "            \"tokenizer\":TOKENIZER,\n",
    "            \"model_name\":MODEL_NAME,\n",
    "            \"description_added\":ADD_DESCRIPTION,\n",
    "            \"epochs\": EPOCHS,\n",
    "            'data_set':file_pair[\"train\"][0]\n",
    "            }\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Optimizerrr -->\n",
    "    optimizer = AdamW(MODEL.parameters(), lr=LEARNING_RATE)\n",
    "    # Total number of training steps is [number of batches] x [number of epochs]\n",
    "    total_steps = len(train_dataloader) * EPOCHS\n",
    "    # Create the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "    print(\"Start training for \", file_pair, \".....\")\n",
    "    training_start_time = time.time()\n",
    "\n",
    "    # tensorboard writer\n",
    "    writer_path = 'tb/' + str(file_pair['train'][0]) + '_' + str(file_pair['test'][0])\n",
    "    writer = SummaryWriter(writer_path)\n",
    "\n",
    "    # vars for model selection\n",
    "    min_eval_loss_epoch = [10000, 0]\n",
    "\n",
    "    time_records = []\n",
    "    MAE_RECORDS = []\n",
    "    MDAE_RECORDS = []\n",
    "    start_time = time.time()\n",
    "    loss_fct = nn.L1Loss()\n",
    "    for e in range(EPOCHS):\n",
    "        # ---TRAINING---\n",
    "        # clean GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\">>> epoch \", e)\n",
    "        # set model into train mode\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # pdb.set_trace()\n",
    "            b_input_ids = batch[0].to(DEVICE)\n",
    "            b_labels = batch[1].to(DEVICE)\n",
    "            b_attention_mask = batch[2].to(DEVICE)\n",
    "            model.zero_grad()\n",
    "            result = model(b_input_ids,\n",
    "                           labels=b_labels,\n",
    "                           attention_mask=b_attention_mask,\n",
    "                           return_dict=True)\n",
    "            loss = result.loss\n",
    "            logits = result.logits\n",
    "            total_train_loss += loss.item()\n",
    "            # Calculates the gradients\n",
    "            loss.backward()\n",
    "            # The clip_grad_norm_ function clips (limits) the norm (magnitude) of the gradients to a maximum value specified by the user.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            #updates the weights and bias accrding to the calculated gradients\n",
    "            optimizer.step()\n",
    "            # update learning rates\n",
    "            scheduler.step()\n",
    "            # clean memory\n",
    "            del step, batch, b_input_ids, b_labels, result, loss, logits\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "        wandb.log({f\"train_loss\": avg_train_loss} , step=e )\n",
    "        print(\" Average training MAE loss: {0:.2f}\".format(avg_train_loss))\n",
    "        writer.add_scalar('loss/train', avg_train_loss, e)\n",
    "\n",
    "        # clean memory\n",
    "        del avg_train_loss, total_train_loss\n",
    "\n",
    "        time_records.append(time.time() - start_time)\n",
    "\n",
    "        # ---EVAL---\n",
    "        print(\"-\")\n",
    "        # set model into eval mode\n",
    "        model.eval()\n",
    "        total_eval_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                b_input_ids = batch[0].to(DEVICE)\n",
    "                b_labels = batch[1].to(DEVICE)\n",
    "                b_attention_mask = batch[2].to(DEVICE)\n",
    "                model.zero_grad()\n",
    "                result = model(b_input_ids,\n",
    "                            labels=b_labels,\n",
    "                            attention_mask=b_attention_mask,\n",
    "                            return_dict=True)\n",
    "                loss = result.loss\n",
    "                logits = result.logits\n",
    "                total_eval_loss += loss.item()\n",
    "                # clean memory\n",
    "                del b_input_ids, b_labels, batch, result, loss, logits\n",
    "        avg_eval_loss = total_eval_loss / len(val_dataloader)\n",
    "        wandb.log({f\"eval_loss\": avg_eval_loss}, step=e)\n",
    "        print(\" Average eval MAE loss: {0:.2f}\".format(avg_eval_loss))\n",
    "\n",
    "        if avg_eval_loss <= min_eval_loss_epoch[0]:\n",
    "            min_eval_loss_epoch[0] = avg_eval_loss\n",
    "            min_eval_loss_epoch[1] = e\n",
    "\n",
    "        writer.add_scalar('loss/eval', avg_eval_loss, e)\n",
    "        # clean memory\n",
    "        del avg_eval_loss, total_eval_loss\n",
    "        # save model state to dict\n",
    "        torch.save(model.state_dict(), './models/' + 'epo_' + str(e))\n",
    "\n",
    "        print(\"===============================\")\n",
    "\n",
    "        # testing on holdout data\n",
    "        index = 0\n",
    "        for test_dataloader in all_test_dataloader:\n",
    "            test_file_name = test_file_names[index]\n",
    "            index += 1\n",
    "            testing_start_time = time.time()\n",
    "            predictions = []\n",
    "            true_labels = []\n",
    "            for batch in test_dataloader:\n",
    "                batch = tuple(t.to(DEVICE) for t in batch)\n",
    "                b_input_ids, b_labels, attention_mask = batch\n",
    "                with torch.no_grad():\n",
    "                    logits = model(b_input_ids,attention_mask=attention_mask)\n",
    "                logits = logits['logits'].detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                predictions.append(logits)\n",
    "                true_labels.append(label_ids)\n",
    "            # calculate errors\n",
    "            distance_records = []\n",
    "            for i in range(len(predictions)):\n",
    "                for j in range(len(predictions[i])):\n",
    "                    distance = abs(predictions[i][j] - true_labels[i][j])\n",
    "                    distance_records.append(distance)\n",
    "\n",
    "            ## MAE = mean value of all absolute errors (stored in distance_records)\n",
    "            MAE = np.mean(np.array(distance_records))\n",
    "            ## MdAE = median value of all absolute errors (stored in distance_records)\n",
    "            MdAE = np.median(np.array(distance_records))\n",
    "\n",
    "            MAE_RECORDS.append(MAE)\n",
    "            MDAE_RECORDS.append(MdAE)\n",
    "\n",
    "            wandb.log({f\"test_MAE\": MAE, f\"MdAE\": MdAE},step=e)\n",
    "\n",
    "            global OUTPUT\n",
    "            OUTPUT +=  'Epochs ' + str(e) + '\\n'\n",
    "            OUTPUT += 'MAE: ' + str(MAE) + '\\n'\n",
    "            OUTPUT += 'MdAE: ' + str(MdAE) + '\\n\\n'\n",
    "            print('MAE: ', MAE)\n",
    "            print('MdAE: ', MdAE)\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    # select model\n",
    "    os.rename('models/epo_' + str(min_eval_loss_epoch[1]),'models/' + str(file_pair['train'][0]) + '_'+ str(file_pair['test'][0]) + '_epo_' + str(min_eval_loss_epoch[1]))\n",
    "\n",
    "    # del unwanted models\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            os.remove(\"models/epo_\" + str(i))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    OUTPUT += 'MAE: ' + str(MAE_RECORDS[min_eval_loss_epoch[1]]) \\\n",
    "                + '  MdAE: ' + str(MDAE_RECORDS[min_eval_loss_epoch[1]]) + '\\n'\n",
    "    OUTPUT += 'training time: ' + str(time_records[min_eval_loss_epoch[1]]) + '\\n'\n",
    "    OUTPUT += 'Epochs: ' + str(min_eval_loss_epoch[1]) +'\\n'\n",
    "    global BATCH_SIZE\n",
    "    OUTPUT += 'batch size: ' + str(BATCH_SIZE) + '\\n'\n",
    "    OUTPUT += 'Description added : ' + str(ADD_DESCRIPTION) + '\\n'\n",
    "\n",
    "    best_mae_index = min_eval_loss_epoch[1]\n",
    "    wandb.log({\"best_MAE\": MAE_RECORDS[best_mae_index],\n",
    "               \"best_MdAE\": MDAE_RECORDS[best_mae_index], \n",
    "               \"best_MAE_train_time\":time_records[min_eval_loss_epoch[1]]})\n",
    "    wandb.finish()\n",
    "\n",
    "    print('all done for one project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn3yXK4lhfbo"
   },
   "source": [
    "### Within Project Training Script @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "x-uMZ1Cfhfbo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MwmBk2BPhfbo",
    "outputId": "3e225ba7-3caf-4a07-8bc4-28119d7a7703",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_embd/hidden_size :  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertSP were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.dense1.weight', 'bert.dense2.weight', 'bert.score.weight', 'bert.transformer.embeddings.LayerNorm.bias', 'bert.transformer.embeddings.LayerNorm.weight', 'bert.transformer.embeddings.position_embeddings.weight', 'bert.transformer.embeddings.token_type_embeddings.weight', 'bert.transformer.embeddings.word_embeddings.weight', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.attention.output.dense.bias', 'bert.transformer.encoder.layer.0.attention.output.dense.weight', 'bert.transformer.encoder.layer.0.attention.self.key.bias', 'bert.transformer.encoder.layer.0.attention.self.key.weight', 'bert.transformer.encoder.layer.0.attention.self.query.bias', 'bert.transformer.encoder.layer.0.attention.self.query.weight', 'bert.transformer.encoder.layer.0.attention.self.value.bias', 'bert.transformer.encoder.layer.0.attention.self.value.weight', 'bert.transformer.encoder.layer.0.intermediate.dense.bias', 'bert.transformer.encoder.layer.0.intermediate.dense.weight', 'bert.transformer.encoder.layer.0.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.output.dense.bias', 'bert.transformer.encoder.layer.0.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.attention.output.dense.bias', 'bert.transformer.encoder.layer.1.attention.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.self.key.bias', 'bert.transformer.encoder.layer.1.attention.self.key.weight', 'bert.transformer.encoder.layer.1.attention.self.query.bias', 'bert.transformer.encoder.layer.1.attention.self.query.weight', 'bert.transformer.encoder.layer.1.attention.self.value.bias', 'bert.transformer.encoder.layer.1.attention.self.value.weight', 'bert.transformer.encoder.layer.1.intermediate.dense.bias', 'bert.transformer.encoder.layer.1.intermediate.dense.weight', 'bert.transformer.encoder.layer.1.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.output.dense.bias', 'bert.transformer.encoder.layer.1.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.attention.output.dense.bias', 'bert.transformer.encoder.layer.10.attention.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.self.key.bias', 'bert.transformer.encoder.layer.10.attention.self.key.weight', 'bert.transformer.encoder.layer.10.attention.self.query.bias', 'bert.transformer.encoder.layer.10.attention.self.query.weight', 'bert.transformer.encoder.layer.10.attention.self.value.bias', 'bert.transformer.encoder.layer.10.attention.self.value.weight', 'bert.transformer.encoder.layer.10.intermediate.dense.bias', 'bert.transformer.encoder.layer.10.intermediate.dense.weight', 'bert.transformer.encoder.layer.10.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.output.dense.bias', 'bert.transformer.encoder.layer.10.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.attention.output.dense.bias', 'bert.transformer.encoder.layer.11.attention.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.self.key.bias', 'bert.transformer.encoder.layer.11.attention.self.key.weight', 'bert.transformer.encoder.layer.11.attention.self.query.bias', 'bert.transformer.encoder.layer.11.attention.self.query.weight', 'bert.transformer.encoder.layer.11.attention.self.value.bias', 'bert.transformer.encoder.layer.11.attention.self.value.weight', 'bert.transformer.encoder.layer.11.intermediate.dense.bias', 'bert.transformer.encoder.layer.11.intermediate.dense.weight', 'bert.transformer.encoder.layer.11.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.output.dense.bias', 'bert.transformer.encoder.layer.11.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.attention.output.dense.bias', 'bert.transformer.encoder.layer.2.attention.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.self.key.bias', 'bert.transformer.encoder.layer.2.attention.self.key.weight', 'bert.transformer.encoder.layer.2.attention.self.query.bias', 'bert.transformer.encoder.layer.2.attention.self.query.weight', 'bert.transformer.encoder.layer.2.attention.self.value.bias', 'bert.transformer.encoder.layer.2.attention.self.value.weight', 'bert.transformer.encoder.layer.2.intermediate.dense.bias', 'bert.transformer.encoder.layer.2.intermediate.dense.weight', 'bert.transformer.encoder.layer.2.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.output.dense.bias', 'bert.transformer.encoder.layer.2.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.attention.output.dense.bias', 'bert.transformer.encoder.layer.3.attention.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.self.key.bias', 'bert.transformer.encoder.layer.3.attention.self.key.weight', 'bert.transformer.encoder.layer.3.attention.self.query.bias', 'bert.transformer.encoder.layer.3.attention.self.query.weight', 'bert.transformer.encoder.layer.3.attention.self.value.bias', 'bert.transformer.encoder.layer.3.attention.self.value.weight', 'bert.transformer.encoder.layer.3.intermediate.dense.bias', 'bert.transformer.encoder.layer.3.intermediate.dense.weight', 'bert.transformer.encoder.layer.3.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.output.dense.bias', 'bert.transformer.encoder.layer.3.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.attention.output.dense.bias', 'bert.transformer.encoder.layer.4.attention.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.self.key.bias', 'bert.transformer.encoder.layer.4.attention.self.key.weight', 'bert.transformer.encoder.layer.4.attention.self.query.bias', 'bert.transformer.encoder.layer.4.attention.self.query.weight', 'bert.transformer.encoder.layer.4.attention.self.value.bias', 'bert.transformer.encoder.layer.4.attention.self.value.weight', 'bert.transformer.encoder.layer.4.intermediate.dense.bias', 'bert.transformer.encoder.layer.4.intermediate.dense.weight', 'bert.transformer.encoder.layer.4.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.output.dense.bias', 'bert.transformer.encoder.layer.4.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.attention.output.dense.bias', 'bert.transformer.encoder.layer.5.attention.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.self.key.bias', 'bert.transformer.encoder.layer.5.attention.self.key.weight', 'bert.transformer.encoder.layer.5.attention.self.query.bias', 'bert.transformer.encoder.layer.5.attention.self.query.weight', 'bert.transformer.encoder.layer.5.attention.self.value.bias', 'bert.transformer.encoder.layer.5.attention.self.value.weight', 'bert.transformer.encoder.layer.5.intermediate.dense.bias', 'bert.transformer.encoder.layer.5.intermediate.dense.weight', 'bert.transformer.encoder.layer.5.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.output.dense.bias', 'bert.transformer.encoder.layer.5.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.attention.output.dense.bias', 'bert.transformer.encoder.layer.6.attention.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.self.key.bias', 'bert.transformer.encoder.layer.6.attention.self.key.weight', 'bert.transformer.encoder.layer.6.attention.self.query.bias', 'bert.transformer.encoder.layer.6.attention.self.query.weight', 'bert.transformer.encoder.layer.6.attention.self.value.bias', 'bert.transformer.encoder.layer.6.attention.self.value.weight', 'bert.transformer.encoder.layer.6.intermediate.dense.bias', 'bert.transformer.encoder.layer.6.intermediate.dense.weight', 'bert.transformer.encoder.layer.6.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.output.dense.bias', 'bert.transformer.encoder.layer.6.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.attention.output.dense.bias', 'bert.transformer.encoder.layer.7.attention.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.self.key.bias', 'bert.transformer.encoder.layer.7.attention.self.key.weight', 'bert.transformer.encoder.layer.7.attention.self.query.bias', 'bert.transformer.encoder.layer.7.attention.self.query.weight', 'bert.transformer.encoder.layer.7.attention.self.value.bias', 'bert.transformer.encoder.layer.7.attention.self.value.weight', 'bert.transformer.encoder.layer.7.intermediate.dense.bias', 'bert.transformer.encoder.layer.7.intermediate.dense.weight', 'bert.transformer.encoder.layer.7.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.output.dense.bias', 'bert.transformer.encoder.layer.7.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.attention.output.dense.bias', 'bert.transformer.encoder.layer.8.attention.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.self.key.bias', 'bert.transformer.encoder.layer.8.attention.self.key.weight', 'bert.transformer.encoder.layer.8.attention.self.query.bias', 'bert.transformer.encoder.layer.8.attention.self.query.weight', 'bert.transformer.encoder.layer.8.attention.self.value.bias', 'bert.transformer.encoder.layer.8.attention.self.value.weight', 'bert.transformer.encoder.layer.8.intermediate.dense.bias', 'bert.transformer.encoder.layer.8.intermediate.dense.weight', 'bert.transformer.encoder.layer.8.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.output.dense.bias', 'bert.transformer.encoder.layer.8.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.attention.output.dense.bias', 'bert.transformer.encoder.layer.9.attention.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.self.key.bias', 'bert.transformer.encoder.layer.9.attention.self.key.weight', 'bert.transformer.encoder.layer.9.attention.self.query.bias', 'bert.transformer.encoder.layer.9.attention.self.query.weight', 'bert.transformer.encoder.layer.9.attention.self.value.bias', 'bert.transformer.encoder.layer.9.attention.self.value.weight', 'bert.transformer.encoder.layer.9.intermediate.dense.bias', 'bert.transformer.encoder.layer.9.intermediate.dense.weight', 'bert.transformer.encoder.layer.9.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.output.dense.bias', 'bert.transformer.encoder.layer.9.output.dense.weight', 'bert.transformer.pooler.dense.bias', 'bert.transformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/tmp/ipykernel_6207/1214379779.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text : title+description\n",
      "Input data feed :::  [CLS]Add CA against object literals in function invocations[SEP]{html}<div><p>The idea here is that if our metadata captures a type as function arg, we should be able to create an instance of that type as an object literal as an arg to a function invocation. For example:</p> <pre> <code>Ti.UI.createLabel( { &lt;property-ca-here&gt; } );</code> </pre></div>{html}[SEP]\n",
      "within project split!\n",
      "usingbert tokenizer\n",
      "usingbert tokenizer\n",
      "tensor([[  101,   101,  5587,  6187,  2114,  4874, 18204,  2015,  1999,  3853,\n",
      "          1999, 19152,  2015,   102,  1063, 16129,  1065,  1026,  4487,  2615,\n",
      "          1028,  1026,  1052,  1028,  1996,  2801,  2182,  2003,  2008,  2065,\n",
      "          2256, 27425, 19566,  1037,  2828,  2004,  3853, 12098,  2290,  1010,\n",
      "          2057,  2323,  2022,  2583,  2000,  3443,  2019,  6013,  1997,  2008,\n",
      "          2828,  2004,  2019,  4874, 18204,  2004,  2019, 12098,  2290,  2000,\n",
      "          1037,  3853,  1999, 19152,  1012,  2005,  2742,  1024,  1026,  1013,\n",
      "          1052,  1028,  1026,  3653,  1028,  1026,  3642,  1028, 14841,  1012,\n",
      "         21318,  1012,  3443, 20470,  2884,  1006,  1063,  1004,  8318,  1025,\n",
      "          3200,  1011,  6187,  1011,  2182,  1004, 14181,  1025,  1065,   102],\n",
      "        [  101,   101, 10651, 16140,  2005, 10439, 29109,  6906,  4263, 13354,\n",
      "          2378,  2000, 10439, 29109,  6906,  4263,  8154,   102,  1063, 16129,\n",
      "          1065,  1026,  4487,  2615,  1028,  1026,  1052,  1028,  2012,  2560,\n",
      "          8081,  3444, 18407,  1010,  3378,  3267,  2015,  1012,  3383,  2060,\n",
      "         12117,  2004,  2092,  1012,  1026,  1013,  1052,  1028,  1026,  1013,\n",
      "          4487,  2615,  1028,  1063, 16129,  1065,   102,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  3443,  2047,  1046,  3385,  8040, 28433,  2005, 17371,\n",
      "          2243,  2136,   102,  1063, 16129,  1065,  1026,  4487,  2615,  1028,\n",
      "          1026,  1052,  1028,  3443,  1046,  3385,  8040, 28433,  4820,  5144,\n",
      "          3223,  2005,  5372,  6187,  1012,  2192,  8040, 28433,  2000,  4132,\n",
      "          2136,  2000,  6434,  2047,  9986,  2015,  1013,  1046,  3385,  6764,\n",
      "          2004,  2112,  1997,  2047, 17371,  2243,  7085,  1012,  2009,  2089,\n",
      "          2022,  2008,  2612,  2057,  2064,  2224,  1996,  5443,  3527,  2278,\n",
      "          4289,  1010,  1999,  2029,  2553,  2057,  2097,  2342,  2000,  5769,\n",
      "          2000,  1996, 17371,  2243,  2136,  3176,  5167,  2000,  2022,  2794,\n",
      "          2000,  1996,  9986,  2015,  1012,  1026,  1013,  1052,  1028,   102],\n",
      "        [  101,   101,  3443,  2622,  7604,  3200,  3931,   102,  1063, 16129,\n",
      "          1065,  1026,  4487,  2615,  1028,  1026,  1052,  1028,  3443,  3200,\n",
      "          3931,  2005,  2622,  2029,  4473, 16924,  1997, 11157,  7604,  1012,\n",
      "          5310,  2064,  5587,  2030,  6366,  7604,  2013,  1996,  6764, 27268,\n",
      "          6633,  2030, 24471,  2140,  1006,  2065,  2825,  1007,  1012,  1026,\n",
      "          1013,  1052,  1028,  1026,  1052,  1028,  2045,  2089,  2092,  2022,\n",
      "          2019,  2511, 19240,  2030,  4493,  3931,  1999, 25718,  1010, 22851,\n",
      "          2102,  1010,  1046, 16150,  2102,  2030,  6974,  1012,  8556,  2128,\n",
      "         18161,  2023,  3931,  2003,  2825,  2030,  6413,  1012,  1026,  1013,\n",
      "          1052,  1028,  1026,  1013,  4487,  2615,  1028,  1063, 16129,   102],\n",
      "        [  101,   101,  2047, 15363,  2622, 10276,   102,  1063, 16129,  1065,\n",
      "          1026,  4487,  2615,  1028,  1026,  1052,  1028, 15363,  1006,  2342,\n",
      "          2000, 10463,  4493,  2622,  4325,  3642,  2000,  9262,  1007,  1012,\n",
      "          2070,  5167,  2182,  1024,  1026,  1037, 17850, 12879,  1027,  1000,\n",
      "         16770,  1024,  1013,  1013, 21025,  2705, 12083,  1012,  4012,  1013,\n",
      "         10439, 29109,  6906,  4263,  1013, 23431,  1035,  9722,  1013,  1038,\n",
      "          4135,  2497,  1013,  3040,  1013,  4219,  1013,  1046,  2015,  1013,\n",
      "          2622,  1012,  1046,  2015,  1001,  1048, 24087,  2487,  1000,  1028,\n",
      "         16770,  1024,  1013,  1013, 21025,  2705, 12083,  1012,  4012,  1013,\n",
      "         10439, 29109,  6906,  4263,  1013, 23431,  1035,  9722,  1013,   102]])\n",
      "BATCH_SIZE :  87\n",
      "BATCH_SIZE :  87\n",
      "usingbert tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_6207/1214379779.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_seq = torch.tensor(tokens_test['input_ids'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE :  87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/gpt2sp/wandb/run-20240318_113528-exo3nm1w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/exo3nm1w' target=\"_blank\">bert_appceleratorstudio</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/exo3nm1w' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/exo3nm1w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for  {'train': ['appceleratorstudio'], 'test': ['appceleratorstudio']} .....\n",
      ">>> epoch  0\n",
      " Average training MAE loss: 3.06\n",
      "-\n",
      " Average eval MAE loss: 1.58\n",
      "===============================\n",
      "MAE:  1.4902573\n",
      "MdAE:  0.33530855\n",
      ">>> epoch  1\n",
      " Average training MAE loss: 2.75\n",
      "-\n",
      " Average eval MAE loss: 1.76\n",
      "===============================\n",
      "MAE:  1.6477295\n",
      "MdAE:  0.6174054\n",
      ">>> epoch  2\n",
      " Average training MAE loss: 2.66\n",
      "-\n",
      " Average eval MAE loss: 1.51\n",
      "===============================\n",
      "MAE:  1.4268535\n",
      "MdAE:  0.22172594\n",
      ">>> epoch  3\n",
      " Average training MAE loss: 2.67\n",
      "-\n",
      " Average eval MAE loss: 1.62\n",
      "===============================\n",
      "MAE:  1.5240699\n",
      "MdAE:  0.39588022\n",
      ">>> epoch  4\n",
      " Average training MAE loss: 2.67\n",
      "-\n",
      " Average eval MAE loss: 1.62\n",
      "===============================\n",
      "MAE:  1.5251471\n",
      "MdAE:  0.39780998\n",
      ">>> epoch  5\n",
      " Average training MAE loss: 2.68\n",
      "-\n",
      " Average eval MAE loss: 1.40\n",
      "===============================\n",
      "MAE:  1.3427628\n",
      "MdAE:  0.087779045\n",
      ">>> epoch  6\n",
      " Average training MAE loss: 2.65\n",
      "-\n",
      " Average eval MAE loss: 1.39\n",
      "===============================\n",
      "MAE:  1.3209325\n",
      "MdAE:  0.031977654\n",
      ">>> epoch  7\n",
      " Average training MAE loss: 2.62\n",
      "-\n",
      " Average eval MAE loss: 1.71\n",
      "===============================\n",
      "MAE:  1.6032174\n",
      "MdAE:  0.53766584\n",
      ">>> epoch  8\n",
      " Average training MAE loss: 2.68\n",
      "-\n",
      " Average eval MAE loss: 1.49\n",
      "===============================\n",
      "MAE:  1.4046797\n",
      "MdAE:  0.1820035\n",
      ">>> epoch  9\n",
      " Average training MAE loss: 2.67\n",
      "-\n",
      " Average eval MAE loss: 1.56\n",
      "===============================\n",
      "MAE:  1.4732726\n",
      "MdAE:  0.3048811\n",
      ">>> epoch  10\n",
      " Average training MAE loss: 2.58\n",
      "-\n",
      " Average eval MAE loss: 1.53\n",
      "===============================\n",
      "MAE:  1.4424568\n",
      "MdAE:  0.24967766\n",
      ">>> epoch  11\n",
      " Average training MAE loss: 2.68\n",
      "-\n",
      " Average eval MAE loss: 1.57\n",
      "===============================\n",
      "MAE:  1.4754585\n",
      "MdAE:  0.30879736\n",
      ">>> epoch  12\n",
      " Average training MAE loss: 2.68\n",
      "-\n",
      " Average eval MAE loss: 1.51\n",
      "===============================\n",
      "MAE:  1.4251286\n",
      "MdAE:  0.21863508\n",
      ">>> epoch  13\n",
      " Average training MAE loss: 2.63\n",
      "-\n",
      " Average eval MAE loss: 1.61\n",
      "===============================\n",
      "MAE:  1.5157251\n",
      "MdAE:  0.38093185\n",
      ">>> epoch  14\n",
      " Average training MAE loss: 2.65\n",
      "-\n",
      " Average eval MAE loss: 1.55\n",
      "===============================\n",
      "MAE:  1.4621078\n",
      "MdAE:  0.28488064\n",
      ">>> epoch  15\n",
      " Average training MAE loss: 2.58\n",
      "-\n",
      " Average eval MAE loss: 1.66\n",
      "===============================\n",
      "MAE:  1.5640521\n",
      "MdAE:  0.46750498\n",
      ">>> epoch  16\n",
      " Average training MAE loss: 2.64\n",
      "-\n",
      " Average eval MAE loss: 1.48\n",
      "===============================\n",
      "MAE:  1.3989277\n",
      "MdAE:  0.17169952\n",
      ">>> epoch  17\n",
      " Average training MAE loss: 2.61\n",
      "-\n",
      " Average eval MAE loss: 1.49\n",
      "===============================\n",
      "MAE:  1.4112335\n",
      "MdAE:  0.1937437\n",
      ">>> epoch  18\n",
      " Average training MAE loss: 2.63\n",
      "-\n",
      " Average eval MAE loss: 1.48\n",
      "===============================\n",
      "MAE:  1.3978025\n",
      "MdAE:  0.16968298\n",
      ">>> epoch  19\n",
      " Average training MAE loss: 2.66\n",
      "-\n",
      " Average eval MAE loss: 1.50\n",
      "===============================\n",
      "MAE:  1.4169273\n",
      "MdAE:  0.2039442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▅█▃▅▅▁▁▇▃▄▄▄▃▅▄▆▃▃▃▃</td></tr><tr><td>test_MAE</td><td>▅█▃▅▅▁▁▇▃▄▄▄▃▅▄▆▃▃▃▃</td></tr><tr><td>test_MdAE</td><td>▅█▃▅▅▂▁▇▃▄▄▄▃▅▄▆▃▃▃▃</td></tr><tr><td>train_loss</td><td>█▄▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>1.32093</td></tr><tr><td>best_MAE_train_time</td><td>262.7106</td></tr><tr><td>best_MdAE</td><td>0.03198</td></tr><tr><td>eval_loss</td><td>1.49994</td></tr><tr><td>test_MAE</td><td>1.41693</td></tr><tr><td>test_MdAE</td><td>0.20394</td></tr><tr><td>train_loss</td><td>2.66028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert_appceleratorstudio</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/exo3nm1w' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/exo3nm1w</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240318_113528-exo3nm1w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done for one project\n",
      "results have been written into a text file!\n",
      "n_embd/hidden_size :  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertSP were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.dense1.weight', 'bert.dense2.weight', 'bert.score.weight', 'bert.transformer.embeddings.LayerNorm.bias', 'bert.transformer.embeddings.LayerNorm.weight', 'bert.transformer.embeddings.position_embeddings.weight', 'bert.transformer.embeddings.token_type_embeddings.weight', 'bert.transformer.embeddings.word_embeddings.weight', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.attention.output.dense.bias', 'bert.transformer.encoder.layer.0.attention.output.dense.weight', 'bert.transformer.encoder.layer.0.attention.self.key.bias', 'bert.transformer.encoder.layer.0.attention.self.key.weight', 'bert.transformer.encoder.layer.0.attention.self.query.bias', 'bert.transformer.encoder.layer.0.attention.self.query.weight', 'bert.transformer.encoder.layer.0.attention.self.value.bias', 'bert.transformer.encoder.layer.0.attention.self.value.weight', 'bert.transformer.encoder.layer.0.intermediate.dense.bias', 'bert.transformer.encoder.layer.0.intermediate.dense.weight', 'bert.transformer.encoder.layer.0.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.output.dense.bias', 'bert.transformer.encoder.layer.0.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.attention.output.dense.bias', 'bert.transformer.encoder.layer.1.attention.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.self.key.bias', 'bert.transformer.encoder.layer.1.attention.self.key.weight', 'bert.transformer.encoder.layer.1.attention.self.query.bias', 'bert.transformer.encoder.layer.1.attention.self.query.weight', 'bert.transformer.encoder.layer.1.attention.self.value.bias', 'bert.transformer.encoder.layer.1.attention.self.value.weight', 'bert.transformer.encoder.layer.1.intermediate.dense.bias', 'bert.transformer.encoder.layer.1.intermediate.dense.weight', 'bert.transformer.encoder.layer.1.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.output.dense.bias', 'bert.transformer.encoder.layer.1.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.attention.output.dense.bias', 'bert.transformer.encoder.layer.10.attention.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.self.key.bias', 'bert.transformer.encoder.layer.10.attention.self.key.weight', 'bert.transformer.encoder.layer.10.attention.self.query.bias', 'bert.transformer.encoder.layer.10.attention.self.query.weight', 'bert.transformer.encoder.layer.10.attention.self.value.bias', 'bert.transformer.encoder.layer.10.attention.self.value.weight', 'bert.transformer.encoder.layer.10.intermediate.dense.bias', 'bert.transformer.encoder.layer.10.intermediate.dense.weight', 'bert.transformer.encoder.layer.10.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.output.dense.bias', 'bert.transformer.encoder.layer.10.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.attention.output.dense.bias', 'bert.transformer.encoder.layer.11.attention.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.self.key.bias', 'bert.transformer.encoder.layer.11.attention.self.key.weight', 'bert.transformer.encoder.layer.11.attention.self.query.bias', 'bert.transformer.encoder.layer.11.attention.self.query.weight', 'bert.transformer.encoder.layer.11.attention.self.value.bias', 'bert.transformer.encoder.layer.11.attention.self.value.weight', 'bert.transformer.encoder.layer.11.intermediate.dense.bias', 'bert.transformer.encoder.layer.11.intermediate.dense.weight', 'bert.transformer.encoder.layer.11.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.output.dense.bias', 'bert.transformer.encoder.layer.11.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.attention.output.dense.bias', 'bert.transformer.encoder.layer.2.attention.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.self.key.bias', 'bert.transformer.encoder.layer.2.attention.self.key.weight', 'bert.transformer.encoder.layer.2.attention.self.query.bias', 'bert.transformer.encoder.layer.2.attention.self.query.weight', 'bert.transformer.encoder.layer.2.attention.self.value.bias', 'bert.transformer.encoder.layer.2.attention.self.value.weight', 'bert.transformer.encoder.layer.2.intermediate.dense.bias', 'bert.transformer.encoder.layer.2.intermediate.dense.weight', 'bert.transformer.encoder.layer.2.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.output.dense.bias', 'bert.transformer.encoder.layer.2.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.attention.output.dense.bias', 'bert.transformer.encoder.layer.3.attention.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.self.key.bias', 'bert.transformer.encoder.layer.3.attention.self.key.weight', 'bert.transformer.encoder.layer.3.attention.self.query.bias', 'bert.transformer.encoder.layer.3.attention.self.query.weight', 'bert.transformer.encoder.layer.3.attention.self.value.bias', 'bert.transformer.encoder.layer.3.attention.self.value.weight', 'bert.transformer.encoder.layer.3.intermediate.dense.bias', 'bert.transformer.encoder.layer.3.intermediate.dense.weight', 'bert.transformer.encoder.layer.3.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.output.dense.bias', 'bert.transformer.encoder.layer.3.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.attention.output.dense.bias', 'bert.transformer.encoder.layer.4.attention.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.self.key.bias', 'bert.transformer.encoder.layer.4.attention.self.key.weight', 'bert.transformer.encoder.layer.4.attention.self.query.bias', 'bert.transformer.encoder.layer.4.attention.self.query.weight', 'bert.transformer.encoder.layer.4.attention.self.value.bias', 'bert.transformer.encoder.layer.4.attention.self.value.weight', 'bert.transformer.encoder.layer.4.intermediate.dense.bias', 'bert.transformer.encoder.layer.4.intermediate.dense.weight', 'bert.transformer.encoder.layer.4.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.output.dense.bias', 'bert.transformer.encoder.layer.4.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.attention.output.dense.bias', 'bert.transformer.encoder.layer.5.attention.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.self.key.bias', 'bert.transformer.encoder.layer.5.attention.self.key.weight', 'bert.transformer.encoder.layer.5.attention.self.query.bias', 'bert.transformer.encoder.layer.5.attention.self.query.weight', 'bert.transformer.encoder.layer.5.attention.self.value.bias', 'bert.transformer.encoder.layer.5.attention.self.value.weight', 'bert.transformer.encoder.layer.5.intermediate.dense.bias', 'bert.transformer.encoder.layer.5.intermediate.dense.weight', 'bert.transformer.encoder.layer.5.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.output.dense.bias', 'bert.transformer.encoder.layer.5.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.attention.output.dense.bias', 'bert.transformer.encoder.layer.6.attention.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.self.key.bias', 'bert.transformer.encoder.layer.6.attention.self.key.weight', 'bert.transformer.encoder.layer.6.attention.self.query.bias', 'bert.transformer.encoder.layer.6.attention.self.query.weight', 'bert.transformer.encoder.layer.6.attention.self.value.bias', 'bert.transformer.encoder.layer.6.attention.self.value.weight', 'bert.transformer.encoder.layer.6.intermediate.dense.bias', 'bert.transformer.encoder.layer.6.intermediate.dense.weight', 'bert.transformer.encoder.layer.6.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.output.dense.bias', 'bert.transformer.encoder.layer.6.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.attention.output.dense.bias', 'bert.transformer.encoder.layer.7.attention.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.self.key.bias', 'bert.transformer.encoder.layer.7.attention.self.key.weight', 'bert.transformer.encoder.layer.7.attention.self.query.bias', 'bert.transformer.encoder.layer.7.attention.self.query.weight', 'bert.transformer.encoder.layer.7.attention.self.value.bias', 'bert.transformer.encoder.layer.7.attention.self.value.weight', 'bert.transformer.encoder.layer.7.intermediate.dense.bias', 'bert.transformer.encoder.layer.7.intermediate.dense.weight', 'bert.transformer.encoder.layer.7.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.output.dense.bias', 'bert.transformer.encoder.layer.7.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.attention.output.dense.bias', 'bert.transformer.encoder.layer.8.attention.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.self.key.bias', 'bert.transformer.encoder.layer.8.attention.self.key.weight', 'bert.transformer.encoder.layer.8.attention.self.query.bias', 'bert.transformer.encoder.layer.8.attention.self.query.weight', 'bert.transformer.encoder.layer.8.attention.self.value.bias', 'bert.transformer.encoder.layer.8.attention.self.value.weight', 'bert.transformer.encoder.layer.8.intermediate.dense.bias', 'bert.transformer.encoder.layer.8.intermediate.dense.weight', 'bert.transformer.encoder.layer.8.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.output.dense.bias', 'bert.transformer.encoder.layer.8.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.attention.output.dense.bias', 'bert.transformer.encoder.layer.9.attention.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.self.key.bias', 'bert.transformer.encoder.layer.9.attention.self.key.weight', 'bert.transformer.encoder.layer.9.attention.self.query.bias', 'bert.transformer.encoder.layer.9.attention.self.query.weight', 'bert.transformer.encoder.layer.9.attention.self.value.bias', 'bert.transformer.encoder.layer.9.attention.self.value.weight', 'bert.transformer.encoder.layer.9.intermediate.dense.bias', 'bert.transformer.encoder.layer.9.intermediate.dense.weight', 'bert.transformer.encoder.layer.9.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.output.dense.bias', 'bert.transformer.encoder.layer.9.output.dense.weight', 'bert.transformer.pooler.dense.bias', 'bert.transformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/tmp/ipykernel_6207/1214379779.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text : title+description\n",
      "Input data feed :::  [CLS]Add Copy URL actions to right-click context menu of Remote view for S3 files[SEP]I was able to connect to our Appcelerator S3 bucket to drag and drog copy image files that I wanted to refer to remotely from the Desktop packaging release links webpage. But I had no easy way to tell what the various URLs were that I could use to refer to the resulting S3 objects/files. Cyberduck lets you right click and choose Copy URL > HTTPS, HTTPS, Signed URL (expiring in one hour, one day, or one week + one hour), Torrent URL.[SEP]\n",
      "within project split!\n",
      "usingbert tokenizer\n",
      "usingbert tokenizer\n",
      "tensor([[  101,   101,  5587,  6100, 24471,  2140,  4506,  2000,  2157,  1011,\n",
      "         11562,  6123, 12183,  1997,  6556,  3193,  2005,  1055,  2509,  6764,\n",
      "           102,  1045,  2001,  2583,  2000,  7532,  2000,  2256, 10439, 29109,\n",
      "          6906,  4263,  1055,  2509, 13610,  2000,  8011,  1998,  2852,  8649,\n",
      "          6100,  3746,  6764,  2008,  1045,  2359,  2000,  6523,  2000, 19512,\n",
      "          2013,  1996, 15363, 14793,  2713,  6971,  4773, 13704,  1012,  2021,\n",
      "          1045,  2018,  2053,  3733,  2126,  2000,  2425,  2054,  1996,  2536,\n",
      "         24471,  4877,  2020,  2008,  1045,  2071,  2224,  2000,  6523,  2000,\n",
      "          1996,  4525,  1055,  2509,  5200,  1013,  6764,  1012, 16941,  8566,\n",
      "          3600, 11082,  2017,  2157, 11562,  1998,  5454,  6100, 24471,   102],\n",
      "        [  101,   101, 26794,  5162,  5363,  2000,  2330,  1037,  2047,  6013,\n",
      "          1997,  2993,  2043,  3098,  6764,  3081,  3645, 10566,   102,  1063,\n",
      "         16129,  1065,  1026,  4487,  2615,  1028,  1026,  1052,  1028,  4137,\n",
      "          2000,  1026,  1037, 17850, 12879,  1027,  1000,  8299,  1024,  1013,\n",
      "          1013, 26794,  5162,  3367, 21041,  2080,  1012,  8616, 29098,  1012,\n",
      "          4012,  1013, 10287,  1013,  3471,  1013,  4749,  1011, 26794,  5162,\n",
      "          1011,  5363,  1011,  2000,  1011,  2330,  1011,  1037,  1011,  2047,\n",
      "          1011,  6013,  1011,  1997,  1011,  2993,  1011,  2043,  1011,  3098,\n",
      "          1011,  6764,  1011,  2013,  1011,  2663,  1011, 10566,  2063,  1000,\n",
      "          1028,  8616,  3277,  1001,  4749,  1026,  1013,  1037,  1028,   102],\n",
      "        [  101,   101,  4180,  6509,  3769,  6279,  2003,  3491,  2648,  1996,\n",
      "          3898,  7372,   102,  2004,  2017,  2064,  2156,  2013,  1996,  3746,\n",
      "          1010,  1996,  9262, 22483,  4180,  6509,  3769,  6279,  8834,  2648,\n",
      "          1996,  3898,  6192,  2000,  1996,  2157,  1012,   102,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101, 25718,  8285,  9006, 10814,  3508,  2005,  6687,  4725,\n",
      "           102,  2043,  2017,  2058, 26373,  1037,  6687,  4118,  2017,  2411,\n",
      "          2342,  2000,  2655,  2009,  2013,  1996,  2047,  4118,  1010,  2742,\n",
      "          1024,  1063,  3642,  1065,  1026,  1029, 25718,  2465,  6687,  1063,\n",
      "          2270,  3853,  9998,  8462, 20744, 11783,  1006,  1007,  1063,  1065,\n",
      "          1065,  2465,  2775,  1063,  2270,  3853,  9998,  8462, 20744, 11783,\n",
      "          1006,  1007,  1063,  1002,  2023,  1011,  1028,  1038,  2721,  1027,\n",
      "          1005, 29379,  1005,  1025,  2709,  6687,  1024,  1024,  1001,  4180,\n",
      "          6509,  2182,  2323,  2031,  9998,  8462, 20744, 11783,  1006,  1007,\n",
      "          1065,  1065,  1029,  1028,  1063,  3642,  1065, 26794,  5162,   102],\n",
      "        [  101,   101, 11920,  2019,  3746,  2046,  1996, 16129,  3559,  2323,\n",
      "          3443,  2019,  3746,  6415,   102, 11920,  2019,  3746,  2046,  1996,\n",
      "          3559,  2323,  3443,  1037, 10047,  2290,  6415,  1012,  2017,  2064,\n",
      "          3193,  2023,  5248,  1999,  3793,  8585,  1012,  7510,  2019,  3746,\n",
      "          3031,  1996, 16129,  3559, 19274,  2015,  2019,  3746,  6415,  2007,\n",
      "          1996,  5816,  4130,  2000,  1996,  3746,  1006,  2013,  2023, 16129,\n",
      "          5371,  1007,  1010,  1996,  2152,  2102,  1998,  9381,  1010,  1998,\n",
      "          1996, 12456,  3793,  2004,  1996,  3988,  1011,  3007,  3550,  2544,\n",
      "          1997,  1996,  5371, 18442,  1024,  1045,  1012,  1041,  1012, 11920,\n",
      "          1000,  3964,  1012,  1052,  3070,  1000,  3957,  2033,  1024,   102]])\n",
      "BATCH_SIZE :  24\n",
      "BATCH_SIZE :  24\n",
      "usingbert tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_6207/1214379779.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_seq = torch.tensor(tokens_test['input_ids'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE :  24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/gpt2sp/wandb/run-20240318_114845-3z09kqv6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/3z09kqv6' target=\"_blank\">bert_aptanastudio</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/3z09kqv6' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/3z09kqv6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for  {'train': ['aptanastudio'], 'test': ['aptanastudio']} .....\n",
      ">>> epoch  0\n",
      " Average training MAE loss: 4.91\n",
      "-\n",
      " Average eval MAE loss: 3.66\n",
      "===============================\n",
      "MAE:  3.9273803\n",
      "MdAE:  3.4994717\n",
      ">>> epoch  1\n",
      " Average training MAE loss: 4.89\n",
      "-\n",
      " Average eval MAE loss: 3.79\n",
      "===============================\n",
      "MAE:  3.4998014\n",
      "MdAE:  2.1348681\n",
      ">>> epoch  2\n",
      " Average training MAE loss: 4.52\n",
      "-\n",
      " Average eval MAE loss: 3.72\n",
      "===============================\n",
      "MAE:  3.524444\n",
      "MdAE:  2.320804\n",
      ">>> epoch  3\n",
      " Average training MAE loss: 4.61\n",
      "-\n",
      " Average eval MAE loss: 3.53\n",
      "===============================\n",
      "MAE:  3.5906682\n",
      "MdAE:  2.8204947\n",
      ">>> epoch  4\n",
      " Average training MAE loss: 4.36\n",
      "-\n",
      " Average eval MAE loss: 3.53\n",
      "===============================\n",
      "MAE:  3.7110026\n",
      "MdAE:  3.1540995\n",
      ">>> epoch  5\n",
      " Average training MAE loss: 4.29\n",
      "-\n",
      " Average eval MAE loss: 3.95\n",
      "===============================\n",
      "MAE:  3.4439034\n",
      "MdAE:  1.7130909\n",
      ">>> epoch  6\n",
      " Average training MAE loss: 4.42\n",
      "-\n",
      " Average eval MAE loss: 3.61\n",
      "===============================\n",
      "MAE:  3.8443515\n",
      "MdAE:  3.3669453\n",
      ">>> epoch  7\n",
      " Average training MAE loss: 4.33\n",
      "-\n",
      " Average eval MAE loss: 3.52\n",
      "===============================\n",
      "MAE:  3.698588\n",
      "MdAE:  3.134285\n",
      ">>> epoch  8\n",
      " Average training MAE loss: 4.51\n",
      "-\n",
      " Average eval MAE loss: 3.48\n",
      "===============================\n",
      "MAE:  3.6094131\n",
      "MdAE:  2.9619346\n",
      ">>> epoch  9\n",
      " Average training MAE loss: 4.35\n",
      "-\n",
      " Average eval MAE loss: 3.53\n",
      "===============================\n",
      "MAE:  3.720862\n",
      "MdAE:  3.169838\n",
      ">>> epoch  10\n",
      " Average training MAE loss: 4.37\n",
      "-\n",
      " Average eval MAE loss: 3.47\n",
      "===============================\n",
      "MAE:  3.6219294\n",
      "MdAE:  3.0119257\n",
      ">>> epoch  11\n",
      " Average training MAE loss: 4.32\n",
      "-\n",
      " Average training MAE loss: 4.27\n",
      "-\n",
      " Average eval MAE loss: 3.56\n",
      "===============================\n",
      "MAE:  3.5811348\n",
      "MdAE:  2.7485619\n",
      ">>> epoch  15\n",
      " Average training MAE loss: 4.29\n",
      "-\n",
      " Average eval MAE loss: 3.56\n",
      "===============================\n",
      "MAE:  3.7608526\n",
      "MdAE:  3.2336683\n",
      ">>> epoch  16\n",
      " Average training MAE loss: 4.30\n",
      "-\n",
      " Average eval MAE loss: 3.56\n",
      "===============================\n",
      "MAE:  3.758625\n",
      "MdAE:  3.230113\n",
      ">>> epoch  17\n",
      " Average training MAE loss: 4.26\n",
      "-\n",
      " Average eval MAE loss: 3.48\n",
      "===============================\n",
      "MAE:  3.6362665\n",
      "MdAE:  3.034809\n",
      ">>> epoch  18\n",
      " Average training MAE loss: 4.29\n",
      "-\n",
      " Average eval MAE loss: 3.62\n",
      "===============================\n",
      "MAE:  3.8640702\n",
      "MdAE:  3.3984203\n",
      ">>> epoch  19\n",
      " Average training MAE loss: 4.26\n",
      "-\n",
      " Average eval MAE loss: 3.55\n",
      "===============================\n",
      "MAE:  3.7439\n",
      "MdAE:  3.2066102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▄▆▅▂▂█▃▂▁▂▁▃▄▃▂▂▂▁▃▂</td></tr><tr><td>test_MAE</td><td>▇▂▂▃▄▁▆▄▃▄▃▅█▆▃▅▅▃▆▅</td></tr><tr><td>test_MdAE</td><td>█▃▃▅▆▁▇▆▆▆▆▇█▇▅▇▇▆▇▆</td></tr><tr><td>train_loss</td><td>██▄▅▂▁▃▂▄▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>3.62193</td></tr><tr><td>best_MAE_train_time</td><td>130.44772</td></tr><tr><td>best_MdAE</td><td>3.01193</td></tr><tr><td>eval_loss</td><td>3.54618</td></tr><tr><td>test_MAE</td><td>3.7439</td></tr><tr><td>test_MdAE</td><td>3.20661</td></tr><tr><td>train_loss</td><td>4.26208</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert_aptanastudio</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/3z09kqv6' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/3z09kqv6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240318_114845-3z09kqv6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done for one project\n",
      "results have been written into a text file!\n",
      "n_embd/hidden_size :  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertSP were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.dense1.weight', 'bert.dense2.weight', 'bert.score.weight', 'bert.transformer.embeddings.LayerNorm.bias', 'bert.transformer.embeddings.LayerNorm.weight', 'bert.transformer.embeddings.position_embeddings.weight', 'bert.transformer.embeddings.token_type_embeddings.weight', 'bert.transformer.embeddings.word_embeddings.weight', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.attention.output.dense.bias', 'bert.transformer.encoder.layer.0.attention.output.dense.weight', 'bert.transformer.encoder.layer.0.attention.self.key.bias', 'bert.transformer.encoder.layer.0.attention.self.key.weight', 'bert.transformer.encoder.layer.0.attention.self.query.bias', 'bert.transformer.encoder.layer.0.attention.self.query.weight', 'bert.transformer.encoder.layer.0.attention.self.value.bias', 'bert.transformer.encoder.layer.0.attention.self.value.weight', 'bert.transformer.encoder.layer.0.intermediate.dense.bias', 'bert.transformer.encoder.layer.0.intermediate.dense.weight', 'bert.transformer.encoder.layer.0.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.output.dense.bias', 'bert.transformer.encoder.layer.0.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.attention.output.dense.bias', 'bert.transformer.encoder.layer.1.attention.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.self.key.bias', 'bert.transformer.encoder.layer.1.attention.self.key.weight', 'bert.transformer.encoder.layer.1.attention.self.query.bias', 'bert.transformer.encoder.layer.1.attention.self.query.weight', 'bert.transformer.encoder.layer.1.attention.self.value.bias', 'bert.transformer.encoder.layer.1.attention.self.value.weight', 'bert.transformer.encoder.layer.1.intermediate.dense.bias', 'bert.transformer.encoder.layer.1.intermediate.dense.weight', 'bert.transformer.encoder.layer.1.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.output.dense.bias', 'bert.transformer.encoder.layer.1.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.attention.output.dense.bias', 'bert.transformer.encoder.layer.10.attention.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.self.key.bias', 'bert.transformer.encoder.layer.10.attention.self.key.weight', 'bert.transformer.encoder.layer.10.attention.self.query.bias', 'bert.transformer.encoder.layer.10.attention.self.query.weight', 'bert.transformer.encoder.layer.10.attention.self.value.bias', 'bert.transformer.encoder.layer.10.attention.self.value.weight', 'bert.transformer.encoder.layer.10.intermediate.dense.bias', 'bert.transformer.encoder.layer.10.intermediate.dense.weight', 'bert.transformer.encoder.layer.10.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.output.dense.bias', 'bert.transformer.encoder.layer.10.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.attention.output.dense.bias', 'bert.transformer.encoder.layer.11.attention.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.self.key.bias', 'bert.transformer.encoder.layer.11.attention.self.key.weight', 'bert.transformer.encoder.layer.11.attention.self.query.bias', 'bert.transformer.encoder.layer.11.attention.self.query.weight', 'bert.transformer.encoder.layer.11.attention.self.value.bias', 'bert.transformer.encoder.layer.11.attention.self.value.weight', 'bert.transformer.encoder.layer.11.intermediate.dense.bias', 'bert.transformer.encoder.layer.11.intermediate.dense.weight', 'bert.transformer.encoder.layer.11.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.output.dense.bias', 'bert.transformer.encoder.layer.11.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.attention.output.dense.bias', 'bert.transformer.encoder.layer.2.attention.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.self.key.bias', 'bert.transformer.encoder.layer.2.attention.self.key.weight', 'bert.transformer.encoder.layer.2.attention.self.query.bias', 'bert.transformer.encoder.layer.2.attention.self.query.weight', 'bert.transformer.encoder.layer.2.attention.self.value.bias', 'bert.transformer.encoder.layer.2.attention.self.value.weight', 'bert.transformer.encoder.layer.2.intermediate.dense.bias', 'bert.transformer.encoder.layer.2.intermediate.dense.weight', 'bert.transformer.encoder.layer.2.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.output.dense.bias', 'bert.transformer.encoder.layer.2.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.attention.output.dense.bias', 'bert.transformer.encoder.layer.3.attention.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.self.key.bias', 'bert.transformer.encoder.layer.3.attention.self.key.weight', 'bert.transformer.encoder.layer.3.attention.self.query.bias', 'bert.transformer.encoder.layer.3.attention.self.query.weight', 'bert.transformer.encoder.layer.3.attention.self.value.bias', 'bert.transformer.encoder.layer.3.attention.self.value.weight', 'bert.transformer.encoder.layer.3.intermediate.dense.bias', 'bert.transformer.encoder.layer.3.intermediate.dense.weight', 'bert.transformer.encoder.layer.3.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.output.dense.bias', 'bert.transformer.encoder.layer.3.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.attention.output.dense.bias', 'bert.transformer.encoder.layer.4.attention.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.self.key.bias', 'bert.transformer.encoder.layer.4.attention.self.key.weight', 'bert.transformer.encoder.layer.4.attention.self.query.bias', 'bert.transformer.encoder.layer.4.attention.self.query.weight', 'bert.transformer.encoder.layer.4.attention.self.value.bias', 'bert.transformer.encoder.layer.4.attention.self.value.weight', 'bert.transformer.encoder.layer.4.intermediate.dense.bias', 'bert.transformer.encoder.layer.4.intermediate.dense.weight', 'bert.transformer.encoder.layer.4.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.output.dense.bias', 'bert.transformer.encoder.layer.4.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.attention.output.dense.bias', 'bert.transformer.encoder.layer.5.attention.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.self.key.bias', 'bert.transformer.encoder.layer.5.attention.self.key.weight', 'bert.transformer.encoder.layer.5.attention.self.query.bias', 'bert.transformer.encoder.layer.5.attention.self.query.weight', 'bert.transformer.encoder.layer.5.attention.self.value.bias', 'bert.transformer.encoder.layer.5.attention.self.value.weight', 'bert.transformer.encoder.layer.5.intermediate.dense.bias', 'bert.transformer.encoder.layer.5.intermediate.dense.weight', 'bert.transformer.encoder.layer.5.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.output.dense.bias', 'bert.transformer.encoder.layer.5.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.attention.output.dense.bias', 'bert.transformer.encoder.layer.6.attention.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.self.key.bias', 'bert.transformer.encoder.layer.6.attention.self.key.weight', 'bert.transformer.encoder.layer.6.attention.self.query.bias', 'bert.transformer.encoder.layer.6.attention.self.query.weight', 'bert.transformer.encoder.layer.6.attention.self.value.bias', 'bert.transformer.encoder.layer.6.attention.self.value.weight', 'bert.transformer.encoder.layer.6.intermediate.dense.bias', 'bert.transformer.encoder.layer.6.intermediate.dense.weight', 'bert.transformer.encoder.layer.6.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.output.dense.bias', 'bert.transformer.encoder.layer.6.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.attention.output.dense.bias', 'bert.transformer.encoder.layer.7.attention.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.self.key.bias', 'bert.transformer.encoder.layer.7.attention.self.key.weight', 'bert.transformer.encoder.layer.7.attention.self.query.bias', 'bert.transformer.encoder.layer.7.attention.self.query.weight', 'bert.transformer.encoder.layer.7.attention.self.value.bias', 'bert.transformer.encoder.layer.7.attention.self.value.weight', 'bert.transformer.encoder.layer.7.intermediate.dense.bias', 'bert.transformer.encoder.layer.7.intermediate.dense.weight', 'bert.transformer.encoder.layer.7.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.output.dense.bias', 'bert.transformer.encoder.layer.7.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.attention.output.dense.bias', 'bert.transformer.encoder.layer.8.attention.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.self.key.bias', 'bert.transformer.encoder.layer.8.attention.self.key.weight', 'bert.transformer.encoder.layer.8.attention.self.query.bias', 'bert.transformer.encoder.layer.8.attention.self.query.weight', 'bert.transformer.encoder.layer.8.attention.self.value.bias', 'bert.transformer.encoder.layer.8.attention.self.value.weight', 'bert.transformer.encoder.layer.8.intermediate.dense.bias', 'bert.transformer.encoder.layer.8.intermediate.dense.weight', 'bert.transformer.encoder.layer.8.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.output.dense.bias', 'bert.transformer.encoder.layer.8.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.attention.output.dense.bias', 'bert.transformer.encoder.layer.9.attention.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.self.key.bias', 'bert.transformer.encoder.layer.9.attention.self.key.weight', 'bert.transformer.encoder.layer.9.attention.self.query.bias', 'bert.transformer.encoder.layer.9.attention.self.query.weight', 'bert.transformer.encoder.layer.9.attention.self.value.bias', 'bert.transformer.encoder.layer.9.attention.self.value.weight', 'bert.transformer.encoder.layer.9.intermediate.dense.bias', 'bert.transformer.encoder.layer.9.intermediate.dense.weight', 'bert.transformer.encoder.layer.9.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.output.dense.bias', 'bert.transformer.encoder.layer.9.output.dense.weight', 'bert.transformer.pooler.dense.bias', 'bert.transformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/tmp/ipykernel_6207/1214379779.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text : title+description\n",
      "Input data feed :::  [CLS]Allows CVS repo to timeout and report on locking issues[SEP]Sometimes, when you perform a CVS action you get something like    {noformat}  cvs update: [01:38:32] waiting for mchai's lock in /cvsroot/atlassian/maven2test/bamboo  {noformat}    so Bamboo would probably just hang and become not so happy. We should allow Bamboo to timeout, or conditionally stop and tell the user how to dix the problem[SEP]\n",
      "within project split!\n",
      "usingbert tokenizer\n",
      "usingbert tokenizer\n",
      "tensor([[  101,   101,  4473, 26226,  2015, 16360,  2080,  2000,  2051,  5833,\n",
      "          1998,  3189,  2006, 14889,  3314,   102,  2823,  1010,  2043,  2017,\n",
      "          4685,  1037, 26226,  2015,  2895,  2017,  2131,  2242,  2066,  1063,\n",
      "          2053, 14192,  4017,  1065, 26226,  2015, 10651,  1024,  1031,  5890,\n",
      "          1024,  4229,  1024,  3590,  1033,  3403,  2005, 11338, 10932,  1005,\n",
      "          1055,  5843,  1999,  1013, 26226, 21338, 17206,  1013, 11568, 17043,\n",
      "          1013,  5003,  8159,  2475, 22199,  1013, 15216,  1063,  2053, 14192,\n",
      "          4017,  1065,  2061, 15216,  2052,  2763,  2074,  6865,  1998,  2468,\n",
      "          2025,  2061,  3407,  1012,  2057,  2323,  3499, 15216,  2000,  2051,\n",
      "          5833,  1010,  2030, 18462,  2135,  2644,  1998,  2425,  1996,   102],\n",
      "        [  101,   101,  3499,  1037,  3857,  2000,  2022,  2872,  2012,  1996,\n",
      "          2132,  1997,  1996,  3857, 24240,  1012,  1012,  1012,  1006,  2030,\n",
      "         10086,  1996, 24240,  2344,  1007,   102,   102,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  2765,  2025,  5552,  2043,  4638,  5833, 11896,   102,\n",
      "          3047,  7483,  2006,  2256,  4354, 15216,  1024, 16770,  1024,  1013,\n",
      "          1013, 21942,  1012, 15216,  2475,  1012, 11568, 17043,  1012,  4012,\n",
      "          1013, 11347,  2063,  1013, 20014,  1011, 24529,  2102, 15216,  2001,\n",
      "          9725,  2013,  1016,  1012,  1014,  1012,  1019,  2000,  1016,  1012,\n",
      "          2321,  1045,  2018,  3857,  8833,  7696,  2066,  1024,  1063,  2053,\n",
      "         14192,  4017,  1065,  2756,  1011,  5553,  1011,  2268,  6021,  1024,\n",
      "          2260,  1024,  2603,  3857, 20014,  1011, 24529,  2102,  1011, 10114,\n",
      "          2581,  2318,  2311,  2006,  4005, 12398,  4005,  2756,  1011,  5553,\n",
      "          1011,  2268,  6021,  1024,  2260,  1024,  2603,  2039, 16616,   102],\n",
      "        [  101,   101,  2831,  5963,  2013, 21274,  4005,  2000, 15216,  8241,\n",
      "          2000,  2421,  1041,  5910,  3872,  4057,  3463,   102,  2043,  2019,\n",
      "         21274,  6013,  1013,  4005,  2003, 26928,  2000,  4057,  1037,  1041,\n",
      "          5910,  3872,  4820,  1037, 20057, 12326,  2076, 22752,  1996,  5082,\n",
      "          1013,  3112,  1013,  8246,  2323,  2022,  7349,  2067,  2000, 15216,\n",
      "          8241,  2005,  4653,  1012,  1996,  8833,  1999,  1013,  1056,  8737,\n",
      "          1013, 16437, 15878,  4757,  2532,  4523, 12326,  1012,  8833,  2071,\n",
      "          2022,  2109,  2000,  2832,  5082,  1998,  3463,  1012,   102,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  5198,  2064,  2156,  1996,  5003,  8159, 11336,  1006,\n",
      "          2177,  3593,  1010, 20785,  3593,  1010,  2544,  1007,  2114,  2169,\n",
      "          2933,  1012,   102,  1008,  2323,  4847,  1996,  4942,  1011,  2551,\n",
      "         14176,  1012,  2069,  2298,  2005, 13433,  5244,  2104,  1996,  4942,\n",
      "          1011,  2551, 14176,  1008,  2069,  3191,  2327,  2504, 13433,  2213,\n",
      "          2005, 14184,  1008, 13433,  2213,  2003,  3191,  2069,  2043,  2311,\n",
      "          1012,  1008,  2023,  2003,  2069,  3191,  2069,  1008,  2169,  2933,\n",
      "          2089,  2031,  3674, 10471,   102,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "BATCH_SIZE :  15\n",
      "BATCH_SIZE :  15\n",
      "usingbert tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_6207/1214379779.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_seq = torch.tensor(tokens_test['input_ids'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE :  15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/gpt2sp/wandb/run-20240318_115305-2u02kwgn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/2u02kwgn' target=\"_blank\">bert_bamboo</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/2u02kwgn' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/2u02kwgn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for  {'train': ['bamboo'], 'test': ['bamboo']} .....\n",
      ">>> epoch  0\n",
      " Average training MAE loss: 1.83\n",
      "-\n",
      " Average eval MAE loss: 0.99\n",
      "===============================\n",
      "MAE:  1.0221175\n",
      "MdAE:  0.5199604\n",
      ">>> epoch  1\n",
      " Average training MAE loss: 1.52\n",
      "-\n",
      " Average eval MAE loss: 0.89\n",
      "===============================\n",
      "MAE:  0.93849534\n",
      "MdAE:  0.6687796\n",
      ">>> epoch  2\n",
      " Average training MAE loss: 1.48\n",
      "-\n",
      " Average eval MAE loss: 1.29\n",
      "===============================\n",
      "MAE:  1.2582061\n",
      "MdAE:  0.9001975\n",
      ">>> epoch  3\n",
      " Average training MAE loss: 1.47\n",
      "-\n",
      " Average eval MAE loss: 0.67\n",
      "===============================\n",
      "MAE:  0.7650599\n",
      "MdAE:  0.9774358\n",
      ">>> epoch  4\n",
      " Average training MAE loss: 1.51\n",
      "-\n",
      " Average eval MAE loss: 1.19\n",
      "===============================\n",
      "MAE:  1.1778575\n",
      "MdAE:  0.75720406\n",
      ">>> epoch  5\n",
      " Average training MAE loss: 1.47\n",
      "-\n",
      " Average eval MAE loss: 0.94\n",
      "===============================\n",
      "MAE:  0.9762532\n",
      "MdAE:  0.6015835\n",
      ">>> epoch  6\n",
      " Average training MAE loss: 1.50\n",
      "-\n",
      " Average eval MAE loss: 0.72\n",
      "===============================\n",
      "MAE:  0.8045562\n",
      "MdAE:  0.90714574\n",
      ">>> epoch  7\n",
      " Average training MAE loss: 1.45\n",
      "-\n",
      " Average eval MAE loss: 0.74\n",
      "===============================\n",
      "MAE:  0.8204783\n",
      "MdAE:  0.8788097\n",
      ">>> epoch  8\n",
      " Average training MAE loss: 1.51\n",
      "-\n",
      " Average eval MAE loss: 1.08\n",
      "===============================\n",
      "MAE:  1.0901424\n",
      "MdAE:  0.6011014\n",
      ">>> epoch  9\n",
      " Average training MAE loss: 1.47\n",
      "-\n",
      " Average eval MAE loss: 0.89\n",
      "===============================\n",
      "MAE:  0.941782\n",
      "MdAE:  0.66293025\n",
      ">>> epoch  10\n",
      " Average training MAE loss: 1.44\n",
      "-\n",
      " Average eval MAE loss: 0.70\n",
      "===============================\n",
      "MAE:  0.788336\n",
      "MdAE:  0.9360125\n",
      ">>> epoch  11\n",
      " Average training MAE loss: 1.44\n",
      "-\n",
      " Average eval MAE loss: 0.70\n",
      "===============================\n",
      "MAE:  0.7924089\n",
      "MdAE:  0.92876387\n",
      ">>> epoch  12\n",
      " Average training MAE loss: 1.43\n",
      "-\n",
      " Average eval MAE loss: 0.82\n",
      "===============================\n",
      "MAE:  0.88493854\n",
      "MdAE:  0.76409245\n",
      ">>> epoch  13\n",
      " Average training MAE loss: 1.45\n",
      "-\n",
      " Average eval MAE loss: 0.78\n",
      "===============================\n",
      "MAE:  0.8558197\n",
      "MdAE:  0.8159139\n",
      ">>> epoch  14\n",
      " Average training MAE loss: 1.44\n",
      "-\n",
      " Average eval MAE loss: 0.69\n",
      "===============================\n",
      "MAE:  0.7857027\n",
      "MdAE:  0.9406986\n",
      ">>> epoch  15\n",
      " Average training MAE loss: 1.42\n",
      "-\n",
      " Average eval MAE loss: 0.75\n",
      "===============================\n",
      "MAE:  0.8266644\n",
      "MdAE:  0.8678007\n",
      ">>> epoch  16\n",
      " Average training MAE loss: 1.41\n",
      "-\n",
      " Average eval MAE loss: 0.77\n",
      "===============================\n",
      "MAE:  0.84469646\n",
      "MdAE:  0.8357098\n",
      ">>> epoch  17\n",
      " Average training MAE loss: 1.42\n",
      "-\n",
      " Average eval MAE loss: 0.78\n",
      "===============================\n",
      "MAE:  0.85481435\n",
      "MdAE:  0.8177035\n",
      ">>> epoch  18\n",
      " Average training MAE loss: 1.40\n",
      "-\n",
      " Average eval MAE loss: 0.75\n",
      "===============================\n",
      "MAE:  0.83245474\n",
      "MdAE:  0.8574958\n",
      ">>> epoch  19\n",
      " Average training MAE loss: 1.42\n",
      "-\n",
      " Average eval MAE loss: 0.73\n",
      "===============================\n",
      "MAE:  0.81301594\n",
      "MdAE:  0.8920903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▅▃█▁▇▄▂▂▆▄▁▁▃▂▁▂▂▂▂▂</td></tr><tr><td>test_MAE</td><td>▅▃█▁▇▄▂▂▆▄▁▁▃▂▁▂▂▂▂▂</td></tr><tr><td>test_MdAE</td><td>▁▃▇█▅▂▇▆▂▃▇▇▅▆▇▆▆▆▆▇</td></tr><tr><td>train_loss</td><td>█▃▂▂▃▂▃▂▃▂▂▂▁▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>0.76506</td></tr><tr><td>best_MAE_train_time</td><td>30.69886</td></tr><tr><td>best_MdAE</td><td>0.97744</td></tr><tr><td>eval_loss</td><td>0.72917</td></tr><tr><td>test_MAE</td><td>0.81302</td></tr><tr><td>test_MdAE</td><td>0.89209</td></tr><tr><td>train_loss</td><td>1.41999</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert_bamboo</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/2u02kwgn' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/2u02kwgn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240318_115305-2u02kwgn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done for one project\n",
      "results have been written into a text file!\n",
      "n_embd/hidden_size :  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertSP were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.dense1.weight', 'bert.dense2.weight', 'bert.score.weight', 'bert.transformer.embeddings.LayerNorm.bias', 'bert.transformer.embeddings.LayerNorm.weight', 'bert.transformer.embeddings.position_embeddings.weight', 'bert.transformer.embeddings.token_type_embeddings.weight', 'bert.transformer.embeddings.word_embeddings.weight', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.attention.output.dense.bias', 'bert.transformer.encoder.layer.0.attention.output.dense.weight', 'bert.transformer.encoder.layer.0.attention.self.key.bias', 'bert.transformer.encoder.layer.0.attention.self.key.weight', 'bert.transformer.encoder.layer.0.attention.self.query.bias', 'bert.transformer.encoder.layer.0.attention.self.query.weight', 'bert.transformer.encoder.layer.0.attention.self.value.bias', 'bert.transformer.encoder.layer.0.attention.self.value.weight', 'bert.transformer.encoder.layer.0.intermediate.dense.bias', 'bert.transformer.encoder.layer.0.intermediate.dense.weight', 'bert.transformer.encoder.layer.0.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.output.dense.bias', 'bert.transformer.encoder.layer.0.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.attention.output.dense.bias', 'bert.transformer.encoder.layer.1.attention.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.self.key.bias', 'bert.transformer.encoder.layer.1.attention.self.key.weight', 'bert.transformer.encoder.layer.1.attention.self.query.bias', 'bert.transformer.encoder.layer.1.attention.self.query.weight', 'bert.transformer.encoder.layer.1.attention.self.value.bias', 'bert.transformer.encoder.layer.1.attention.self.value.weight', 'bert.transformer.encoder.layer.1.intermediate.dense.bias', 'bert.transformer.encoder.layer.1.intermediate.dense.weight', 'bert.transformer.encoder.layer.1.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.output.dense.bias', 'bert.transformer.encoder.layer.1.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.attention.output.dense.bias', 'bert.transformer.encoder.layer.10.attention.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.self.key.bias', 'bert.transformer.encoder.layer.10.attention.self.key.weight', 'bert.transformer.encoder.layer.10.attention.self.query.bias', 'bert.transformer.encoder.layer.10.attention.self.query.weight', 'bert.transformer.encoder.layer.10.attention.self.value.bias', 'bert.transformer.encoder.layer.10.attention.self.value.weight', 'bert.transformer.encoder.layer.10.intermediate.dense.bias', 'bert.transformer.encoder.layer.10.intermediate.dense.weight', 'bert.transformer.encoder.layer.10.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.output.dense.bias', 'bert.transformer.encoder.layer.10.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.attention.output.dense.bias', 'bert.transformer.encoder.layer.11.attention.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.self.key.bias', 'bert.transformer.encoder.layer.11.attention.self.key.weight', 'bert.transformer.encoder.layer.11.attention.self.query.bias', 'bert.transformer.encoder.layer.11.attention.self.query.weight', 'bert.transformer.encoder.layer.11.attention.self.value.bias', 'bert.transformer.encoder.layer.11.attention.self.value.weight', 'bert.transformer.encoder.layer.11.intermediate.dense.bias', 'bert.transformer.encoder.layer.11.intermediate.dense.weight', 'bert.transformer.encoder.layer.11.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.output.dense.bias', 'bert.transformer.encoder.layer.11.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.attention.output.dense.bias', 'bert.transformer.encoder.layer.2.attention.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.self.key.bias', 'bert.transformer.encoder.layer.2.attention.self.key.weight', 'bert.transformer.encoder.layer.2.attention.self.query.bias', 'bert.transformer.encoder.layer.2.attention.self.query.weight', 'bert.transformer.encoder.layer.2.attention.self.value.bias', 'bert.transformer.encoder.layer.2.attention.self.value.weight', 'bert.transformer.encoder.layer.2.intermediate.dense.bias', 'bert.transformer.encoder.layer.2.intermediate.dense.weight', 'bert.transformer.encoder.layer.2.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.output.dense.bias', 'bert.transformer.encoder.layer.2.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.attention.output.dense.bias', 'bert.transformer.encoder.layer.3.attention.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.self.key.bias', 'bert.transformer.encoder.layer.3.attention.self.key.weight', 'bert.transformer.encoder.layer.3.attention.self.query.bias', 'bert.transformer.encoder.layer.3.attention.self.query.weight', 'bert.transformer.encoder.layer.3.attention.self.value.bias', 'bert.transformer.encoder.layer.3.attention.self.value.weight', 'bert.transformer.encoder.layer.3.intermediate.dense.bias', 'bert.transformer.encoder.layer.3.intermediate.dense.weight', 'bert.transformer.encoder.layer.3.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.output.dense.bias', 'bert.transformer.encoder.layer.3.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.attention.output.dense.bias', 'bert.transformer.encoder.layer.4.attention.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.self.key.bias', 'bert.transformer.encoder.layer.4.attention.self.key.weight', 'bert.transformer.encoder.layer.4.attention.self.query.bias', 'bert.transformer.encoder.layer.4.attention.self.query.weight', 'bert.transformer.encoder.layer.4.attention.self.value.bias', 'bert.transformer.encoder.layer.4.attention.self.value.weight', 'bert.transformer.encoder.layer.4.intermediate.dense.bias', 'bert.transformer.encoder.layer.4.intermediate.dense.weight', 'bert.transformer.encoder.layer.4.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.output.dense.bias', 'bert.transformer.encoder.layer.4.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.attention.output.dense.bias', 'bert.transformer.encoder.layer.5.attention.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.self.key.bias', 'bert.transformer.encoder.layer.5.attention.self.key.weight', 'bert.transformer.encoder.layer.5.attention.self.query.bias', 'bert.transformer.encoder.layer.5.attention.self.query.weight', 'bert.transformer.encoder.layer.5.attention.self.value.bias', 'bert.transformer.encoder.layer.5.attention.self.value.weight', 'bert.transformer.encoder.layer.5.intermediate.dense.bias', 'bert.transformer.encoder.layer.5.intermediate.dense.weight', 'bert.transformer.encoder.layer.5.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.output.dense.bias', 'bert.transformer.encoder.layer.5.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.attention.output.dense.bias', 'bert.transformer.encoder.layer.6.attention.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.self.key.bias', 'bert.transformer.encoder.layer.6.attention.self.key.weight', 'bert.transformer.encoder.layer.6.attention.self.query.bias', 'bert.transformer.encoder.layer.6.attention.self.query.weight', 'bert.transformer.encoder.layer.6.attention.self.value.bias', 'bert.transformer.encoder.layer.6.attention.self.value.weight', 'bert.transformer.encoder.layer.6.intermediate.dense.bias', 'bert.transformer.encoder.layer.6.intermediate.dense.weight', 'bert.transformer.encoder.layer.6.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.output.dense.bias', 'bert.transformer.encoder.layer.6.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.attention.output.dense.bias', 'bert.transformer.encoder.layer.7.attention.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.self.key.bias', 'bert.transformer.encoder.layer.7.attention.self.key.weight', 'bert.transformer.encoder.layer.7.attention.self.query.bias', 'bert.transformer.encoder.layer.7.attention.self.query.weight', 'bert.transformer.encoder.layer.7.attention.self.value.bias', 'bert.transformer.encoder.layer.7.attention.self.value.weight', 'bert.transformer.encoder.layer.7.intermediate.dense.bias', 'bert.transformer.encoder.layer.7.intermediate.dense.weight', 'bert.transformer.encoder.layer.7.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.output.dense.bias', 'bert.transformer.encoder.layer.7.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.attention.output.dense.bias', 'bert.transformer.encoder.layer.8.attention.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.self.key.bias', 'bert.transformer.encoder.layer.8.attention.self.key.weight', 'bert.transformer.encoder.layer.8.attention.self.query.bias', 'bert.transformer.encoder.layer.8.attention.self.query.weight', 'bert.transformer.encoder.layer.8.attention.self.value.bias', 'bert.transformer.encoder.layer.8.attention.self.value.weight', 'bert.transformer.encoder.layer.8.intermediate.dense.bias', 'bert.transformer.encoder.layer.8.intermediate.dense.weight', 'bert.transformer.encoder.layer.8.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.output.dense.bias', 'bert.transformer.encoder.layer.8.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.attention.output.dense.bias', 'bert.transformer.encoder.layer.9.attention.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.self.key.bias', 'bert.transformer.encoder.layer.9.attention.self.key.weight', 'bert.transformer.encoder.layer.9.attention.self.query.bias', 'bert.transformer.encoder.layer.9.attention.self.query.weight', 'bert.transformer.encoder.layer.9.attention.self.value.bias', 'bert.transformer.encoder.layer.9.attention.self.value.weight', 'bert.transformer.encoder.layer.9.intermediate.dense.bias', 'bert.transformer.encoder.layer.9.intermediate.dense.weight', 'bert.transformer.encoder.layer.9.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.output.dense.bias', 'bert.transformer.encoder.layer.9.output.dense.weight', 'bert.transformer.pooler.dense.bias', 'bert.transformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/tmp/ipykernel_6207/1214379779.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text : title+description\n",
      "Input data feed :::  [CLS]Line coverage data is inconsistent[SEP]I'm running 2.4.1 on IDEA 7 and get inconsistent line and branch coverage in the editor: every line that is hit by the a test always gets \"1\" as the hitcount.  [SEP]\n",
      "within project split!\n",
      "usingbert tokenizer\n",
      "usingbert tokenizer\n",
      "tensor([[  101,   101,  2240,  6325,  2951,  2003, 20316,   102,  1045,  1005,\n",
      "          1049,  2770,  1016,  1012,  1018,  1012,  1015,  2006,  2801,  1021,\n",
      "          1998,  2131, 20316,  2240,  1998,  3589,  6325,  1999,  1996,  3559,\n",
      "          1024,  2296,  2240,  2008,  2003,  2718,  2011,  1996,  1037,  3231,\n",
      "          2467,  4152,  1000,  1015,  1000,  2004,  1996,  2718,  3597, 16671,\n",
      "          1012,   102,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  2469, 10273,  2465, 15069,  2003, 16542,  2043,  5834,\n",
      "          2006,  1037, 15723,  1998,  1037,  3231,  1011, 15723,  2013,  1996,\n",
      "          2168,  5003,  8159, 11336,   102,  2057,  2031,  2048,  2367,  5097,\n",
      "          2008,  2031,  1996,  2168, 25353, 27718,  5358,  1012,  2037,  3231,\n",
      "          3572,  2147,  7919,  2043,  6472,  2302, 25133,  1010,  2021,  2043,\n",
      "          2057,  2448,  2068,  2007, 25133,  1010,  2027,  8246,  2138,  4280,\n",
      "          2030,  7692,  6764,  2024,  4394,  2013,  1996,  2465, 15069,  1012,\n",
      "          2043,  2770,  1996, 16473,  2007, 25133,  1010,  1996,  3231,  3572,\n",
      "          2024,  6472,  3674,  2335,  1012,  2069,  1996,  2197,  2051,  2027,\n",
      "          2448,  2027,  8246,  1012,  2043,  9361,  1996,  5003,  8159,   102],\n",
      "        [  101,   101,  4292,  2569, 16015,  6434, 16101,  2000,  1037,  3120,\n",
      "         16101,  3972, 12870,  2015,  2035,  3120,   999,   102,   102,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  5587,  4118,  1013,  4861,  2504, 16015,  4292,  1999,\n",
      "          2622,  5144,  3931,   102,   102,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  2191,  3231,  2448, 10566,  4685,  2488,  1998,  2644,\n",
      "         14889,  1996, 21318, 11689,   102,   102,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "BATCH_SIZE :  11\n",
      "BATCH_SIZE :  11\n",
      "usingbert tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_6207/1214379779.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_seq = torch.tensor(tokens_test['input_ids'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE :  11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/gpt2sp/wandb/run-20240318_115605-c5heo308</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/c5heo308' target=\"_blank\">bert_clover</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/c5heo308' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/c5heo308</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for  {'train': ['clover'], 'test': ['clover']} .....\n",
      ">>> epoch  0\n",
      " Average training MAE loss: 4.17\n",
      "-\n",
      " Average eval MAE loss: 3.30\n",
      "===============================\n",
      "MAE:  4.564216\n",
      "MdAE:  3.1015806\n",
      ">>> epoch  1\n",
      " Average training MAE loss: 3.62\n",
      "-\n",
      " Average eval MAE loss: 2.94\n",
      "===============================\n",
      "MAE:  4.295474\n",
      "MdAE:  3.3071852\n",
      ">>> epoch  2\n",
      " Average training MAE loss: 3.66\n",
      "-\n",
      " Average eval MAE loss: 2.94\n",
      "===============================\n",
      "MAE:  4.292211\n",
      "MdAE:  3.300006\n",
      ">>> epoch  3\n",
      " Average training MAE loss: 3.56\n",
      "-\n",
      " Average eval MAE loss: 2.35\n",
      "===============================\n",
      "MAE:  3.8867881\n",
      "MdAE:  2.3316996\n",
      ">>> epoch  4\n",
      " Average training MAE loss: 3.50\n",
      "-\n",
      " Average eval MAE loss: 2.08\n",
      "===============================\n",
      "MAE:  3.7082222\n",
      "MdAE:  1.614789\n",
      ">>> epoch  5\n",
      " Average training MAE loss: 3.50\n",
      "-\n",
      " Average eval MAE loss: 1.98\n",
      "===============================\n",
      "MAE:  3.6413138\n",
      "MdAE:  1.0423503\n",
      ">>> epoch  6\n",
      " Average training MAE loss: 3.47\n",
      "-\n",
      " Average eval MAE loss: 1.98\n",
      "===============================\n",
      "MAE:  3.6426995\n",
      "MdAE:  1.0542059\n",
      ">>> epoch  7\n",
      " Average training MAE loss: 3.48\n",
      "-\n",
      " Average eval MAE loss: 2.04\n",
      "===============================\n",
      "MAE:  3.683331\n",
      "MdAE:  1.4018295\n",
      ">>> epoch  8\n",
      " Average training MAE loss: 3.61\n",
      "-\n",
      " Average eval MAE loss: 1.98\n",
      "===============================\n",
      "MAE:  3.6436977\n",
      "MdAE:  0.9774108\n",
      ">>> epoch  9\n",
      " Average training MAE loss: 3.59\n",
      "-\n",
      " Average eval MAE loss: 2.05\n",
      "===============================\n",
      "MAE:  3.6872725\n",
      "MdAE:  1.4355531\n",
      ">>> epoch  10\n",
      " Average training MAE loss: 3.50\n",
      "-\n",
      " Average eval MAE loss: 2.13\n",
      "===============================\n",
      "MAE:  3.7458572\n",
      "MdAE:  1.9367762\n",
      ">>> epoch  11\n",
      " Average training MAE loss: 3.48\n",
      "-\n",
      " Average eval MAE loss: 2.21\n",
      "===============================\n",
      "MAE:  3.7959924\n",
      "MdAE:  2.1061745\n",
      ">>> epoch  12\n",
      " Average training MAE loss: 3.52\n",
      "-\n",
      " Average eval MAE loss: 2.02\n",
      "===============================\n",
      "MAE:  3.667906\n",
      "MdAE:  1.2698641\n",
      ">>> epoch  13\n",
      " Average training MAE loss: 3.48\n",
      "-\n",
      " Average eval MAE loss: 2.22\n",
      "===============================\n",
      "MAE:  3.80566\n",
      "MdAE:  2.130188\n",
      ">>> epoch  14\n",
      " Average training MAE loss: 3.48\n",
      "-\n",
      " Average eval MAE loss: 2.24\n",
      "===============================\n",
      "MAE:  3.8184915\n",
      "MdAE:  2.1620593\n",
      ">>> epoch  15\n",
      " Average training MAE loss: 3.47\n",
      "-\n",
      " Average eval MAE loss: 2.09\n",
      "===============================\n",
      "MAE:  3.7175467\n",
      "MdAE:  1.6945701\n",
      ">>> epoch  16\n",
      " Average training MAE loss: 3.47\n",
      "-\n",
      " Average eval MAE loss: 2.01\n",
      "===============================\n",
      "MAE:  3.6601348\n",
      "MdAE:  1.2033749\n",
      ">>> epoch  17\n",
      " Average training MAE loss: 3.49\n",
      "-\n",
      " Average eval MAE loss: 2.00\n",
      "===============================\n",
      "MAE:  3.6558921\n",
      "MdAE:  1.1670785\n",
      ">>> epoch  18\n",
      " Average training MAE loss: 3.48\n",
      "-\n",
      " Average eval MAE loss: 2.01\n",
      "===============================\n",
      "MAE:  3.6645079\n",
      "MdAE:  1.2407906\n",
      ">>> epoch  19\n",
      " Average training MAE loss: 3.47\n",
      "-\n",
      " Average eval MAE loss: 2.04\n",
      "===============================\n",
      "MAE:  3.682532\n",
      "MdAE:  1.3949938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>█▆▆▃▂▁▁▁▁▁▂▂▁▂▂▂▁▁▁▁</td></tr><tr><td>test_MAE</td><td>█▆▆▃▂▁▁▁▁▁▂▂▁▂▂▂▁▁▁▁</td></tr><tr><td>test_MdAE</td><td>▇██▅▃▁▁▂▁▂▄▄▂▄▅▃▂▂▂▂</td></tr><tr><td>train_loss</td><td>█▃▃▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>3.6437</td></tr><tr><td>best_MAE_train_time</td><td>57.57454</td></tr><tr><td>best_MdAE</td><td>0.97741</td></tr><tr><td>eval_loss</td><td>2.04071</td></tr><tr><td>test_MAE</td><td>3.68253</td></tr><tr><td>test_MdAE</td><td>1.39499</td></tr><tr><td>train_loss</td><td>3.46858</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert_clover</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/c5heo308' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/c5heo308</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240318_115605-c5heo308/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done for one project\n",
      "results have been written into a text file!\n",
      "n_embd/hidden_size :  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertSP were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.dense1.weight', 'bert.dense2.weight', 'bert.score.weight', 'bert.transformer.embeddings.LayerNorm.bias', 'bert.transformer.embeddings.LayerNorm.weight', 'bert.transformer.embeddings.position_embeddings.weight', 'bert.transformer.embeddings.token_type_embeddings.weight', 'bert.transformer.embeddings.word_embeddings.weight', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.attention.output.dense.bias', 'bert.transformer.encoder.layer.0.attention.output.dense.weight', 'bert.transformer.encoder.layer.0.attention.self.key.bias', 'bert.transformer.encoder.layer.0.attention.self.key.weight', 'bert.transformer.encoder.layer.0.attention.self.query.bias', 'bert.transformer.encoder.layer.0.attention.self.query.weight', 'bert.transformer.encoder.layer.0.attention.self.value.bias', 'bert.transformer.encoder.layer.0.attention.self.value.weight', 'bert.transformer.encoder.layer.0.intermediate.dense.bias', 'bert.transformer.encoder.layer.0.intermediate.dense.weight', 'bert.transformer.encoder.layer.0.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.output.dense.bias', 'bert.transformer.encoder.layer.0.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.attention.output.dense.bias', 'bert.transformer.encoder.layer.1.attention.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.self.key.bias', 'bert.transformer.encoder.layer.1.attention.self.key.weight', 'bert.transformer.encoder.layer.1.attention.self.query.bias', 'bert.transformer.encoder.layer.1.attention.self.query.weight', 'bert.transformer.encoder.layer.1.attention.self.value.bias', 'bert.transformer.encoder.layer.1.attention.self.value.weight', 'bert.transformer.encoder.layer.1.intermediate.dense.bias', 'bert.transformer.encoder.layer.1.intermediate.dense.weight', 'bert.transformer.encoder.layer.1.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.output.dense.bias', 'bert.transformer.encoder.layer.1.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.attention.output.dense.bias', 'bert.transformer.encoder.layer.10.attention.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.self.key.bias', 'bert.transformer.encoder.layer.10.attention.self.key.weight', 'bert.transformer.encoder.layer.10.attention.self.query.bias', 'bert.transformer.encoder.layer.10.attention.self.query.weight', 'bert.transformer.encoder.layer.10.attention.self.value.bias', 'bert.transformer.encoder.layer.10.attention.self.value.weight', 'bert.transformer.encoder.layer.10.intermediate.dense.bias', 'bert.transformer.encoder.layer.10.intermediate.dense.weight', 'bert.transformer.encoder.layer.10.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.output.dense.bias', 'bert.transformer.encoder.layer.10.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.attention.output.dense.bias', 'bert.transformer.encoder.layer.11.attention.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.self.key.bias', 'bert.transformer.encoder.layer.11.attention.self.key.weight', 'bert.transformer.encoder.layer.11.attention.self.query.bias', 'bert.transformer.encoder.layer.11.attention.self.query.weight', 'bert.transformer.encoder.layer.11.attention.self.value.bias', 'bert.transformer.encoder.layer.11.attention.self.value.weight', 'bert.transformer.encoder.layer.11.intermediate.dense.bias', 'bert.transformer.encoder.layer.11.intermediate.dense.weight', 'bert.transformer.encoder.layer.11.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.output.dense.bias', 'bert.transformer.encoder.layer.11.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.attention.output.dense.bias', 'bert.transformer.encoder.layer.2.attention.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.self.key.bias', 'bert.transformer.encoder.layer.2.attention.self.key.weight', 'bert.transformer.encoder.layer.2.attention.self.query.bias', 'bert.transformer.encoder.layer.2.attention.self.query.weight', 'bert.transformer.encoder.layer.2.attention.self.value.bias', 'bert.transformer.encoder.layer.2.attention.self.value.weight', 'bert.transformer.encoder.layer.2.intermediate.dense.bias', 'bert.transformer.encoder.layer.2.intermediate.dense.weight', 'bert.transformer.encoder.layer.2.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.output.dense.bias', 'bert.transformer.encoder.layer.2.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.attention.output.dense.bias', 'bert.transformer.encoder.layer.3.attention.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.self.key.bias', 'bert.transformer.encoder.layer.3.attention.self.key.weight', 'bert.transformer.encoder.layer.3.attention.self.query.bias', 'bert.transformer.encoder.layer.3.attention.self.query.weight', 'bert.transformer.encoder.layer.3.attention.self.value.bias', 'bert.transformer.encoder.layer.3.attention.self.value.weight', 'bert.transformer.encoder.layer.3.intermediate.dense.bias', 'bert.transformer.encoder.layer.3.intermediate.dense.weight', 'bert.transformer.encoder.layer.3.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.output.dense.bias', 'bert.transformer.encoder.layer.3.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.attention.output.dense.bias', 'bert.transformer.encoder.layer.4.attention.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.self.key.bias', 'bert.transformer.encoder.layer.4.attention.self.key.weight', 'bert.transformer.encoder.layer.4.attention.self.query.bias', 'bert.transformer.encoder.layer.4.attention.self.query.weight', 'bert.transformer.encoder.layer.4.attention.self.value.bias', 'bert.transformer.encoder.layer.4.attention.self.value.weight', 'bert.transformer.encoder.layer.4.intermediate.dense.bias', 'bert.transformer.encoder.layer.4.intermediate.dense.weight', 'bert.transformer.encoder.layer.4.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.output.dense.bias', 'bert.transformer.encoder.layer.4.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.attention.output.dense.bias', 'bert.transformer.encoder.layer.5.attention.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.self.key.bias', 'bert.transformer.encoder.layer.5.attention.self.key.weight', 'bert.transformer.encoder.layer.5.attention.self.query.bias', 'bert.transformer.encoder.layer.5.attention.self.query.weight', 'bert.transformer.encoder.layer.5.attention.self.value.bias', 'bert.transformer.encoder.layer.5.attention.self.value.weight', 'bert.transformer.encoder.layer.5.intermediate.dense.bias', 'bert.transformer.encoder.layer.5.intermediate.dense.weight', 'bert.transformer.encoder.layer.5.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.output.dense.bias', 'bert.transformer.encoder.layer.5.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.attention.output.dense.bias', 'bert.transformer.encoder.layer.6.attention.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.self.key.bias', 'bert.transformer.encoder.layer.6.attention.self.key.weight', 'bert.transformer.encoder.layer.6.attention.self.query.bias', 'bert.transformer.encoder.layer.6.attention.self.query.weight', 'bert.transformer.encoder.layer.6.attention.self.value.bias', 'bert.transformer.encoder.layer.6.attention.self.value.weight', 'bert.transformer.encoder.layer.6.intermediate.dense.bias', 'bert.transformer.encoder.layer.6.intermediate.dense.weight', 'bert.transformer.encoder.layer.6.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.output.dense.bias', 'bert.transformer.encoder.layer.6.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.attention.output.dense.bias', 'bert.transformer.encoder.layer.7.attention.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.self.key.bias', 'bert.transformer.encoder.layer.7.attention.self.key.weight', 'bert.transformer.encoder.layer.7.attention.self.query.bias', 'bert.transformer.encoder.layer.7.attention.self.query.weight', 'bert.transformer.encoder.layer.7.attention.self.value.bias', 'bert.transformer.encoder.layer.7.attention.self.value.weight', 'bert.transformer.encoder.layer.7.intermediate.dense.bias', 'bert.transformer.encoder.layer.7.intermediate.dense.weight', 'bert.transformer.encoder.layer.7.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.output.dense.bias', 'bert.transformer.encoder.layer.7.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.attention.output.dense.bias', 'bert.transformer.encoder.layer.8.attention.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.self.key.bias', 'bert.transformer.encoder.layer.8.attention.self.key.weight', 'bert.transformer.encoder.layer.8.attention.self.query.bias', 'bert.transformer.encoder.layer.8.attention.self.query.weight', 'bert.transformer.encoder.layer.8.attention.self.value.bias', 'bert.transformer.encoder.layer.8.attention.self.value.weight', 'bert.transformer.encoder.layer.8.intermediate.dense.bias', 'bert.transformer.encoder.layer.8.intermediate.dense.weight', 'bert.transformer.encoder.layer.8.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.output.dense.bias', 'bert.transformer.encoder.layer.8.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.attention.output.dense.bias', 'bert.transformer.encoder.layer.9.attention.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.self.key.bias', 'bert.transformer.encoder.layer.9.attention.self.key.weight', 'bert.transformer.encoder.layer.9.attention.self.query.bias', 'bert.transformer.encoder.layer.9.attention.self.query.weight', 'bert.transformer.encoder.layer.9.attention.self.value.bias', 'bert.transformer.encoder.layer.9.attention.self.value.weight', 'bert.transformer.encoder.layer.9.intermediate.dense.bias', 'bert.transformer.encoder.layer.9.intermediate.dense.weight', 'bert.transformer.encoder.layer.9.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.output.dense.bias', 'bert.transformer.encoder.layer.9.output.dense.weight', 'bert.transformer.pooler.dense.bias', 'bert.transformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/tmp/ipykernel_6207/1214379779.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text : title+description\n",
      "Input data feed :::  [CLS]Document logging framework[SEP]Store-client: Whenever used, creates a c:/ directory and several directories underneath it to store its log files.  Sending logs to STDOUT by default and/or having a documented way to changes this would be good.[SEP]\n",
      "within project split!\n",
      "usingbert tokenizer\n",
      "usingbert tokenizer\n",
      "tensor([[  101,   101,  6254, 15899,  7705,   102,  3573,  1011,  7396,  1024,\n",
      "          7188,  2109,  1010,  9005,  1037,  1039,  1024,  1013, 14176,  1998,\n",
      "          2195,  2472,  3111,  7650,  2009,  2000,  3573,  2049,  8833,  6764,\n",
      "          1012,  6016, 15664,  2000,  2358, 26797,  2102,  2011, 12398,  1998,\n",
      "          1013,  2030,  2383,  1037,  8832,  2126,  2000,  3431,  2023,  2052,\n",
      "          2022,  2204,  1012,   102,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  3499,  2005,  3722,  2039, 16616,  1997,  2622,  2544,\n",
      "          3616,   102,  2009,  2323,  2022,  3733,  1013,  3722,  2000, 10651,\n",
      "          1996,  2544,  2193,  1997,  2035,  3033,  1997,  1996, 26163,  2005,\n",
      "          2169,  2713,  1012,   102,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  9625,  7170,  1024, 20410,  3144,  4241, 22648, 23743,\n",
      "          2094, 13749,  4355,  1997,  2184,  2102,  2497,  1997,  1038,  7317,\n",
      "          4180,   102,   102,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101, 16545, 13910,  2475,  2243,  1024,  3746,  7584,  2326,\n",
      "           102,  2326, 10236,  4842,  1998,  2326,  2000,  4685,  7584,  1997,\n",
      "          4871,  2013, 14841,  4246,  2000, 16545, 13910,  2475,  2243,  1012,\n",
      "           102,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101, 16545, 13910,  2475,  2243,  1024,  3746,  8241,  2326,\n",
      "           102,  2326, 10236,  4842,  1998,  2326,  2000,  3710, 16545, 13910,\n",
      "          2475,  2243,  4871,  1012,   102,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "BATCH_SIZE :  19\n",
      "BATCH_SIZE :  19\n",
      "usingbert tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_6207/1214379779.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_seq = torch.tensor(tokens_test['input_ids'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE :  19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/gpt2sp/wandb/run-20240318_115835-idkwqyra</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/idkwqyra' target=\"_blank\">bert_duracloud</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/idkwqyra' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/idkwqyra</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for  {'train': ['duracloud'], 'test': ['duracloud']} .....\n",
      ">>> epoch  0\n",
      " Average training MAE loss: 1.76\n",
      "-\n",
      " Average eval MAE loss: 0.81\n",
      "===============================\n",
      "MAE:  0.7981257\n",
      "MdAE:  0.7372114\n",
      ">>> epoch  1\n",
      " Average training MAE loss: 1.45\n",
      "-\n",
      " Average eval MAE loss: 0.82\n",
      "===============================\n",
      "MAE:  0.79644054\n",
      "MdAE:  0.68075776\n",
      ">>> epoch  2\n",
      " Average training MAE loss: 1.50\n",
      "-\n",
      " Average eval MAE loss: 0.80\n",
      "===============================\n",
      "MAE:  0.8185715\n",
      "MdAE:  1.0126014\n",
      ">>> epoch  3\n",
      " Average training MAE loss: 1.38\n",
      "-\n",
      " Average eval MAE loss: 0.83\n",
      "===============================\n",
      "MAE:  0.7919821\n",
      "MdAE:  0.5313995\n",
      ">>> epoch  4\n",
      " Average training MAE loss: 1.37\n",
      "-\n",
      " Average eval MAE loss: 0.87\n",
      "===============================\n",
      "MAE:  0.77651715\n",
      "MdAE:  0.9866729\n",
      ">>> epoch  5\n",
      " Average training MAE loss: 1.43\n",
      "-\n",
      " Average eval MAE loss: 0.84\n",
      "===============================\n",
      "MAE:  0.8569488\n",
      "MdAE:  1.0509784\n",
      ">>> epoch  6\n",
      " Average training MAE loss: 1.40\n",
      "-\n",
      " Average eval MAE loss: 0.82\n",
      "===============================\n",
      "MAE:  0.79349005\n",
      "MdAE:  0.5819185\n",
      ">>> epoch  7\n",
      " Average training MAE loss: 1.36\n",
      "-\n",
      " Average eval MAE loss: 0.82\n",
      "===============================\n",
      "MAE:  0.7942416\n",
      "MdAE:  0.60709393\n",
      ">>> epoch  8\n",
      " Average training MAE loss: 1.37\n",
      "-\n",
      " Average eval MAE loss: 0.79\n",
      "===============================\n",
      "MAE:  0.80573624\n",
      "MdAE:  0.99216425\n",
      ">>> epoch  9\n",
      " Average training MAE loss: 1.37\n",
      "-\n",
      " Average eval MAE loss: 0.80\n",
      "===============================\n",
      "MAE:  0.8019263\n",
      "MdAE:  0.86453295\n",
      ">>> epoch  10\n",
      " Average training MAE loss: 1.35\n",
      "-\n",
      " Average eval MAE loss: 0.80\n",
      "===============================\n",
      "MAE:  0.80214757\n",
      "MdAE:  0.87194157\n",
      ">>> epoch  11\n",
      " Average training MAE loss: 1.36\n",
      "-\n",
      " Average eval MAE loss: 0.81\n",
      "===============================\n",
      "MAE:  0.8252201\n",
      "MdAE:  1.0192499\n",
      ">>> epoch  12\n",
      " Average training MAE loss: 1.36\n",
      "-\n",
      " Average eval MAE loss: 0.82\n",
      "===============================\n",
      "MAE:  0.795746\n",
      "MdAE:  0.6574924\n",
      ">>> epoch  13\n",
      " Average training MAE loss: 1.38\n",
      "-\n",
      " Average eval MAE loss: 0.85\n",
      "===============================\n",
      "MAE:  0.78438926\n",
      "MdAE:  0.72296035\n",
      ">>> epoch  14\n",
      " Average training MAE loss: 1.38\n",
      "-\n",
      " Average eval MAE loss: 0.80\n",
      "===============================\n",
      "MAE:  0.8019706\n",
      "MdAE:  0.8660152\n",
      ">>> epoch  15\n",
      " Average training MAE loss: 1.35\n",
      "-\n",
      " Average eval MAE loss: 0.79\n",
      "===============================\n",
      "MAE:  0.80405855\n",
      "MdAE:  0.9359617\n",
      ">>> epoch  16\n",
      " Average training MAE loss: 1.35\n",
      "-\n",
      " Average eval MAE loss: 0.80\n",
      "===============================\n",
      "MAE:  0.8025114\n",
      "MdAE:  0.8841325\n",
      ">>> epoch  17\n",
      " Average training MAE loss: 1.35\n",
      "-\n",
      " Average eval MAE loss: 0.81\n",
      "===============================\n",
      "MAE:  0.80023193\n",
      "MdAE:  0.8077705\n",
      ">>> epoch  18\n",
      " Average training MAE loss: 1.36\n",
      "-\n",
      " Average eval MAE loss: 0.81\n",
      "===============================\n",
      "MAE:  0.7994691\n",
      "MdAE:  0.7822164\n",
      ">>> epoch  19\n",
      " Average training MAE loss: 1.36\n",
      "-\n",
      " Average eval MAE loss: 0.80\n",
      "===============================\n",
      "MAE:  0.80151176\n",
      "MdAE:  0.8506448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.020 MB uploaded\\r'), FloatProgress(value=0.07562184313351758, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▃▃▂▄█▅▄▄▁▂▂▃▃▆▂▁▂▂▃▂</td></tr><tr><td>test_MAE</td><td>▃▃▅▂▁█▂▃▄▃▃▅▃▂▃▃▃▃▃▃</td></tr><tr><td>test_MdAE</td><td>▄▃▇▁▇█▂▂▇▅▆█▃▄▆▆▆▅▄▅</td></tr><tr><td>train_loss</td><td>█▃▄▂▁▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>0.80574</td></tr><tr><td>best_MAE_train_time</td><td>86.07058</td></tr><tr><td>best_MdAE</td><td>0.99216</td></tr><tr><td>eval_loss</td><td>0.80183</td></tr><tr><td>test_MAE</td><td>0.80151</td></tr><tr><td>test_MdAE</td><td>0.85064</td></tr><tr><td>train_loss</td><td>1.35521</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert_duracloud</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/idkwqyra' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/idkwqyra</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240318_115835-idkwqyra/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done for one project\n",
      "results have been written into a text file!\n",
      "n_embd/hidden_size :  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertSP were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.dense1.weight', 'bert.dense2.weight', 'bert.score.weight', 'bert.transformer.embeddings.LayerNorm.bias', 'bert.transformer.embeddings.LayerNorm.weight', 'bert.transformer.embeddings.position_embeddings.weight', 'bert.transformer.embeddings.token_type_embeddings.weight', 'bert.transformer.embeddings.word_embeddings.weight', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.attention.output.dense.bias', 'bert.transformer.encoder.layer.0.attention.output.dense.weight', 'bert.transformer.encoder.layer.0.attention.self.key.bias', 'bert.transformer.encoder.layer.0.attention.self.key.weight', 'bert.transformer.encoder.layer.0.attention.self.query.bias', 'bert.transformer.encoder.layer.0.attention.self.query.weight', 'bert.transformer.encoder.layer.0.attention.self.value.bias', 'bert.transformer.encoder.layer.0.attention.self.value.weight', 'bert.transformer.encoder.layer.0.intermediate.dense.bias', 'bert.transformer.encoder.layer.0.intermediate.dense.weight', 'bert.transformer.encoder.layer.0.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.output.dense.bias', 'bert.transformer.encoder.layer.0.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.attention.output.dense.bias', 'bert.transformer.encoder.layer.1.attention.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.self.key.bias', 'bert.transformer.encoder.layer.1.attention.self.key.weight', 'bert.transformer.encoder.layer.1.attention.self.query.bias', 'bert.transformer.encoder.layer.1.attention.self.query.weight', 'bert.transformer.encoder.layer.1.attention.self.value.bias', 'bert.transformer.encoder.layer.1.attention.self.value.weight', 'bert.transformer.encoder.layer.1.intermediate.dense.bias', 'bert.transformer.encoder.layer.1.intermediate.dense.weight', 'bert.transformer.encoder.layer.1.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.output.dense.bias', 'bert.transformer.encoder.layer.1.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.attention.output.dense.bias', 'bert.transformer.encoder.layer.10.attention.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.self.key.bias', 'bert.transformer.encoder.layer.10.attention.self.key.weight', 'bert.transformer.encoder.layer.10.attention.self.query.bias', 'bert.transformer.encoder.layer.10.attention.self.query.weight', 'bert.transformer.encoder.layer.10.attention.self.value.bias', 'bert.transformer.encoder.layer.10.attention.self.value.weight', 'bert.transformer.encoder.layer.10.intermediate.dense.bias', 'bert.transformer.encoder.layer.10.intermediate.dense.weight', 'bert.transformer.encoder.layer.10.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.output.dense.bias', 'bert.transformer.encoder.layer.10.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.attention.output.dense.bias', 'bert.transformer.encoder.layer.11.attention.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.self.key.bias', 'bert.transformer.encoder.layer.11.attention.self.key.weight', 'bert.transformer.encoder.layer.11.attention.self.query.bias', 'bert.transformer.encoder.layer.11.attention.self.query.weight', 'bert.transformer.encoder.layer.11.attention.self.value.bias', 'bert.transformer.encoder.layer.11.attention.self.value.weight', 'bert.transformer.encoder.layer.11.intermediate.dense.bias', 'bert.transformer.encoder.layer.11.intermediate.dense.weight', 'bert.transformer.encoder.layer.11.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.output.dense.bias', 'bert.transformer.encoder.layer.11.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.attention.output.dense.bias', 'bert.transformer.encoder.layer.2.attention.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.self.key.bias', 'bert.transformer.encoder.layer.2.attention.self.key.weight', 'bert.transformer.encoder.layer.2.attention.self.query.bias', 'bert.transformer.encoder.layer.2.attention.self.query.weight', 'bert.transformer.encoder.layer.2.attention.self.value.bias', 'bert.transformer.encoder.layer.2.attention.self.value.weight', 'bert.transformer.encoder.layer.2.intermediate.dense.bias', 'bert.transformer.encoder.layer.2.intermediate.dense.weight', 'bert.transformer.encoder.layer.2.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.output.dense.bias', 'bert.transformer.encoder.layer.2.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.attention.output.dense.bias', 'bert.transformer.encoder.layer.3.attention.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.self.key.bias', 'bert.transformer.encoder.layer.3.attention.self.key.weight', 'bert.transformer.encoder.layer.3.attention.self.query.bias', 'bert.transformer.encoder.layer.3.attention.self.query.weight', 'bert.transformer.encoder.layer.3.attention.self.value.bias', 'bert.transformer.encoder.layer.3.attention.self.value.weight', 'bert.transformer.encoder.layer.3.intermediate.dense.bias', 'bert.transformer.encoder.layer.3.intermediate.dense.weight', 'bert.transformer.encoder.layer.3.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.output.dense.bias', 'bert.transformer.encoder.layer.3.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.attention.output.dense.bias', 'bert.transformer.encoder.layer.4.attention.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.self.key.bias', 'bert.transformer.encoder.layer.4.attention.self.key.weight', 'bert.transformer.encoder.layer.4.attention.self.query.bias', 'bert.transformer.encoder.layer.4.attention.self.query.weight', 'bert.transformer.encoder.layer.4.attention.self.value.bias', 'bert.transformer.encoder.layer.4.attention.self.value.weight', 'bert.transformer.encoder.layer.4.intermediate.dense.bias', 'bert.transformer.encoder.layer.4.intermediate.dense.weight', 'bert.transformer.encoder.layer.4.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.output.dense.bias', 'bert.transformer.encoder.layer.4.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.attention.output.dense.bias', 'bert.transformer.encoder.layer.5.attention.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.self.key.bias', 'bert.transformer.encoder.layer.5.attention.self.key.weight', 'bert.transformer.encoder.layer.5.attention.self.query.bias', 'bert.transformer.encoder.layer.5.attention.self.query.weight', 'bert.transformer.encoder.layer.5.attention.self.value.bias', 'bert.transformer.encoder.layer.5.attention.self.value.weight', 'bert.transformer.encoder.layer.5.intermediate.dense.bias', 'bert.transformer.encoder.layer.5.intermediate.dense.weight', 'bert.transformer.encoder.layer.5.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.output.dense.bias', 'bert.transformer.encoder.layer.5.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.attention.output.dense.bias', 'bert.transformer.encoder.layer.6.attention.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.self.key.bias', 'bert.transformer.encoder.layer.6.attention.self.key.weight', 'bert.transformer.encoder.layer.6.attention.self.query.bias', 'bert.transformer.encoder.layer.6.attention.self.query.weight', 'bert.transformer.encoder.layer.6.attention.self.value.bias', 'bert.transformer.encoder.layer.6.attention.self.value.weight', 'bert.transformer.encoder.layer.6.intermediate.dense.bias', 'bert.transformer.encoder.layer.6.intermediate.dense.weight', 'bert.transformer.encoder.layer.6.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.output.dense.bias', 'bert.transformer.encoder.layer.6.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.attention.output.dense.bias', 'bert.transformer.encoder.layer.7.attention.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.self.key.bias', 'bert.transformer.encoder.layer.7.attention.self.key.weight', 'bert.transformer.encoder.layer.7.attention.self.query.bias', 'bert.transformer.encoder.layer.7.attention.self.query.weight', 'bert.transformer.encoder.layer.7.attention.self.value.bias', 'bert.transformer.encoder.layer.7.attention.self.value.weight', 'bert.transformer.encoder.layer.7.intermediate.dense.bias', 'bert.transformer.encoder.layer.7.intermediate.dense.weight', 'bert.transformer.encoder.layer.7.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.output.dense.bias', 'bert.transformer.encoder.layer.7.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.attention.output.dense.bias', 'bert.transformer.encoder.layer.8.attention.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.self.key.bias', 'bert.transformer.encoder.layer.8.attention.self.key.weight', 'bert.transformer.encoder.layer.8.attention.self.query.bias', 'bert.transformer.encoder.layer.8.attention.self.query.weight', 'bert.transformer.encoder.layer.8.attention.self.value.bias', 'bert.transformer.encoder.layer.8.attention.self.value.weight', 'bert.transformer.encoder.layer.8.intermediate.dense.bias', 'bert.transformer.encoder.layer.8.intermediate.dense.weight', 'bert.transformer.encoder.layer.8.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.output.dense.bias', 'bert.transformer.encoder.layer.8.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.attention.output.dense.bias', 'bert.transformer.encoder.layer.9.attention.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.self.key.bias', 'bert.transformer.encoder.layer.9.attention.self.key.weight', 'bert.transformer.encoder.layer.9.attention.self.query.bias', 'bert.transformer.encoder.layer.9.attention.self.query.weight', 'bert.transformer.encoder.layer.9.attention.self.value.bias', 'bert.transformer.encoder.layer.9.attention.self.value.weight', 'bert.transformer.encoder.layer.9.intermediate.dense.bias', 'bert.transformer.encoder.layer.9.intermediate.dense.weight', 'bert.transformer.encoder.layer.9.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.output.dense.bias', 'bert.transformer.encoder.layer.9.output.dense.weight', 'bert.transformer.pooler.dense.bias', 'bert.transformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/tmp/ipykernel_6207/1214379779.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text : title+description\n",
      "Input data feed :::  [CLS]As a JIRA Administrator I would like to be able to change the trigger of the night service[SEP] [SEP]\n",
      "within project split!\n",
      "usingbert tokenizer\n",
      "usingbert tokenizer\n",
      "tensor([[  101,   101,  2004,  1037, 10147,  2527,  8911,  1045,  2052,  2066,\n",
      "          2000,  2022,  2583,  2000,  2689,  1996,  9495,  1997,  1996,  2305,\n",
      "          2326,   102,   102,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  2004,  1037, 10147,  2527,  8911,  1045,  2052,  2066,\n",
      "          2000,  2022,  2583,  2000,  2689,  1996,  9495,  1997,  1996,  2305,\n",
      "          2326,   102,   102,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101, 12391,  4773,  6198, 14593,  2229,  2089, 13249,  2007,\n",
      "          2060, 13354,  7076,   102,  2070,  4773,  2147,  4506,  2031, 10954,\n",
      "          2008,  2031,  2200, 12391, 14593,  2229,  1010,  2107,  2004,  1000,\n",
      "         10651,  1000,  1010,  1000,  2693,  1000,  1998,  1000, 26351,  2232,\n",
      "          1000,  4385,  1012,  2122, 14593,  2229,  2031,  1037,  2204,  3382,\n",
      "          2000, 13249,  2007,  1996,  2895,  2171,  2030, 14593,  2229,  2109,\n",
      "          2011,  2060, 13354,  7076,  1012,  2122, 14593,  2229,  2323,  2022,\n",
      "          2445,  1037,  2171,  3563,  2000,  1996, 13354,  2378,  1010,  2107,\n",
      "          2004,  1000, 10651, 28637, 25311,  7361,  4842, 25711,  6277,  1000,\n",
      "          1012,  1012,  1012, 14084,  1010,  1996,  9748, 20231,  2064,   102],\n",
      "        [  101,   101, 12391,  4773,  6198, 14593,  2229,  2089, 13249,  2007,\n",
      "          2060, 13354,  7076,   102,  2070,  4773,  2147,  4506,  2031, 10954,\n",
      "          2008,  2031,  2200, 12391, 14593,  2229,  1010,  2107,  2004,  1000,\n",
      "         10651,  1000,  1010,  1000,  2693,  1000,  1998,  1000, 26351,  2232,\n",
      "          1000,  4385,  1012,  2122, 14593,  2229,  2031,  1037,  2204,  3382,\n",
      "          2000, 13249,  2007,  1996,  2895,  2171,  2030, 14593,  2229,  2109,\n",
      "          2011,  2060, 13354,  7076,  1012,  2122, 14593,  2229,  2323,  2022,\n",
      "          2445,  1037,  2171,  3563,  2000,  1996, 13354,  2378,  1010,  2107,\n",
      "          2004,  1000, 10651, 28637, 25311,  7361,  4842, 25711,  6277,  1000,\n",
      "          1012,  1012,  1012, 14084,  1010,  1996,  9748, 20231,  2064,   102],\n",
      "        [  101,   101,  5587,  3793,  2000,  1996, 29003, 11721, 24291,  1000,\n",
      "         19528,  2622,  1000,  4471,   102,  2043,  1996,  7561,  2003,  1000,\n",
      "         19528,  2622,  1000,  5587,  4751,  2008,  1996,  2622,  2003,  2025,\n",
      "         26928,  2005,  2224,  2007,  2665, 27330,  1011,  1000, 19528,  2622,\n",
      "          1011,  1031,  2025, 26928,  2005,  2224,  2007,  2665, 27330,  1064,\n",
      "          8299,  1024,  1013,  1013, 13693,  1012, 11568, 17043,  1012,  4012,\n",
      "          1013,  4653,  1013,  1043,  2232,  1013,  9530,  8873, 27390,  2075,\n",
      "          1009,  2115,  1009,  2665, 27330,  1009,  3795,  1009, 10906,  1001,\n",
      "          9530,  8873, 27390,  2075, 29337, 10623, 28029, 27330, 23296, 16429,\n",
      "          9777, 18319,  3070,  2015,  1011,  6123,  1033,  1000,   102,   102]])\n",
      "BATCH_SIZE :  10\n",
      "BATCH_SIZE :  10\n",
      "usingbert tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_6207/1214379779.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_seq = torch.tensor(tokens_test['input_ids'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE :  10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/gpt2sp/wandb/run-20240318_120208-jcxrvlt6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/jcxrvlt6' target=\"_blank\">bert_jirasoftware</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/jcxrvlt6' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/jcxrvlt6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for  {'train': ['jirasoftware'], 'test': ['jirasoftware']} .....\n",
      ">>> epoch  0\n",
      " Average training MAE loss: 3.13\n",
      "-\n",
      " Average eval MAE loss: 2.92\n",
      "===============================\n",
      "MAE:  2.955779\n",
      "MdAE:  2.8111925\n",
      ">>> epoch  1\n",
      " Average training MAE loss: 3.14\n",
      "-\n",
      " Average eval MAE loss: 3.87\n",
      "===============================\n",
      "MAE:  3.871528\n",
      "MdAE:  3.9131927\n",
      ">>> epoch  2\n",
      " Average training MAE loss: 2.96\n",
      "-\n",
      " Average eval MAE loss: 2.36\n",
      "===============================\n",
      "MAE:  2.4048848\n",
      "MdAE:  2.148251\n",
      ">>> epoch  3\n",
      " Average training MAE loss: 2.95\n",
      "-\n",
      " Average eval MAE loss: 4.06\n",
      "===============================\n",
      "MAE:  4.05471\n",
      "MdAE:  4.1336336\n",
      ">>> epoch  4\n",
      " Average training MAE loss: 3.11\n",
      "-\n",
      " Average eval MAE loss: 2.36\n",
      "===============================\n",
      "MAE:  2.406957\n",
      "MdAE:  2.1507454\n",
      ">>> epoch  5\n",
      " Average training MAE loss: 2.75\n",
      "-\n",
      " Average eval MAE loss: 1.96\n",
      "===============================\n",
      "MAE:  1.9678893\n",
      "MdAE:  1.2812948\n",
      ">>> epoch  6\n",
      " Average training MAE loss: 2.79\n",
      "-\n",
      " Average eval MAE loss: 2.75\n",
      "===============================\n",
      "MAE:  2.7829862\n",
      "MdAE:  2.6032543\n",
      ">>> epoch  7\n",
      " Average training MAE loss: 3.00\n",
      "-\n",
      " Average eval MAE loss: 2.57\n",
      "===============================\n",
      "MAE:  2.6170774\n",
      "MdAE:  2.4036026\n",
      ">>> epoch  8\n",
      " Average training MAE loss: 2.93\n",
      "-\n",
      " Average eval MAE loss: 2.19\n",
      "===============================\n",
      "MAE:  2.231856\n",
      "MdAE:  1.8858638\n",
      ">>> epoch  9\n",
      " Average training MAE loss: 2.73\n",
      "-\n",
      " Average eval MAE loss: 2.20\n",
      "===============================\n",
      "MAE:  2.2481995\n",
      "MdAE:  1.923296\n",
      ">>> epoch  10\n",
      " Average training MAE loss: 2.78\n",
      "-\n",
      " Average eval MAE loss: 2.12\n",
      "===============================\n",
      "MAE:  2.1487384\n",
      "MdAE:  1.6954985\n",
      ">>> epoch  11\n",
      " Average training MAE loss: 2.74\n",
      "-\n",
      " Average eval MAE loss: 2.55\n",
      "===============================\n",
      "MAE:  2.5927122\n",
      "MdAE:  2.3742805\n",
      ">>> epoch  12\n",
      " Average training MAE loss: 2.90\n",
      "-\n",
      " Average eval MAE loss: 2.17\n",
      "===============================\n",
      "MAE:  2.2153695\n",
      "MdAE:  1.8481059\n",
      ">>> epoch  13\n",
      " Average training MAE loss: 2.79\n",
      "-\n",
      " Average eval MAE loss: 2.26\n",
      "===============================\n",
      "MAE:  2.3140059\n",
      "MdAE:  2.0388875\n",
      ">>> epoch  14\n",
      " Average training MAE loss: 2.71\n",
      "-\n",
      " Average eval MAE loss: 2.79\n",
      "===============================\n",
      "MAE:  2.8248036\n",
      "MdAE:  2.6535769\n",
      ">>> epoch  15\n",
      " Average training MAE loss: 2.86\n",
      "-\n",
      " Average eval MAE loss: 2.23\n",
      "===============================\n",
      "MAE:  2.287167\n",
      "MdAE:  2.0065908\n",
      ">>> epoch  16\n",
      " Average training MAE loss: 3.30\n",
      "-\n",
      " Average eval MAE loss: 2.30\n",
      "===============================\n",
      "MAE:  2.3529537\n",
      "MdAE:  2.0857582\n",
      ">>> epoch  17\n",
      " Average training MAE loss: 2.78\n",
      "-\n",
      " Average eval MAE loss: 2.25\n",
      "===============================\n",
      "MAE:  2.306468\n",
      "MdAE:  2.0298176\n",
      ">>> epoch  18\n",
      " Average training MAE loss: 3.00\n",
      "-\n",
      " Average eval MAE loss: 2.43\n",
      "===============================\n",
      "MAE:  2.476835\n",
      "MdAE:  2.2348356\n",
      ">>> epoch  19\n",
      " Average training MAE loss: 2.77\n",
      "-\n",
      " Average eval MAE loss: 2.31\n",
      "===============================\n",
      "MAE:  2.3626153\n",
      "MdAE:  2.097385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.023 MB uploaded\\r'), FloatProgress(value=0.06469079509831861, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▄▇▂█▂▁▄▃▂▂▂▃▂▂▄▂▂▂▃▂</td></tr><tr><td>test_MAE</td><td>▄▇▂█▂▁▄▃▂▂▂▃▂▂▄▂▂▂▃▂</td></tr><tr><td>test_MdAE</td><td>▅▇▃█▃▁▄▄▂▃▂▄▂▃▄▃▃▃▃▃</td></tr><tr><td>train_loss</td><td>▆▆▄▄▆▁▂▄▄▁▂▁▃▂▁▃█▂▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>1.96789</td></tr><tr><td>best_MAE_train_time</td><td>34.94675</td></tr><tr><td>best_MdAE</td><td>1.28129</td></tr><tr><td>eval_loss</td><td>2.31204</td></tr><tr><td>test_MAE</td><td>2.36262</td></tr><tr><td>test_MdAE</td><td>2.09738</td></tr><tr><td>train_loss</td><td>2.77435</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert_jirasoftware</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/jcxrvlt6' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/jcxrvlt6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240318_120208-jcxrvlt6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done for one project\n",
      "results have been written into a text file!\n",
      "n_embd/hidden_size :  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertSP were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.dense1.weight', 'bert.dense2.weight', 'bert.score.weight', 'bert.transformer.embeddings.LayerNorm.bias', 'bert.transformer.embeddings.LayerNorm.weight', 'bert.transformer.embeddings.position_embeddings.weight', 'bert.transformer.embeddings.token_type_embeddings.weight', 'bert.transformer.embeddings.word_embeddings.weight', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.attention.output.dense.bias', 'bert.transformer.encoder.layer.0.attention.output.dense.weight', 'bert.transformer.encoder.layer.0.attention.self.key.bias', 'bert.transformer.encoder.layer.0.attention.self.key.weight', 'bert.transformer.encoder.layer.0.attention.self.query.bias', 'bert.transformer.encoder.layer.0.attention.self.query.weight', 'bert.transformer.encoder.layer.0.attention.self.value.bias', 'bert.transformer.encoder.layer.0.attention.self.value.weight', 'bert.transformer.encoder.layer.0.intermediate.dense.bias', 'bert.transformer.encoder.layer.0.intermediate.dense.weight', 'bert.transformer.encoder.layer.0.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.output.dense.bias', 'bert.transformer.encoder.layer.0.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.attention.output.dense.bias', 'bert.transformer.encoder.layer.1.attention.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.self.key.bias', 'bert.transformer.encoder.layer.1.attention.self.key.weight', 'bert.transformer.encoder.layer.1.attention.self.query.bias', 'bert.transformer.encoder.layer.1.attention.self.query.weight', 'bert.transformer.encoder.layer.1.attention.self.value.bias', 'bert.transformer.encoder.layer.1.attention.self.value.weight', 'bert.transformer.encoder.layer.1.intermediate.dense.bias', 'bert.transformer.encoder.layer.1.intermediate.dense.weight', 'bert.transformer.encoder.layer.1.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.output.dense.bias', 'bert.transformer.encoder.layer.1.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.attention.output.dense.bias', 'bert.transformer.encoder.layer.10.attention.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.self.key.bias', 'bert.transformer.encoder.layer.10.attention.self.key.weight', 'bert.transformer.encoder.layer.10.attention.self.query.bias', 'bert.transformer.encoder.layer.10.attention.self.query.weight', 'bert.transformer.encoder.layer.10.attention.self.value.bias', 'bert.transformer.encoder.layer.10.attention.self.value.weight', 'bert.transformer.encoder.layer.10.intermediate.dense.bias', 'bert.transformer.encoder.layer.10.intermediate.dense.weight', 'bert.transformer.encoder.layer.10.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.output.dense.bias', 'bert.transformer.encoder.layer.10.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.attention.output.dense.bias', 'bert.transformer.encoder.layer.11.attention.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.self.key.bias', 'bert.transformer.encoder.layer.11.attention.self.key.weight', 'bert.transformer.encoder.layer.11.attention.self.query.bias', 'bert.transformer.encoder.layer.11.attention.self.query.weight', 'bert.transformer.encoder.layer.11.attention.self.value.bias', 'bert.transformer.encoder.layer.11.attention.self.value.weight', 'bert.transformer.encoder.layer.11.intermediate.dense.bias', 'bert.transformer.encoder.layer.11.intermediate.dense.weight', 'bert.transformer.encoder.layer.11.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.output.dense.bias', 'bert.transformer.encoder.layer.11.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.attention.output.dense.bias', 'bert.transformer.encoder.layer.2.attention.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.self.key.bias', 'bert.transformer.encoder.layer.2.attention.self.key.weight', 'bert.transformer.encoder.layer.2.attention.self.query.bias', 'bert.transformer.encoder.layer.2.attention.self.query.weight', 'bert.transformer.encoder.layer.2.attention.self.value.bias', 'bert.transformer.encoder.layer.2.attention.self.value.weight', 'bert.transformer.encoder.layer.2.intermediate.dense.bias', 'bert.transformer.encoder.layer.2.intermediate.dense.weight', 'bert.transformer.encoder.layer.2.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.output.dense.bias', 'bert.transformer.encoder.layer.2.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.attention.output.dense.bias', 'bert.transformer.encoder.layer.3.attention.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.self.key.bias', 'bert.transformer.encoder.layer.3.attention.self.key.weight', 'bert.transformer.encoder.layer.3.attention.self.query.bias', 'bert.transformer.encoder.layer.3.attention.self.query.weight', 'bert.transformer.encoder.layer.3.attention.self.value.bias', 'bert.transformer.encoder.layer.3.attention.self.value.weight', 'bert.transformer.encoder.layer.3.intermediate.dense.bias', 'bert.transformer.encoder.layer.3.intermediate.dense.weight', 'bert.transformer.encoder.layer.3.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.output.dense.bias', 'bert.transformer.encoder.layer.3.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.attention.output.dense.bias', 'bert.transformer.encoder.layer.4.attention.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.self.key.bias', 'bert.transformer.encoder.layer.4.attention.self.key.weight', 'bert.transformer.encoder.layer.4.attention.self.query.bias', 'bert.transformer.encoder.layer.4.attention.self.query.weight', 'bert.transformer.encoder.layer.4.attention.self.value.bias', 'bert.transformer.encoder.layer.4.attention.self.value.weight', 'bert.transformer.encoder.layer.4.intermediate.dense.bias', 'bert.transformer.encoder.layer.4.intermediate.dense.weight', 'bert.transformer.encoder.layer.4.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.output.dense.bias', 'bert.transformer.encoder.layer.4.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.attention.output.dense.bias', 'bert.transformer.encoder.layer.5.attention.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.self.key.bias', 'bert.transformer.encoder.layer.5.attention.self.key.weight', 'bert.transformer.encoder.layer.5.attention.self.query.bias', 'bert.transformer.encoder.layer.5.attention.self.query.weight', 'bert.transformer.encoder.layer.5.attention.self.value.bias', 'bert.transformer.encoder.layer.5.attention.self.value.weight', 'bert.transformer.encoder.layer.5.intermediate.dense.bias', 'bert.transformer.encoder.layer.5.intermediate.dense.weight', 'bert.transformer.encoder.layer.5.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.output.dense.bias', 'bert.transformer.encoder.layer.5.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.attention.output.dense.bias', 'bert.transformer.encoder.layer.6.attention.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.self.key.bias', 'bert.transformer.encoder.layer.6.attention.self.key.weight', 'bert.transformer.encoder.layer.6.attention.self.query.bias', 'bert.transformer.encoder.layer.6.attention.self.query.weight', 'bert.transformer.encoder.layer.6.attention.self.value.bias', 'bert.transformer.encoder.layer.6.attention.self.value.weight', 'bert.transformer.encoder.layer.6.intermediate.dense.bias', 'bert.transformer.encoder.layer.6.intermediate.dense.weight', 'bert.transformer.encoder.layer.6.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.output.dense.bias', 'bert.transformer.encoder.layer.6.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.attention.output.dense.bias', 'bert.transformer.encoder.layer.7.attention.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.self.key.bias', 'bert.transformer.encoder.layer.7.attention.self.key.weight', 'bert.transformer.encoder.layer.7.attention.self.query.bias', 'bert.transformer.encoder.layer.7.attention.self.query.weight', 'bert.transformer.encoder.layer.7.attention.self.value.bias', 'bert.transformer.encoder.layer.7.attention.self.value.weight', 'bert.transformer.encoder.layer.7.intermediate.dense.bias', 'bert.transformer.encoder.layer.7.intermediate.dense.weight', 'bert.transformer.encoder.layer.7.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.output.dense.bias', 'bert.transformer.encoder.layer.7.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.attention.output.dense.bias', 'bert.transformer.encoder.layer.8.attention.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.self.key.bias', 'bert.transformer.encoder.layer.8.attention.self.key.weight', 'bert.transformer.encoder.layer.8.attention.self.query.bias', 'bert.transformer.encoder.layer.8.attention.self.query.weight', 'bert.transformer.encoder.layer.8.attention.self.value.bias', 'bert.transformer.encoder.layer.8.attention.self.value.weight', 'bert.transformer.encoder.layer.8.intermediate.dense.bias', 'bert.transformer.encoder.layer.8.intermediate.dense.weight', 'bert.transformer.encoder.layer.8.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.output.dense.bias', 'bert.transformer.encoder.layer.8.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.attention.output.dense.bias', 'bert.transformer.encoder.layer.9.attention.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.self.key.bias', 'bert.transformer.encoder.layer.9.attention.self.key.weight', 'bert.transformer.encoder.layer.9.attention.self.query.bias', 'bert.transformer.encoder.layer.9.attention.self.query.weight', 'bert.transformer.encoder.layer.9.attention.self.value.bias', 'bert.transformer.encoder.layer.9.attention.self.value.weight', 'bert.transformer.encoder.layer.9.intermediate.dense.bias', 'bert.transformer.encoder.layer.9.intermediate.dense.weight', 'bert.transformer.encoder.layer.9.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.output.dense.bias', 'bert.transformer.encoder.layer.9.output.dense.weight', 'bert.transformer.pooler.dense.bias', 'bert.transformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/tmp/ipykernel_6207/1214379779.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text : title+description\n",
      "Input data feed :::  [CLS]Report executor terminations to framework schedulers.[SEP]The Scheduler interface has a callback for executorLost, but currently it is never called.[SEP]\n",
      "within project split!\n",
      "usingbert tokenizer\n",
      "usingbert tokenizer\n",
      "tensor([[  101,   101,  3189,  4654,  8586, 16161,  2099, 18287,  2015,  2000,\n",
      "          7705,  6134,  2869,  1012,   102,  1996,  6134,  2099,  8278,  2038,\n",
      "          1037,  2655,  5963,  2005,  4654,  8586, 16161, 12190, 14122,  1010,\n",
      "          2021,  2747,  2009,  2003,  2196,  2170,  1012,   102,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  2033, 17063,  6658,  2323, 17053,  4654,  8586, 16161,\n",
      "          2869,   102,  1996,  6658,  2323,  2022, 25670,  2055,  2129,  2009,\n",
      "         16024,  4815,  2091,  4654,  8586, 16161,  2869,  1012,  1999,  2256,\n",
      "          4044,  1010,  4654,  8586, 16161,  2869,  6524,  2689,  2021,  1996,\n",
      "          6658,  2097,  2467,  4139,  2009,  2091,  2013,  7539, 10751, 10343,\n",
      "          1012,  2023,  8509,  6151,  5657,  6911,  2006,  2256, 10751, 10343,\n",
      "         12906,  1010,  1998,  2003,  2025, 24501, 18622,  4765,  2000,  4359,\n",
      "         10751, 10343, 11343,  1012,   102,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101, 14451,  4708,  1035,  3478,  3114,  2000,  7705,  2015,\n",
      "          1012,   102,  2057,  2085,  2031,  1037,  4471,  5164,  2503,  8518,\n",
      "         29336,  2271,  2008,  3640,  2529,  3191,  3085,  2592,  2055,  4708,\n",
      "          1035,  3478,  1012,  2009,  2052,  2022,  2204,  2000,  5587,  2070,\n",
      "          3252,  2000,  1996,  4945,  4436,  1010,  2005,  7705,  6134,  2869,\n",
      "          2000,  2552,  2006,  2565, 12644,  3973,  1012,  1041,  1012,  1043,\n",
      "          1012,  4372,  2819,  4708,  7011,  4014,  5397,  1063,  4654,  8586,\n",
      "         16161,  2099,  1035,  1051,  5358,  1025,  4654,  8586, 16161,  2099,\n",
      "          1035,  2041,  1035,  1997,  1035,  9785,  1025,  4654,  8586, 16161,\n",
      "          2099,  1035, 12527,  1025,  6658,  1035,  2439,  1025,  4385,   102],\n",
      "        [  101,   101, 13212,  7705, 11896,  2000,  2448,  2349,  2000,  2919,\n",
      "          9245,   102,  1045,  8343,  2023,  2038,  2000,  2079,  2007,  1996,\n",
      "          6745,  9245, 25416, 18908,  2953,  1012,  1031, 19354,  7716,  1030,\n",
      "         15488,  2546,  2094,  1011, 23923,  4160,  1011,  6021,  1011,  5034,\n",
      "          2549,  3857,  1033,  1002, 19219,  2080,  1043, 21197,  1035,  1058,\n",
      "          1027,  1015,  1012,  1013,  8026,  1013,  2033, 17063,  1011,  5852,\n",
      "          1012, 14021,  1011,  1011, 14181,  4355,  1035, 11307,  1027,  1000,\n",
      "          1008, 13212,  1008,  1000,  1011,  1011, 12034,  9232,  5432,  1024,\n",
      "         15899,  2077,  1999,  4183,  3995,  8649,  2571, 21197,  4726,  1006,\n",
      "          1007,  2003,  2517,  2000,  2358,  4063,  2099,  1045,  2692,   102],\n",
      "        [  101,   101,  2036,  4638,  1005, 21025,  2102,  4487,  4246,  1011,\n",
      "          1011,  9132, 29336,  1011,  1011,  9813,  1005,  1999,  2695,  1011,\n",
      "          4391,  1012,  1052,  2100,  1012,   102,  2057,  2783,  4638,  2065,\n",
      "          2017,  2031,  2151,  3431,  2077,  2057,  2448,  2695,  1011,  4391,\n",
      "          1012,  1052,  2100,  2021,  2057,  2123,  1005,  1056,  4638,  2005,\n",
      "          9813,  3431,  2029,  2462, 14194,  2071,  2131,  2439,  1012,   102,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "BATCH_SIZE :  50\n",
      "BATCH_SIZE :  50\n",
      "usingbert tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_6207/1214379779.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_seq = torch.tensor(tokens_test['input_ids'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE :  50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/gpt2sp/wandb/run-20240318_120433-k0q8lguk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/k0q8lguk' target=\"_blank\">bert_mesos</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/k0q8lguk' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/k0q8lguk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for  {'train': ['mesos'], 'test': ['mesos']} .....\n",
      ">>> epoch  0\n",
      " Average training MAE loss: 2.13\n",
      "-\n",
      " Average eval MAE loss: 1.33\n",
      "===============================\n",
      "MAE:  1.21393\n",
      "MdAE:  0.5298724\n",
      ">>> epoch  1\n",
      " Average training MAE loss: 1.72\n",
      "-\n",
      " Average eval MAE loss: 1.33\n",
      "===============================\n",
      "MAE:  1.2108583\n",
      "MdAE:  0.7879045\n",
      ">>> epoch  2\n",
      " Average training MAE loss: 1.81\n",
      "-\n",
      " Average eval MAE loss: 1.34\n",
      "===============================\n",
      "MAE:  1.2184815\n",
      "MdAE:  0.8524394\n",
      ">>> epoch  3\n",
      " Average training MAE loss: 1.71\n",
      "-\n",
      " Average eval MAE loss: 1.34\n",
      "===============================\n",
      "MAE:  1.2168232\n",
      "MdAE:  0.71315455\n",
      ">>> epoch  4\n",
      " Average training MAE loss: 1.69\n",
      "-\n",
      " Average eval MAE loss: 1.34\n",
      "===============================\n",
      "MAE:  1.2184087\n",
      "MdAE:  0.8463304\n",
      ">>> epoch  5\n",
      " Average training MAE loss: 1.66\n",
      "-\n",
      " Average eval MAE loss: 1.49\n",
      "===============================\n",
      "MAE:  1.370511\n",
      "MdAE:  1.2427487\n",
      ">>> epoch  6\n",
      " Average training MAE loss: 1.65\n",
      "-\n",
      " Average eval MAE loss: 1.56\n",
      "===============================\n",
      "MAE:  1.4418435\n",
      "MdAE:  1.3579781\n",
      ">>> epoch  7\n",
      " Average training MAE loss: 1.70\n",
      "-\n",
      " Average eval MAE loss: 1.37\n",
      "===============================\n",
      "MAE:  1.2492241\n",
      "MdAE:  1.0468237\n",
      ">>> epoch  8\n",
      " Average training MAE loss: 1.68\n",
      "-\n",
      " Average eval MAE loss: 1.33\n",
      "===============================\n",
      "MAE:  1.215254\n",
      "MdAE:  0.58133435\n",
      ">>> epoch  9\n",
      " Average training MAE loss: 1.72\n",
      "-\n",
      " Average eval MAE loss: 1.43\n",
      "===============================\n",
      "MAE:  1.3115485\n",
      "MdAE:  1.1475015\n",
      ">>> epoch  10\n",
      " Average training MAE loss: 1.69\n",
      "-\n",
      " Average eval MAE loss: 1.55\n",
      "===============================\n",
      "MAE:  1.4298123\n",
      "MdAE:  1.3385432\n",
      ">>> epoch  11\n",
      " Average training MAE loss: 1.73\n",
      "-\n",
      " Average eval MAE loss: 1.63\n",
      "===============================\n",
      "MAE:  1.5045156\n",
      "MdAE:  1.4592175\n",
      ">>> epoch  12\n",
      " Average training MAE loss: 1.72\n",
      "-\n",
      " Average eval MAE loss: 1.35\n",
      "===============================\n",
      "MAE:  1.2338076\n",
      "MdAE:  1.02192\n",
      ">>> epoch  13\n",
      " Average training MAE loss: 1.68\n",
      "-\n",
      " Average eval MAE loss: 1.40\n",
      "===============================\n",
      "MAE:  1.2805486\n",
      "MdAE:  1.0974247\n",
      ">>> epoch  14\n",
      " Average training MAE loss: 1.65\n",
      "-\n",
      " Average eval MAE loss: 1.34\n",
      "===============================\n",
      "MAE:  1.2201357\n",
      "MdAE:  0.9914019\n",
      ">>> epoch  15\n",
      " Average training MAE loss: 1.65\n",
      "-\n",
      " Average eval MAE loss: 1.35\n",
      "===============================\n",
      "MAE:  1.22973\n",
      "MdAE:  1.0153329\n",
      ">>> epoch  16\n",
      " Average training MAE loss: 1.67\n",
      "-\n",
      " Average eval MAE loss: 1.38\n",
      "===============================\n",
      "MAE:  1.2604626\n",
      "MdAE:  1.0649781\n",
      ">>> epoch  17\n",
      " Average training MAE loss: 1.69\n",
      "-\n",
      " Average eval MAE loss: 1.41\n",
      "===============================\n",
      "MAE:  1.2845435\n",
      "MdAE:  1.1038783\n",
      ">>> epoch  18\n",
      " Average training MAE loss: 1.64\n",
      "-\n",
      " Average eval MAE loss: 1.39\n",
      "===============================\n",
      "MAE:  1.2645665\n",
      "MdAE:  1.0716074\n",
      ">>> epoch  19\n",
      " Average training MAE loss: 1.61\n",
      "-\n",
      " Average eval MAE loss: 1.40\n",
      "===============================\n",
      "MAE:  1.275116\n",
      "MdAE:  1.0886488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>▁</td></tr><tr><td>best_MAE_train_time</td><td>▁</td></tr><tr><td>best_MdAE</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁▁▁▁▁▅▇▂▁▃▆█▂▃▁▂▂▃▂▃</td></tr><tr><td>test_MAE</td><td>▁▁▁▁▁▅▇▂▁▃▆█▂▃▁▁▂▃▂▃</td></tr><tr><td>test_MdAE</td><td>▁▃▃▂▃▆▇▅▁▆▇█▅▅▄▅▅▅▅▅</td></tr><tr><td>train_loss</td><td>█▂▄▂▂▂▂▂▂▂▂▃▂▂▁▁▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_MAE</td><td>1.21086</td></tr><tr><td>best_MAE_train_time</td><td>40.21704</td></tr><tr><td>best_MdAE</td><td>0.7879</td></tr><tr><td>eval_loss</td><td>1.39615</td></tr><tr><td>test_MAE</td><td>1.27512</td></tr><tr><td>test_MdAE</td><td>1.08865</td></tr><tr><td>train_loss</td><td>1.6118</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert_mesos</strong> at: <a href='https://wandb.ai/seniyas/esti-mate/runs/k0q8lguk' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/k0q8lguk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240318_120433-k0q8lguk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done for one project\n",
      "results have been written into a text file!\n",
      "n_embd/hidden_size :  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertSP were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.dense1.weight', 'bert.dense2.weight', 'bert.score.weight', 'bert.transformer.embeddings.LayerNorm.bias', 'bert.transformer.embeddings.LayerNorm.weight', 'bert.transformer.embeddings.position_embeddings.weight', 'bert.transformer.embeddings.token_type_embeddings.weight', 'bert.transformer.embeddings.word_embeddings.weight', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.attention.output.dense.bias', 'bert.transformer.encoder.layer.0.attention.output.dense.weight', 'bert.transformer.encoder.layer.0.attention.self.key.bias', 'bert.transformer.encoder.layer.0.attention.self.key.weight', 'bert.transformer.encoder.layer.0.attention.self.query.bias', 'bert.transformer.encoder.layer.0.attention.self.query.weight', 'bert.transformer.encoder.layer.0.attention.self.value.bias', 'bert.transformer.encoder.layer.0.attention.self.value.weight', 'bert.transformer.encoder.layer.0.intermediate.dense.bias', 'bert.transformer.encoder.layer.0.intermediate.dense.weight', 'bert.transformer.encoder.layer.0.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.output.dense.bias', 'bert.transformer.encoder.layer.0.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.attention.output.dense.bias', 'bert.transformer.encoder.layer.1.attention.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.self.key.bias', 'bert.transformer.encoder.layer.1.attention.self.key.weight', 'bert.transformer.encoder.layer.1.attention.self.query.bias', 'bert.transformer.encoder.layer.1.attention.self.query.weight', 'bert.transformer.encoder.layer.1.attention.self.value.bias', 'bert.transformer.encoder.layer.1.attention.self.value.weight', 'bert.transformer.encoder.layer.1.intermediate.dense.bias', 'bert.transformer.encoder.layer.1.intermediate.dense.weight', 'bert.transformer.encoder.layer.1.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.output.dense.bias', 'bert.transformer.encoder.layer.1.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.attention.output.dense.bias', 'bert.transformer.encoder.layer.10.attention.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.self.key.bias', 'bert.transformer.encoder.layer.10.attention.self.key.weight', 'bert.transformer.encoder.layer.10.attention.self.query.bias', 'bert.transformer.encoder.layer.10.attention.self.query.weight', 'bert.transformer.encoder.layer.10.attention.self.value.bias', 'bert.transformer.encoder.layer.10.attention.self.value.weight', 'bert.transformer.encoder.layer.10.intermediate.dense.bias', 'bert.transformer.encoder.layer.10.intermediate.dense.weight', 'bert.transformer.encoder.layer.10.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.output.dense.bias', 'bert.transformer.encoder.layer.10.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.attention.output.dense.bias', 'bert.transformer.encoder.layer.11.attention.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.self.key.bias', 'bert.transformer.encoder.layer.11.attention.self.key.weight', 'bert.transformer.encoder.layer.11.attention.self.query.bias', 'bert.transformer.encoder.layer.11.attention.self.query.weight', 'bert.transformer.encoder.layer.11.attention.self.value.bias', 'bert.transformer.encoder.layer.11.attention.self.value.weight', 'bert.transformer.encoder.layer.11.intermediate.dense.bias', 'bert.transformer.encoder.layer.11.intermediate.dense.weight', 'bert.transformer.encoder.layer.11.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.output.dense.bias', 'bert.transformer.encoder.layer.11.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.attention.output.dense.bias', 'bert.transformer.encoder.layer.2.attention.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.self.key.bias', 'bert.transformer.encoder.layer.2.attention.self.key.weight', 'bert.transformer.encoder.layer.2.attention.self.query.bias', 'bert.transformer.encoder.layer.2.attention.self.query.weight', 'bert.transformer.encoder.layer.2.attention.self.value.bias', 'bert.transformer.encoder.layer.2.attention.self.value.weight', 'bert.transformer.encoder.layer.2.intermediate.dense.bias', 'bert.transformer.encoder.layer.2.intermediate.dense.weight', 'bert.transformer.encoder.layer.2.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.output.dense.bias', 'bert.transformer.encoder.layer.2.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.attention.output.dense.bias', 'bert.transformer.encoder.layer.3.attention.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.self.key.bias', 'bert.transformer.encoder.layer.3.attention.self.key.weight', 'bert.transformer.encoder.layer.3.attention.self.query.bias', 'bert.transformer.encoder.layer.3.attention.self.query.weight', 'bert.transformer.encoder.layer.3.attention.self.value.bias', 'bert.transformer.encoder.layer.3.attention.self.value.weight', 'bert.transformer.encoder.layer.3.intermediate.dense.bias', 'bert.transformer.encoder.layer.3.intermediate.dense.weight', 'bert.transformer.encoder.layer.3.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.output.dense.bias', 'bert.transformer.encoder.layer.3.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.attention.output.dense.bias', 'bert.transformer.encoder.layer.4.attention.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.self.key.bias', 'bert.transformer.encoder.layer.4.attention.self.key.weight', 'bert.transformer.encoder.layer.4.attention.self.query.bias', 'bert.transformer.encoder.layer.4.attention.self.query.weight', 'bert.transformer.encoder.layer.4.attention.self.value.bias', 'bert.transformer.encoder.layer.4.attention.self.value.weight', 'bert.transformer.encoder.layer.4.intermediate.dense.bias', 'bert.transformer.encoder.layer.4.intermediate.dense.weight', 'bert.transformer.encoder.layer.4.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.output.dense.bias', 'bert.transformer.encoder.layer.4.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.attention.output.dense.bias', 'bert.transformer.encoder.layer.5.attention.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.self.key.bias', 'bert.transformer.encoder.layer.5.attention.self.key.weight', 'bert.transformer.encoder.layer.5.attention.self.query.bias', 'bert.transformer.encoder.layer.5.attention.self.query.weight', 'bert.transformer.encoder.layer.5.attention.self.value.bias', 'bert.transformer.encoder.layer.5.attention.self.value.weight', 'bert.transformer.encoder.layer.5.intermediate.dense.bias', 'bert.transformer.encoder.layer.5.intermediate.dense.weight', 'bert.transformer.encoder.layer.5.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.output.dense.bias', 'bert.transformer.encoder.layer.5.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.attention.output.dense.bias', 'bert.transformer.encoder.layer.6.attention.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.self.key.bias', 'bert.transformer.encoder.layer.6.attention.self.key.weight', 'bert.transformer.encoder.layer.6.attention.self.query.bias', 'bert.transformer.encoder.layer.6.attention.self.query.weight', 'bert.transformer.encoder.layer.6.attention.self.value.bias', 'bert.transformer.encoder.layer.6.attention.self.value.weight', 'bert.transformer.encoder.layer.6.intermediate.dense.bias', 'bert.transformer.encoder.layer.6.intermediate.dense.weight', 'bert.transformer.encoder.layer.6.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.output.dense.bias', 'bert.transformer.encoder.layer.6.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.attention.output.dense.bias', 'bert.transformer.encoder.layer.7.attention.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.self.key.bias', 'bert.transformer.encoder.layer.7.attention.self.key.weight', 'bert.transformer.encoder.layer.7.attention.self.query.bias', 'bert.transformer.encoder.layer.7.attention.self.query.weight', 'bert.transformer.encoder.layer.7.attention.self.value.bias', 'bert.transformer.encoder.layer.7.attention.self.value.weight', 'bert.transformer.encoder.layer.7.intermediate.dense.bias', 'bert.transformer.encoder.layer.7.intermediate.dense.weight', 'bert.transformer.encoder.layer.7.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.output.dense.bias', 'bert.transformer.encoder.layer.7.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.attention.output.dense.bias', 'bert.transformer.encoder.layer.8.attention.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.self.key.bias', 'bert.transformer.encoder.layer.8.attention.self.key.weight', 'bert.transformer.encoder.layer.8.attention.self.query.bias', 'bert.transformer.encoder.layer.8.attention.self.query.weight', 'bert.transformer.encoder.layer.8.attention.self.value.bias', 'bert.transformer.encoder.layer.8.attention.self.value.weight', 'bert.transformer.encoder.layer.8.intermediate.dense.bias', 'bert.transformer.encoder.layer.8.intermediate.dense.weight', 'bert.transformer.encoder.layer.8.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.output.dense.bias', 'bert.transformer.encoder.layer.8.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.attention.output.dense.bias', 'bert.transformer.encoder.layer.9.attention.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.self.key.bias', 'bert.transformer.encoder.layer.9.attention.self.key.weight', 'bert.transformer.encoder.layer.9.attention.self.query.bias', 'bert.transformer.encoder.layer.9.attention.self.query.weight', 'bert.transformer.encoder.layer.9.attention.self.value.bias', 'bert.transformer.encoder.layer.9.attention.self.value.weight', 'bert.transformer.encoder.layer.9.intermediate.dense.bias', 'bert.transformer.encoder.layer.9.intermediate.dense.weight', 'bert.transformer.encoder.layer.9.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.output.dense.bias', 'bert.transformer.encoder.layer.9.output.dense.weight', 'bert.transformer.pooler.dense.bias', 'bert.transformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/tmp/ipykernel_6207/1214379779.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text : title+description\n",
      "Input data feed :::  [CLS]Forum: Per-discussion subscription[SEP]I am finding that my inbox is absolutely flooded with unwanted moodle mails off the forum script. This is very annoying and I know it will similarly annoy my users. In fact it will put them off the system.    The problem arises because unlike other discussion boards moodle messages are emailed to me from the entire forum, not just the thread I have started or responded to. The overwhelming of people's inboxes is a serious business: it could be said that moodle is generating spam because the email feature is so unfocused.    Is there any chance this is going to be improved please?[SEP]\n",
      "within project split!\n",
      "usingbert tokenizer\n",
      "usingbert tokenizer\n",
      "tensor([[  101,   101,  7057,  1024,  2566,  1011,  6594, 15002,   102,  1045,\n",
      "          2572,  4531,  2008,  2026,  1999,  8758,  2003,  7078, 10361,  2007,\n",
      "         18162,  6888,  2571,  5653,  2015,  2125,  1996,  7057,  5896,  1012,\n",
      "          2023,  2003,  2200, 15703,  1998,  1045,  2113,  2009,  2097,  6660,\n",
      "          5754,  6977,  2026,  5198,  1012,  1999,  2755,  2009,  2097,  2404,\n",
      "          2068,  2125,  1996,  2291,  1012,  1996,  3291, 18653,  2138,  4406,\n",
      "          2060,  6594,  7923,  6888,  2571,  7696,  2024, 10373,  2098,  2000,\n",
      "          2033,  2013,  1996,  2972,  7057,  1010,  2025,  2074,  1996, 11689,\n",
      "          1045,  2031,  2318,  2030,  5838,  2000,  1012,  1996, 10827,  1997,\n",
      "          2111,  1005,  1055,  1999,  8758,  2229,  2003,  1037,  3809,   102],\n",
      "        [  101,   101,  7057,  1024,  7514,  2011,  1041,  1011,  5653,   102,\n",
      "          2129,  2055,  1996,  3754,  2000,  2695,  2000,  1996, 21415,  3081,\n",
      "         10373,  1029,   102,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  3499,  5089,  2000, 20648,  3056,  4249,  1999,  7809,\n",
      "          4023,  2004,  3223,   102,  2043,  4526,  1037,  7809,  1010,  3499,\n",
      "          1996,  3836,  2000, 20648,  3251,  1037,  2492,  2442,  2022,  3561,\n",
      "          1999,  2030,  2025,  1012,   102,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  7057,  1024, 10838,  2000,  2279, 11689,  4957,   102,\n",
      "          3531,  2404,  1037,  4957,  2000,  5376,  2000,  1996,  2279, 11689,\n",
      "          1999,  1996,  7057,  8278,  1012,  1012,  1012, 21415,  2024,  2200,\n",
      "          4658,  2021,  1996,  9312,  2832,  2003,  2051, 15077,  1998,  1010,\n",
      "          2005,  1037,  3836,  1010,  2051,  2003,  2673,  2043, 23208,  2531,\n",
      "          2015,  1997,  2493,  1012,  1012,  1012,   102,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   101,  1037,  2224,  6337,  1005,  1055,  2607,  2862,  2003,\n",
      "         12098, 16313,  8486,  2135,  3132,  2007,  2053,  2126,  1997,  3773,\n",
      "          3143,  2862,   102,  2043, 10523,  1037,  5310,  1005,  1055,  6337,\n",
      "          1010,  2065,  1996,  2862,  1997,  2037,  5352, 23651,  2538,  1006,\n",
      "          1045,  2228,  1007,  2019,  3449, 15000,  6190,  2003,  6913,  1012,\n",
      "          2023,  3849,  1037,  2978, 11809,  2138,  1012,  1012,  1012,  1037,\n",
      "          1007,  2017,  2064,  1005,  1056, 11562,  2006,  1996,  3449, 15000,\n",
      "          6190,  2000,  2156,  1996,  2717,  1997,  1996,  5352,  1038,  1007,\n",
      "          1996,  2862,  3475,  1005,  1056,  2130,  1999, 12440,  2594,  2344,\n",
      "          2061,  2009,  4150,  2130,  2062, 15275,  1039,  1007,  1996,   102]])\n",
      "BATCH_SIZE :  34\n",
      "BATCH_SIZE :  34\n",
      "usingbert tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_6207/1214379779.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
      "/var/tmp/ipykernel_6207/1214379779.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_seq = torch.tensor(tokens_test['input_ids'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE :  34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/gpt2sp/wandb/run-20240318_121211-fuzrfotr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seniyas/esti-mate/runs/fuzrfotr' target=\"_blank\">bert_moodle</a></strong> to <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seniyas/esti-mate' target=\"_blank\">https://wandb.ai/seniyas/esti-mate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seniyas/esti-mate/runs/fuzrfotr' target=\"_blank\">https://wandb.ai/seniyas/esti-mate/runs/fuzrfotr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for  {'train': ['moodle'], 'test': ['moodle']} .....\n",
      ">>> epoch  0\n",
      " Average training MAE loss: 13.81\n",
      "-\n",
      " Average eval MAE loss: 13.96\n",
      "===============================\n",
      "MAE:  6.253713\n",
      "MdAE:  5.376383\n",
      ">>> epoch  1\n",
      " Average training MAE loss: 13.71\n",
      "-\n",
      " Average eval MAE loss: 14.56\n",
      "===============================\n",
      "MAE:  10.950114\n",
      "MdAE:  12.031331\n",
      ">>> epoch  2\n",
      " Average training MAE loss: 13.04\n",
      "-\n",
      " Average eval MAE loss: 13.99\n",
      "===============================\n",
      "MAE:  6.2133493\n",
      "MdAE:  5.2665553\n",
      ">>> epoch  3\n",
      " Average training MAE loss: 12.88\n",
      "-\n",
      " Average eval MAE loss: 13.87\n",
      "===============================\n",
      "MAE:  8.392755\n",
      "MdAE:  8.192177\n",
      ">>> epoch  4\n",
      " Average training MAE loss: 13.08\n",
      "-\n",
      " Average eval MAE loss: 13.79\n",
      "===============================\n",
      "MAE:  6.5244827\n",
      "MdAE:  5.0694933\n",
      ">>> epoch  5\n",
      " Average training MAE loss: 12.99\n",
      "-\n",
      " Average eval MAE loss: 13.79\n",
      "===============================\n",
      "MAE:  6.5481195\n",
      "MdAE:  5.109\n",
      ">>> epoch  6\n",
      " Average training MAE loss: 12.98\n",
      "-\n",
      " Average eval MAE loss: 13.87\n",
      "===============================\n",
      "MAE:  6.37566\n",
      "MdAE:  5.29181\n",
      ">>> epoch  7\n",
      " Average training MAE loss: 12.81\n",
      "-\n",
      " Average eval MAE loss: 13.80\n",
      "===============================\n",
      "MAE:  6.8043423\n",
      "MdAE:  5.5372586\n",
      ">>> epoch  8\n",
      " Average training MAE loss: 12.82\n",
      "-\n",
      " Average eval MAE loss: 13.81\n",
      "===============================\n",
      "MAE:  6.9642944\n",
      "MdAE:  5.8046074\n",
      ">>> epoch  9\n",
      " Average training MAE loss: 12.93\n",
      "-\n",
      " Average eval MAE loss: 13.83\n",
      "===============================\n",
      "MAE:  7.3474717\n",
      "MdAE:  6.4450617\n",
      ">>> epoch  10\n",
      " Average training MAE loss: 12.98\n",
      "-\n",
      " Average eval MAE loss: 13.80\n",
      "===============================\n",
      "MAE:  6.759822\n",
      "MdAE:  5.4628463\n",
      ">>> epoch  11\n",
      " Average training MAE loss: 12.97\n",
      "-\n",
      " Average eval MAE loss: 13.79\n",
      "===============================\n",
      "MAE:  6.5860376\n",
      "MdAE:  5.1723766\n",
      ">>> epoch  12\n",
      " Average training MAE loss: 12.93\n",
      "-\n",
      " Average eval MAE loss: 13.79\n",
      "===============================\n",
      "MAE:  6.677856\n",
      "MdAE:  5.3258467\n",
      ">>> epoch  13\n",
      " Average training MAE loss: 12.81\n",
      "-\n",
      " Average eval MAE loss: 13.80\n",
      "===============================\n",
      "MAE:  6.8102746\n",
      "MdAE:  5.5471735\n",
      ">>> epoch  14\n",
      " Average training MAE loss: 12.81\n",
      "-\n",
      " Average eval MAE loss: 13.81\n",
      "===============================\n",
      "MAE:  6.902715\n",
      "MdAE:  5.701681\n",
      ">>> epoch  15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 69\u001b[0m\n\u001b[1;32m     65\u001b[0m             OUTPUT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[45], line 56\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     MODEL\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     55\u001b[0m file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names \u001b[38;5;241m=\u001b[39m data_processing(file_pair\u001b[38;5;241m=\u001b[39mfile)\n\u001b[0;32m---> 56\u001b[0m \u001b[43mtrain_eval_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_test_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_file_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m MODEL\n\u001b[1;32m     60\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[0;32mIn[43], line 224\u001b[0m, in \u001b[0;36mtrain_eval_test\u001b[0;34m(file_pair, train_dataloader, val_dataloader, all_test_dataloader, model, test_file_names)\u001b[0m\n\u001b[1;32m    222\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# Calculates the gradients\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# The clip_grad_norm_ function clips (limits) the norm (magnitude) of the gradients to a maximum value specified by the user.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global WITHIN_PROJECT\n",
    "WITHIN_PROJECT = True\n",
    "\n",
    "TRAIN_TEST_FILE_PAIRS = [\n",
    "                        {'train': ['appceleratorstudio'], 'test': ['appceleratorstudio']},\n",
    "                        {'train': ['aptanastudio'], 'test': ['aptanastudio']},\n",
    "                        {'train': ['bamboo'], 'test': ['bamboo']},\n",
    "                        {'train': ['clover'], 'test': ['clover']},\n",
    "                        # {'train': ['datamanagement'], 'test': ['datamanagement']},\n",
    "                        {'train': ['duracloud'], 'test': ['duracloud']},\n",
    "                        {'train': ['jirasoftware'], 'test': ['jirasoftware']},\n",
    "                        {'train': ['mesos'], 'test': ['mesos']},\n",
    "                        {'train': ['moodle'], 'test': ['moodle']},\n",
    "                        {'train': ['mule'], 'test': ['mule']},\n",
    "                        {'train': ['mulestudio'], 'test': ['mulestudio']},\n",
    "                        # {'train': ['springxd'], 'test': ['springxd']},\n",
    "                        {'train': ['talenddataquality'], 'test': ['talenddataquality']},\n",
    "                        {'train': ['talendesb'], 'test': ['talendesb']},\n",
    "                        {'train': ['titanium'], 'test': ['titanium']},\n",
    "                        {'train': ['usergrid'], 'test': ['usergrid']},\n",
    "                        ]\n",
    "\n",
    "\n",
    "def main():\n",
    "    global TRAIN_TEST_FILE_PAIRS, MODEL, TOKENIZER, MODEL_NAME\n",
    "    for file in TRAIN_TEST_FILE_PAIRS:\n",
    "        if TOKENIZER == 'bbpe':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=50257)\n",
    "        elif TOKENIZER == 'gpt2':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=50256)\n",
    "        elif TOKENIZER == 'wordpiece':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
    "        elif TOKENIZER == 'sentencepiece':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
    "        elif TOKENIZER == 'wordlevel':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=3)\n",
    "        elif TOKENIZER == 'bert':\n",
    "            config = BertConfig(num_labels=1, pad_token_id=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if MODEL_NAME == 'gpt2':\n",
    "            MODEL = LinearGPT2.from_pretrained('gpt2', config=config)\n",
    "            MODEL.cuda()\n",
    "        elif MODEL_NAME == 'gpt2sp':\n",
    "            MODEL = GPT2SP.from_pretrained('gpt2', config=config)\n",
    "            MODEL.cuda()\n",
    "        elif MODEL_NAME == 'bert':\n",
    "            MODEL = BertSP.from_pretrained('bert-base-uncased', config=config)\n",
    "            MODEL.cuda()\n",
    "\n",
    "\n",
    "\n",
    "        file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names = data_processing(file_pair=file)\n",
    "        train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, MODEL, test_file_names)\n",
    "        \n",
    "\n",
    "        del MODEL\n",
    "        torch.cuda.empty_cache()\n",
    "        global OUTPUT\n",
    "        with open('./results/' + str(file['train'][0]) + '_' + str(file['test'][0]) +'.txt', 'w+') as f:\n",
    "            f.writelines(OUTPUT)\n",
    "            print('results have been written into a text file!')\n",
    "            OUTPUT = \"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSte0lR_hfbo"
   },
   "source": [
    "### Cross Project Training Script - Within Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ij9vp2J2hfbo"
   },
   "outputs": [],
   "source": [
    "global WITHIN_PROJECT\n",
    "WITHIN_PROJECT = False\n",
    "\n",
    "# within repo\n",
    "TRAIN_TEST_FILE_PAIRS = [\n",
    "                        {'train': ['mesos'], 'test': ['usergrid']},\n",
    "                        {'train': ['usergrid'], 'test': ['mesos']},\n",
    "                        {'train': ['appceleratorstudio'], 'test': ['aptanastudio']},\n",
    "                        {'train': ['appceleratorstudio'], 'test': ['titanium']},\n",
    "                        {'train': ['titanium'], 'test': ['appceleratorstudio']},\n",
    "                        {'train': ['aptanastudio'], 'test': ['titanium']},\n",
    "                        {'train': ['mule'], 'test': ['mulestudio']},\n",
    "                        {'train': ['mulestudio'], 'test': ['mule']}\n",
    "                        ]\n",
    "\n",
    "\n",
    "def main():\n",
    "    global TRAIN_TEST_FILE_PAIRS, MODEL, TOKENIZER, MODEL_NAME\n",
    "    for file in TRAIN_TEST_FILE_PAIRS:\n",
    "        if TOKENIZER == 'bbpe':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=50257)\n",
    "        elif TOKENIZER == 'gpt2':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=50256)\n",
    "        elif TOKENIZER == 'wordpiece':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
    "        elif TOKENIZER == 'sentencepiece':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
    "        elif TOKENIZER == 'wordlevel':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=3)\n",
    "        if MODEL_NAME == 'gpt2':\n",
    "            MODEL = LinearGPT2.from_pretrained('gpt2', config=config)\n",
    "            MODEL.cuda()\n",
    "        elif MODEL_NAME == 'gpt2sp':\n",
    "            MODEL = GPT2SP.from_pretrained('gpt2', config=config)\n",
    "            MODEL.cuda()\n",
    "        file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names = data_processing(file_pair=file)\n",
    "        train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, MODEL, test_file_names)\n",
    "        del MODEL\n",
    "        torch.cuda.empty_cache()\n",
    "        global OUTPUT\n",
    "        with open('./results/' + str(file['train'][0]) + '_' + str(file['test'][0]) +'.txt', 'w+') as f:\n",
    "            f.writelines(OUTPUT)\n",
    "            print('results have been written into a text file!')\n",
    "            OUTPUT = \"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMcxbMB7hfbp"
   },
   "source": [
    "### Cross Project Training Script - Cross Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35iJqeeNhfbp"
   },
   "outputs": [],
   "source": [
    "global WITHIN_PROJECT\n",
    "WITHIN_PROJECT = False\n",
    "\n",
    "# cross repo\n",
    "TRAIN_TEST_FILE_PAIRS = [\n",
    "                        {'train': ['clover'], 'test': ['usergrid']},\n",
    "                        {'train': ['talendesb'], 'test': ['mesos']},\n",
    "                        {'train': ['talenddataquality'], 'test': ['aptanastudio']},\n",
    "                        {'train': ['mule'], 'test': ['titanium']},\n",
    "                        {'train': ['talenddataquality'], 'test': ['appceleratorstudio']},\n",
    "                        {'train': ['mulestudio'], 'test': ['titanium']},\n",
    "                        {'train': ['appceleratorstudio'], 'test': ['mulestudio']},\n",
    "                        {'train': ['appceleratorstudio'], 'test': ['mule']}\n",
    "                        ]\n",
    "\n",
    "\n",
    "def main():\n",
    "    global TRAIN_TEST_FILE_PAIRS, MODEL, TOKENIZER, MODEL_NAME\n",
    "    for file in TRAIN_TEST_FILE_PAIRS:\n",
    "        if TOKENIZER == 'gpt2':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=50256)\n",
    "        elif TOKENIZER == 'wordpiece':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
    "        elif TOKENIZER == 'sentencepiece':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
    "        elif TOKENIZER == 'wordlevel':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=3)\n",
    "        if MODEL_NAME == 'gpt2':\n",
    "            MODEL = LinearGPT2.from_pretrained('gpt2', config=config)\n",
    "            MODEL.cuda()\n",
    "        elif MODEL_NAME == 'gpt2sp':\n",
    "            MODEL = GPT2SP.from_pretrained('gpt2', config=config)\n",
    "            MODEL.cuda()\n",
    "        file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names = data_processing(file_pair=file)\n",
    "        train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, MODEL, test_file_names)\n",
    "        del MODEL\n",
    "        torch.cuda.empty_cache()\n",
    "        global OUTPUT\n",
    "        with open('./results/' + str(file['train'][0]) + '_' + str(file['test'][0]) +'.txt', 'w+') as f:\n",
    "            f.writelines(OUTPUT)\n",
    "            print('results have been written into a text file!')\n",
    "            OUTPUT = \"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "95502c86ed2e8b82df6e58f8450b4387aca3c902602792f25ea2aa6818e861bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
