{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Sansith/gpt2sp/blob/bertsp/model_training_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyLoXxhlhfbk",
    "tags": []
   },
   "source": [
    "# Model Training Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ren7VyEyhfbl",
    "tags": []
   },
   "source": [
    "### Necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMyN0hhThfbl",
    "outputId": "bc9e260f-b571-4885-faf7-aaa3d95590f9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
      "Requirement already satisfied: pandas===1.5.3 in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
      "Collecting koila\n",
      "  Downloading koila-0.1.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas===1.5.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas===1.5.3) (2023.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
      "Collecting pynvml (from koila)\n",
      "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from koila) (13.7.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.62.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->koila) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->koila) (2.16.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->koila) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
      "Installing collected packages: pynvml, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, koila\n",
      "Successfully installed koila-0.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pynvml-11.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install torch pandas===1.5.3 transformers numpy tokenizers koila tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "O8TuUYj7h6St"
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIh96xVTiuIa",
    "outputId": "ca9c9488-8b03-4a0f-cd05-f29260936686"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3R16ZxuirGo",
    "outputId": "3be31f12-4ff0-405d-9890-a1d7cedc72fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Year4/FYP/effort-estimation/gpt2sp\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/Year4/FYP/effort-estimation/gpt2sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bhcSAPbLhfbm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup , BertTokenizer\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from GPT2SP import GPT2ForSequenceClassification as GPT2SP\n",
    "from transformers import GPT2ForSequenceClassification as LinearGPT2\n",
    "from transformers import GPT2Config , BertConfig\n",
    "import os\n",
    "from tokenizers import Tokenizer\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cf6cpSnmvZcA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers.modeling_outputs import SequenceClassifierOutputWithPast\n",
    "import torch.nn as nn\n",
    "from transformers import  BertPreTrainedModel , BertModel\n",
    "import torch\n",
    "\n",
    "\n",
    "class BertSP(BertPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"h\\.\\d+\\.attn\\.masked_bias\", r\"lm_head\\.weight\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.transformer = BertModel(config)\n",
    "        print(\"n_embd/hidden_size : \", config.hidden_size)\n",
    "        self.dense1 = nn.Linear(config.hidden_size, 4 * config.hidden_size, bias=False)\n",
    "        self.dense2 = nn.Linear(4 * config.hidden_size, config.hidden_size, bias=False)\n",
    "        self.score = nn.Linear(config.hidden_size, self.num_labels, bias=False)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        past_key_values=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
    "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        transformer_outputs = self.transformer(\n",
    "            input_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = transformer_outputs[0]\n",
    "\n",
    "        # MLP Layer\n",
    "        hidden_states = self.dense1(hidden_states)\n",
    "        hidden_states = self.dense2(hidden_states)\n",
    "\n",
    "        logits = self.score(hidden_states)\n",
    "\n",
    "        if input_ids is not None:\n",
    "            batch_size, sequence_length = input_ids.shape[:2]\n",
    "        else:\n",
    "            batch_size, sequence_length = inputs_embeds.shape[:2]\n",
    "\n",
    "        assert (\n",
    "            self.config.pad_token_id is not None or batch_size == 1\n",
    "        ), \"Cannot handle batch sizes > 1 if no padding token is defined.\"\n",
    "        if self.config.pad_token_id is None:\n",
    "            sequence_lengths = -1\n",
    "        else:\n",
    "            if input_ids is not None:\n",
    "                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1\n",
    "            else:\n",
    "                sequence_lengths = -1\n",
    "                logger.warning(\n",
    "                    f\"{self.__class__.__name__} will not detect padding tokens in `inputs_embeds`. Results may be \"\n",
    "                    f\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"\n",
    "                )\n",
    "\n",
    "        pooled_logits = logits[range(batch_size), sequence_lengths]\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = nn.L1Loss()\n",
    "                loss = loss_fct(pooled_logits.view(-1), labels.to(self.dtype).view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(pooled_logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (pooled_logits,) + transformer_outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=pooled_logits,\n",
    "            past_key_values=transformer_outputs.past_key_values,\n",
    "            hidden_states=transformer_outputs.hidden_states,\n",
    "            attentions=transformer_outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbQNj41Ghfbn"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ch24eOM0hfbn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "global EPOCHS, BATCH_SIZE_RATIO, SEQUENCE_LEN, LEARNING_RATE, TOKENIZER, MODEL_NAME , ADD_DESCRIPTION\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE_RATIO = 0.04 # within proj: 0.3 / cross proj: 0.4\n",
    "SEQUENCE_LEN = 512\n",
    "LEARNING_RATE = 5e-4\n",
    "TOKENIZER = 'bert' # available:bert, gpt2, wordlevel, sentencepiece, wordpiece\n",
    "MODEL_NAME = 'bert' # available: bert, gpt2sp, gpt2\n",
    "ADD_DESCRIPTION = True\n",
    "\n",
    "# define device\n",
    "global DEVICE\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# define files to be used\n",
    "global DATA_PATH\n",
    "DATA_PATH = './sp_dataset/marked_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH1j_lvmhfbn"
   },
   "source": [
    "### Static Methods and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "W1FZRuJ7hfbn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT = '  '\n",
    "MODEL = None\n",
    "DYNAMIC_BATCH = True\n",
    "BATCH_SIZE = None\n",
    "WITHIN_PROJECT = None\n",
    "MAE_RECORDS = []\n",
    "MDAE_RECORDS = []\n",
    "\n",
    "def data_processing(file_pair):\n",
    "    global BATCH_SIZE, BATCH_SIZE_RATIO, DATA_PATH, WITHIN_PROJECT, DYNAMIC_BATCH\n",
    "\n",
    "    train_data = pd.DataFrame(columns=['text', 'label'])\n",
    "    for train_file_name in file_pair['train']:\n",
    "        fname = DATA_PATH + train_file_name + '.csv'\n",
    "        df = prepare_dataframe(fname)\n",
    "        train_data = train_data.append(df)\n",
    "\n",
    "    # data split\n",
    "    if WITHIN_PROJECT:\n",
    "        train_text, train_labels, val_text, val_labels, test_text, test_labels = within_project_split(train_data)\n",
    "    else:\n",
    "        train_text, train_labels, val_text, val_labels = train_val_split(train_data, 0.6)\n",
    "    # define batch size dynamically based on training length\n",
    "    if DYNAMIC_BATCH:\n",
    "        BATCH_SIZE = int(len(train_text) * BATCH_SIZE_RATIO)\n",
    "    # tokenization\n",
    "    tokens_train = tokenization(train_text.tolist())\n",
    "    tokens_val = tokenization(val_text.tolist())\n",
    "    print(tokens_train['input_ids'][:5])\n",
    "\n",
    "    train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "    train_y = torch.tensor(train_labels.tolist()).type(torch.LongTensor)\n",
    "    train_dataloader = prepare_dataloader(train_seq, train_y, sampler_type='random')\n",
    "\n",
    "    val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "    val_y = torch.tensor(val_labels.tolist()).type(torch.LongTensor)\n",
    "    val_dataloader = prepare_dataloader(val_seq, val_y, sampler_type='sequential')\n",
    "\n",
    "    # prepare testing datasets\n",
    "    all_test_dataloader = []\n",
    "    test_file_names = []\n",
    "    if WITHIN_PROJECT:\n",
    "        tokens_test = tokenization(test_text.tolist())\n",
    "        test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "        test_y = torch.tensor(test_labels.tolist()).type(torch.LongTensor)\n",
    "        test_dataloader = prepare_dataloader(test_seq, test_y, sampler_type='sequential')\n",
    "        all_test_dataloader.append(test_dataloader)\n",
    "        test_file_names.append(file_pair['test'][0])\n",
    "        return file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names\n",
    "\n",
    "    for test_file_name in file_pair['test']:\n",
    "        fname = DATA_PATH + test_file_name + '.csv'\n",
    "        test_data = prepare_dataframe(fname)\n",
    "\n",
    "        test_text = test_data['text']\n",
    "        test_labels = test_data['label']\n",
    "\n",
    "        # tokenization\n",
    "        tokens_test = tokenization(test_text.tolist())\n",
    "        test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "        test_y = torch.tensor(test_labels.tolist()).type(torch.LongTensor)\n",
    "        test_dataloader = prepare_dataloader(test_seq, test_y, sampler_type='sequential')\n",
    "\n",
    "        all_test_dataloader.append(test_dataloader)\n",
    "        test_file_names.append(test_file_name)\n",
    "    print('cross project data processing!')\n",
    "    return file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names\n",
    "\n",
    "\n",
    "def train_val_split(data, split_ratio):\n",
    "    print('cross project split!')\n",
    "    split_point = int(len(data) * split_ratio)\n",
    "    train_text = data['text'][:split_point]\n",
    "    train_labels = data['label'][:split_point]\n",
    "    val_text = data['text'][split_point:]\n",
    "    val_labels = data['label'][split_point:]\n",
    "    return train_text, train_labels, val_text, val_labels\n",
    "\n",
    "\n",
    "def tokenization(text_list):\n",
    "    global TOKENIZER, SEQUENCE_LEN, MODEL\n",
    "    # tokenization\n",
    "    if TOKENIZER == 'wordpiece':\n",
    "        print('using wordpiece tokenizer!')\n",
    "        tokenizer = BertTokenizer('all_tokenizers/word_piece/vocab.txt')\n",
    "    elif TOKENIZER == 'sentencepiece':\n",
    "        print('using sentencepiece tokenizer!')\n",
    "        tokenizer = XLNetTokenizer('all_tokenizers/sentence_piece/spm_tokenizer.model', padding_side='right')\n",
    "    elif TOKENIZER == 'wordlevel':\n",
    "        print('using wordlevel tokenizer!')\n",
    "        tokenizer = Tokenizer.from_file('all_tokenizers/word_level/wordlevel.json')\n",
    "        encoded_sentences = {'input_ids':[]}\n",
    "        for sentence in text_list:\n",
    "            encoded = tokenizer.encode(sentence)\n",
    "            encoded = encoded.ids\n",
    "            if len(encoded) > SEQUENCE_LEN:\n",
    "                encoded = encoded[:SEQUENCE_LEN]\n",
    "            elif len(encoded) < SEQUENCE_LEN:\n",
    "                padding = SEQUENCE_LEN - len(encoded)\n",
    "                for _ in range(padding):\n",
    "                    encoded.append(3)\n",
    "            encoded_sentences['input_ids'].append(encoded)\n",
    "        return encoded_sentences\n",
    "    elif TOKENIZER == 'gpt2':\n",
    "        print('using pretrained gpt-2 tokenizer')\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(TOKENIZER)\n",
    "        tokenizer.pad_token = '[PAD]'\n",
    "\n",
    "    elif TOKENIZER == 'bert':\n",
    "        print('usingbert tokenizer')\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        # tokenizer.pad_token = '[PAD]'\n",
    "    return tokenizer.batch_encode_plus(text_list, truncation=True, max_length=SEQUENCE_LEN, padding='max_length')\n",
    "\n",
    "\n",
    "def prepare_dataframe(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    # some rows have no description, fill blank to avoid Null\n",
    "    data = data.fillna(' ')\n",
    "\n",
    "\n",
    "    if ADD_DESCRIPTION :\n",
    "      print(\"### text : title+description\")\n",
    "      d = {'text':('[CLS]' + data['title'] + '[SEP]' + data[\"description\"]+'[SEP]').tolist(), 'label': data['storypoint']}\n",
    "    else:\n",
    "      print(\"### text : title\")\n",
    "      d = {'text': (data['title']).tolist(), 'label': data['storypoint']}\n",
    "    print(\"Input data feed ::: \",d['text'][0])\n",
    "    return pd.DataFrame(data=d)\n",
    "\n",
    "\n",
    "def prepare_dataloader(seq, y, sampler_type):\n",
    "    global BATCH_SIZE\n",
    "    tensor_dataset = TensorDataset(seq, y)\n",
    "    if sampler_type == 'random':\n",
    "        sampler = RandomSampler(tensor_dataset)\n",
    "    elif sampler_type == 'sequential':\n",
    "        sampler = SequentialSampler(tensor_dataset)\n",
    "    print(\"BATCH_SIZE : \",BATCH_SIZE)\n",
    "    dataloader = DataLoader(tensor_dataset, sampler=sampler, batch_size=BATCH_SIZE)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def within_project_split(data):\n",
    "    print('within project split!')\n",
    "    train_val_split_point = int(len(data) * 0.6)\n",
    "    val_test_split_point = int(len(data) * 0.8)\n",
    "    train_text = data['text'][:train_val_split_point]\n",
    "    train_labels = data['label'][:train_val_split_point]\n",
    "    val_text = data['text'][train_val_split_point:val_test_split_point]\n",
    "    val_labels = data['label'][train_val_split_point:val_test_split_point]\n",
    "    test_text = data['text'][val_test_split_point:]\n",
    "    test_labels = data['label'][val_test_split_point:]\n",
    "    return train_text, train_labels, val_text, val_labels, test_text, test_labels\n",
    "\n",
    "\n",
    "def train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, model, test_file_names):\n",
    "    global LEARNING_RATE, EPOCHS, MAE_RECORDS, MDAE_RECORDS, DEVICE\n",
    "\n",
    "    # Optimizerrr -->\n",
    "    optimizer = AdamW(MODEL.parameters(), lr=LEARNING_RATE)\n",
    "    # Total number of training steps is [number of batches] x [number of epochs]\n",
    "    total_steps = len(train_dataloader) * EPOCHS\n",
    "    # Create the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "    print(\"Start training for \", file_pair, \".....\")\n",
    "    training_start_time = time.time()\n",
    "\n",
    "    # tensorboard writer\n",
    "    writer_path = 'tb/' + str(file_pair['train'][0]) + '_' + str(file_pair['test'][0])\n",
    "    writer = SummaryWriter(writer_path)\n",
    "\n",
    "    # vars for model selection\n",
    "    min_eval_loss_epoch = [10000, 0]\n",
    "\n",
    "    time_records = []\n",
    "    MAE_RECORDS = []\n",
    "    MDAE_RECORDS = []\n",
    "    start_time = time.time()\n",
    "    loss_fct = nn.L1Loss()\n",
    "    for e in range(EPOCHS):\n",
    "        # ---TRAINING---\n",
    "        # clean GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\">>> epoch \", e)\n",
    "        # set model into train mode\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # pdb.set_trace()\n",
    "            b_input_ids = batch[0].to(DEVICE)\n",
    "            b_labels = batch[1].to(DEVICE)\n",
    "            model.zero_grad()\n",
    "            result = model(b_input_ids,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "            loss = result.loss\n",
    "            logits = result.logits\n",
    "            total_train_loss += loss.item()\n",
    "            # Calculates the gradients\n",
    "            loss.backward()\n",
    "            # The clip_grad_norm_ function clips (limits) the norm (magnitude) of the gradients to a maximum value specified by the user.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            #updates the weights and bias accrding to the calculated gradients\n",
    "            optimizer.step()\n",
    "            # update learning rates\n",
    "            scheduler.step()\n",
    "            # clean memory\n",
    "            del step, batch, b_input_ids, b_labels, result, loss, logits\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        print(\" Average training MAE loss: {0:.2f}\".format(avg_train_loss))\n",
    "        writer.add_scalar('loss/train', avg_train_loss, e)\n",
    "        # clean memory\n",
    "        del avg_train_loss, total_train_loss\n",
    "\n",
    "        time_records.append(time.time() - start_time)\n",
    "\n",
    "        # ---EVAL---\n",
    "        print(\"-\")\n",
    "        # set model into eval mode\n",
    "        model.eval()\n",
    "        total_eval_loss = 0\n",
    "        for batch in val_dataloader:\n",
    "            b_input_ids = batch[0].to(DEVICE)\n",
    "            b_labels = batch[1].to(DEVICE)\n",
    "            model.zero_grad()\n",
    "            result = model(b_input_ids,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "            loss = result.loss\n",
    "            logits = result.logits\n",
    "            total_eval_loss += loss.item()\n",
    "            # clean memory\n",
    "            del b_input_ids, b_labels, batch, result, loss, logits\n",
    "        avg_eval_loss = total_eval_loss / len(val_dataloader)\n",
    "        print(\" Average eval MAE loss: {0:.2f}\".format(avg_eval_loss))\n",
    "\n",
    "        if avg_eval_loss <= min_eval_loss_epoch[0]:\n",
    "            min_eval_loss_epoch[0] = avg_eval_loss\n",
    "            min_eval_loss_epoch[1] = e\n",
    "\n",
    "        writer.add_scalar('loss/eval', avg_eval_loss, e)\n",
    "        # clean memory\n",
    "        del avg_eval_loss, total_eval_loss\n",
    "        # save model state to dict\n",
    "        torch.save(model.state_dict(), './models/' + 'epo_' + str(e))\n",
    "\n",
    "        print(\"===============================\")\n",
    "\n",
    "        # testing on holdout data\n",
    "        index = 0\n",
    "        for test_dataloader in all_test_dataloader:\n",
    "            test_file_name = test_file_names[index]\n",
    "            index += 1\n",
    "            testing_start_time = time.time()\n",
    "            predictions = []\n",
    "            true_labels = []\n",
    "            for batch in test_dataloader:\n",
    "                batch = tuple(t.to(DEVICE) for t in batch)\n",
    "                b_input_ids, b_labels = batch\n",
    "                with torch.no_grad():\n",
    "                    logits = model(b_input_ids)\n",
    "                logits = logits['logits'].detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                predictions.append(logits)\n",
    "                true_labels.append(label_ids)\n",
    "            # calculate errors\n",
    "            distance_records = []\n",
    "            for i in range(len(predictions)):\n",
    "                for j in range(len(predictions[i])):\n",
    "                    distance = abs(predictions[i][j] - true_labels[i][j])\n",
    "                    distance_records.append(distance)\n",
    "\n",
    "            ## MAE = mean value of all absolute errors (stored in distance_records)\n",
    "            MAE = np.mean(np.array(distance_records))\n",
    "            ## MdAE = median value of all absolute errors (stored in distance_records)\n",
    "            MdAE = np.median(np.array(distance_records))\n",
    "\n",
    "            MAE_RECORDS.append(MAE)\n",
    "            MDAE_RECORDS.append(MdAE)\n",
    "\n",
    "            global OUTPUT\n",
    "            OUTPUT +=  'Epochs ' + str(e) + '\\n'\n",
    "            OUTPUT += 'MAE: ' + str(MAE) + '\\n'\n",
    "            OUTPUT += 'MdAE: ' + str(MdAE) + '\\n\\n'\n",
    "            print('MAE: ', MAE)\n",
    "            print('MdAE: ', MdAE)\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    # select model\n",
    "    os.rename('models/epo_' + str(min_eval_loss_epoch[1]),\n",
    "              'models/' + str(file_pair['train'][0]) + '_'\n",
    "              + str(file_pair['test'][0]) + '_epo_' + str(min_eval_loss_epoch[1]))\n",
    "\n",
    "    # del unwanted models\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            os.remove(\"models/epo_\" + str(i))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    OUTPUT += 'MAE: ' + str(MAE_RECORDS[min_eval_loss_epoch[1]]) \\\n",
    "                + '  MdAE: ' + str(MDAE_RECORDS[min_eval_loss_epoch[1]]) + '\\n'\n",
    "    OUTPUT += 'training time: ' + str(time_records[min_eval_loss_epoch[1]]) + '\\n'\n",
    "    OUTPUT += 'Epochs: ' + str(min_eval_loss_epoch[1]) +'\\n'\n",
    "    global BATCH_SIZE\n",
    "    OUTPUT += 'batch size: ' + str(BATCH_SIZE) + '\\n'\n",
    "    global ADD_DESCRIPTION\n",
    "    OUTPUT += 'Description added : ' + str(ADD_DESCRIPTION) + '\\n'\n",
    "\n",
    "\n",
    "    print('all done for one project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn3yXK4lhfbo"
   },
   "source": [
    "### Within Project Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "x-uMZ1Cfhfbo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwmBk2BPhfbo",
    "outputId": "42532499-13cb-40db-b31d-95f553d2db2b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_embd/hidden_size :  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertSP were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.dense1.weight', 'bert.dense2.weight', 'bert.score.weight', 'bert.transformer.embeddings.LayerNorm.bias', 'bert.transformer.embeddings.LayerNorm.weight', 'bert.transformer.embeddings.position_embeddings.weight', 'bert.transformer.embeddings.token_type_embeddings.weight', 'bert.transformer.embeddings.word_embeddings.weight', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.attention.output.dense.bias', 'bert.transformer.encoder.layer.0.attention.output.dense.weight', 'bert.transformer.encoder.layer.0.attention.self.key.bias', 'bert.transformer.encoder.layer.0.attention.self.key.weight', 'bert.transformer.encoder.layer.0.attention.self.query.bias', 'bert.transformer.encoder.layer.0.attention.self.query.weight', 'bert.transformer.encoder.layer.0.attention.self.value.bias', 'bert.transformer.encoder.layer.0.attention.self.value.weight', 'bert.transformer.encoder.layer.0.intermediate.dense.bias', 'bert.transformer.encoder.layer.0.intermediate.dense.weight', 'bert.transformer.encoder.layer.0.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.output.dense.bias', 'bert.transformer.encoder.layer.0.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.attention.output.dense.bias', 'bert.transformer.encoder.layer.1.attention.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.self.key.bias', 'bert.transformer.encoder.layer.1.attention.self.key.weight', 'bert.transformer.encoder.layer.1.attention.self.query.bias', 'bert.transformer.encoder.layer.1.attention.self.query.weight', 'bert.transformer.encoder.layer.1.attention.self.value.bias', 'bert.transformer.encoder.layer.1.attention.self.value.weight', 'bert.transformer.encoder.layer.1.intermediate.dense.bias', 'bert.transformer.encoder.layer.1.intermediate.dense.weight', 'bert.transformer.encoder.layer.1.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.output.dense.bias', 'bert.transformer.encoder.layer.1.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.attention.output.dense.bias', 'bert.transformer.encoder.layer.10.attention.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.self.key.bias', 'bert.transformer.encoder.layer.10.attention.self.key.weight', 'bert.transformer.encoder.layer.10.attention.self.query.bias', 'bert.transformer.encoder.layer.10.attention.self.query.weight', 'bert.transformer.encoder.layer.10.attention.self.value.bias', 'bert.transformer.encoder.layer.10.attention.self.value.weight', 'bert.transformer.encoder.layer.10.intermediate.dense.bias', 'bert.transformer.encoder.layer.10.intermediate.dense.weight', 'bert.transformer.encoder.layer.10.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.output.dense.bias', 'bert.transformer.encoder.layer.10.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.attention.output.dense.bias', 'bert.transformer.encoder.layer.11.attention.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.self.key.bias', 'bert.transformer.encoder.layer.11.attention.self.key.weight', 'bert.transformer.encoder.layer.11.attention.self.query.bias', 'bert.transformer.encoder.layer.11.attention.self.query.weight', 'bert.transformer.encoder.layer.11.attention.self.value.bias', 'bert.transformer.encoder.layer.11.attention.self.value.weight', 'bert.transformer.encoder.layer.11.intermediate.dense.bias', 'bert.transformer.encoder.layer.11.intermediate.dense.weight', 'bert.transformer.encoder.layer.11.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.output.dense.bias', 'bert.transformer.encoder.layer.11.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.attention.output.dense.bias', 'bert.transformer.encoder.layer.2.attention.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.self.key.bias', 'bert.transformer.encoder.layer.2.attention.self.key.weight', 'bert.transformer.encoder.layer.2.attention.self.query.bias', 'bert.transformer.encoder.layer.2.attention.self.query.weight', 'bert.transformer.encoder.layer.2.attention.self.value.bias', 'bert.transformer.encoder.layer.2.attention.self.value.weight', 'bert.transformer.encoder.layer.2.intermediate.dense.bias', 'bert.transformer.encoder.layer.2.intermediate.dense.weight', 'bert.transformer.encoder.layer.2.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.output.dense.bias', 'bert.transformer.encoder.layer.2.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.attention.output.dense.bias', 'bert.transformer.encoder.layer.3.attention.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.self.key.bias', 'bert.transformer.encoder.layer.3.attention.self.key.weight', 'bert.transformer.encoder.layer.3.attention.self.query.bias', 'bert.transformer.encoder.layer.3.attention.self.query.weight', 'bert.transformer.encoder.layer.3.attention.self.value.bias', 'bert.transformer.encoder.layer.3.attention.self.value.weight', 'bert.transformer.encoder.layer.3.intermediate.dense.bias', 'bert.transformer.encoder.layer.3.intermediate.dense.weight', 'bert.transformer.encoder.layer.3.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.output.dense.bias', 'bert.transformer.encoder.layer.3.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.attention.output.dense.bias', 'bert.transformer.encoder.layer.4.attention.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.self.key.bias', 'bert.transformer.encoder.layer.4.attention.self.key.weight', 'bert.transformer.encoder.layer.4.attention.self.query.bias', 'bert.transformer.encoder.layer.4.attention.self.query.weight', 'bert.transformer.encoder.layer.4.attention.self.value.bias', 'bert.transformer.encoder.layer.4.attention.self.value.weight', 'bert.transformer.encoder.layer.4.intermediate.dense.bias', 'bert.transformer.encoder.layer.4.intermediate.dense.weight', 'bert.transformer.encoder.layer.4.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.output.dense.bias', 'bert.transformer.encoder.layer.4.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.attention.output.dense.bias', 'bert.transformer.encoder.layer.5.attention.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.self.key.bias', 'bert.transformer.encoder.layer.5.attention.self.key.weight', 'bert.transformer.encoder.layer.5.attention.self.query.bias', 'bert.transformer.encoder.layer.5.attention.self.query.weight', 'bert.transformer.encoder.layer.5.attention.self.value.bias', 'bert.transformer.encoder.layer.5.attention.self.value.weight', 'bert.transformer.encoder.layer.5.intermediate.dense.bias', 'bert.transformer.encoder.layer.5.intermediate.dense.weight', 'bert.transformer.encoder.layer.5.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.output.dense.bias', 'bert.transformer.encoder.layer.5.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.attention.output.dense.bias', 'bert.transformer.encoder.layer.6.attention.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.self.key.bias', 'bert.transformer.encoder.layer.6.attention.self.key.weight', 'bert.transformer.encoder.layer.6.attention.self.query.bias', 'bert.transformer.encoder.layer.6.attention.self.query.weight', 'bert.transformer.encoder.layer.6.attention.self.value.bias', 'bert.transformer.encoder.layer.6.attention.self.value.weight', 'bert.transformer.encoder.layer.6.intermediate.dense.bias', 'bert.transformer.encoder.layer.6.intermediate.dense.weight', 'bert.transformer.encoder.layer.6.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.output.dense.bias', 'bert.transformer.encoder.layer.6.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.attention.output.dense.bias', 'bert.transformer.encoder.layer.7.attention.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.self.key.bias', 'bert.transformer.encoder.layer.7.attention.self.key.weight', 'bert.transformer.encoder.layer.7.attention.self.query.bias', 'bert.transformer.encoder.layer.7.attention.self.query.weight', 'bert.transformer.encoder.layer.7.attention.self.value.bias', 'bert.transformer.encoder.layer.7.attention.self.value.weight', 'bert.transformer.encoder.layer.7.intermediate.dense.bias', 'bert.transformer.encoder.layer.7.intermediate.dense.weight', 'bert.transformer.encoder.layer.7.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.output.dense.bias', 'bert.transformer.encoder.layer.7.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.attention.output.dense.bias', 'bert.transformer.encoder.layer.8.attention.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.self.key.bias', 'bert.transformer.encoder.layer.8.attention.self.key.weight', 'bert.transformer.encoder.layer.8.attention.self.query.bias', 'bert.transformer.encoder.layer.8.attention.self.query.weight', 'bert.transformer.encoder.layer.8.attention.self.value.bias', 'bert.transformer.encoder.layer.8.attention.self.value.weight', 'bert.transformer.encoder.layer.8.intermediate.dense.bias', 'bert.transformer.encoder.layer.8.intermediate.dense.weight', 'bert.transformer.encoder.layer.8.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.output.dense.bias', 'bert.transformer.encoder.layer.8.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.attention.output.dense.bias', 'bert.transformer.encoder.layer.9.attention.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.self.key.bias', 'bert.transformer.encoder.layer.9.attention.self.key.weight', 'bert.transformer.encoder.layer.9.attention.self.query.bias', 'bert.transformer.encoder.layer.9.attention.self.query.weight', 'bert.transformer.encoder.layer.9.attention.self.value.bias', 'bert.transformer.encoder.layer.9.attention.self.value.weight', 'bert.transformer.encoder.layer.9.intermediate.dense.bias', 'bert.transformer.encoder.layer.9.intermediate.dense.weight', 'bert.transformer.encoder.layer.9.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.output.dense.bias', 'bert.transformer.encoder.layer.9.output.dense.weight', 'bert.transformer.pooler.dense.bias', 'bert.transformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text : title+description\n",
      "Input data feed :::  [CLS]Add Copy URL actions to right-click context menu of Remote view for S3 files[SEP]I was able to connect to our Appcelerator S3 bucket to drag and drog copy image files that I wanted to refer to remotely from the Desktop packaging release links webpage. But I had no easy way to tell what the various URLs were that I could use to refer to the resulting S3 objects/files. Cyberduck lets you right click and choose Copy URL > HTTPS, HTTPS, Signed URL (expiring in one hour, one day, or one week + one hour), Torrent URL.[SEP]\n",
      "within project split!\n",
      "usingbert tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_9945/1514377913.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usingbert tokenizer\n",
      "[[101, 101, 5587, 6100, 24471, 2140, 4506, 2000, 2157, 1011, 11562, 6123, 12183, 1997, 6556, 3193, 2005, 1055, 2509, 6764, 102, 1045, 2001, 2583, 2000, 7532, 2000, 2256, 10439, 29109, 6906, 4263, 1055, 2509, 13610, 2000, 8011, 1998, 2852, 8649, 6100, 3746, 6764, 2008, 1045, 2359, 2000, 6523, 2000, 19512, 2013, 1996, 15363, 14793, 2713, 6971, 4773, 13704, 1012, 2021, 1045, 2018, 2053, 3733, 2126, 2000, 2425, 2054, 1996, 2536, 24471, 4877, 2020, 2008, 1045, 2071, 2224, 2000, 6523, 2000, 1996, 4525, 1055, 2509, 5200, 1013, 6764, 1012, 16941, 8566, 3600, 11082, 2017, 2157, 11562, 1998, 5454, 6100, 24471, 2140, 1028, 16770, 1010, 16770, 1010, 2772, 24471, 2140, 1006, 4654, 8197, 4892, 1999, 2028, 3178, 1010, 2028, 2154, 1010, 2030, 2028, 2733, 1009, 2028, 3178, 1007, 1010, 22047, 3372, 24471, 2140, 1012, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 101, 26794, 5162, 5363, 2000, 2330, 1037, 2047, 6013, 1997, 2993, 2043, 3098, 6764, 3081, 3645, 10566, 102, 1063, 16129, 1065, 1026, 4487, 2615, 1028, 1026, 1052, 1028, 4137, 2000, 1026, 1037, 17850, 12879, 1027, 1000, 8299, 1024, 1013, 1013, 26794, 5162, 3367, 21041, 2080, 1012, 8616, 29098, 1012, 4012, 1013, 10287, 1013, 3471, 1013, 4749, 1011, 26794, 5162, 1011, 5363, 1011, 2000, 1011, 2330, 1011, 1037, 1011, 2047, 1011, 6013, 1011, 1997, 1011, 2993, 1011, 2043, 1011, 3098, 1011, 6764, 1011, 2013, 1011, 2663, 1011, 10566, 2063, 1000, 1028, 8616, 3277, 1001, 4749, 1026, 1013, 1037, 1028, 1012, 2004, 2988, 1999, 8616, 1024, 1026, 1013, 1052, 1028, 1026, 3796, 28940, 12184, 1028, 1026, 1052, 1028, 9808, 1024, 2663, 26726, 1026, 1013, 1052, 1028, 1026, 1052, 1028, 2043, 26794, 5162, 2003, 2770, 1998, 1045, 3046, 2000, 2330, 6764, 2013, 2026, 3645, 10566, 1006, 2007, 3313, 11562, 2030, 4607, 1007, 26794, 5162, 8834, 1000, 2573, 15327, 1999, 2224, 2030, 3685, 2022, 2580, 1010, 5454, 1037, 2367, 2028, 1000, 2044, 4760, 1996, 17624, 3898, 2005, 1016, 1011, 1017, 3823, 1012, 1026, 1013, 1052, 1028, 1026, 1052, 1028, 11920, 6764, 2046, 2026, 2770, 6013, 2180, 1005, 1056, 3426, 2023, 5248, 1012, 3098, 6764, 2013, 2026, 2622, 3193, 5320, 2053, 3471, 1010, 3272, 1012, 1044, 2696, 9468, 7971, 6764, 1012, 2004, 1037, 8915, 8737, 5576, 1045, 4900, 2000, 2330, 1012, 1044, 2696, 9468, 7971, 6764, 2007, 3602, 15455, 1012, 1026, 1013, 1052, 1028, 1026, 1052, 1028, 2023, 2003, 2054, 1045, 2525, 2106, 1006, 2007, 2053, 6735, 1007, 1025, 1026, 1013, 1052, 1028, 1026, 17359, 1028, 1026, 5622, 1028, 2026, 8272, 19622, 1998, 2573, 15327, 19622, 2024, 2119, 25697, 3085, 1012, 1026, 1013, 5622, 1028, 1026, 5622, 1028, 1045, 2106, 2195, 3143, 2128, 1011, 16500, 2015, 1012, 1026, 1013, 5622, 1028, 1026, 5622, 1028, 1045, 3718, 1996, 1012, 5843, 5371, 1999, 2026, 2573, 15327, 19622, 1012, 1026, 1013, 5622, 1028, 1026, 5622, 1028, 1045, 2580, 1037, 2047, 2573, 15327, 19622, 2015, 1998, 7237, 2000, 2009, 1012, 1026, 1013, 5622, 1028, 1026, 5622, 1028, 1045, 2031, 8911, 2916, 1012, 1026, 1013, 5622, 1028, 1026, 1013, 17359, 1028, 1026, 1052, 1028, 4526, 1037, 2047, 2573, 15327, 2097, 8081, 2026, 3291, 5741, 2021, 1996, 3291, 2003, 2067, 2306, 1037, 2733, 1012, 1026, 1013, 1052, 1028, 1026, 1052, 1028, 1999, 26794, 5162, 1015, 1012, 1016, 1045, 2196, 2387, 1037, 17624, 3898, 2043, 26794, 5162, 2001, 2770, 1998, 1045, 2441, 2178, 5371, 1012, 1996, 6764, 2020, 2074, 8209, 1999, 1996, 2770, 6013, 1012, 2003, 2023, 3303, 2011, 13232, 1017, 1012, 1019, 1029, 1026, 1013, 1052, 1028, 1026, 1052, 1028, 2023, 2003, 3243, 15703, 3426, 2296, 2051, 1996, 17624, 3898, 3065, 2009, 2593, 3138, 2039, 1017, 3823, 1997, 1996, 5371, 2180, 1005, 1056, 2330, 2349, 2000, 1996, 5299, 2573, 15327, 1012, 1026, 1013, 1052, 1028, 1026, 1013, 3796, 28940, 12184, 1028, 1026, 1013, 4487, 2615, 1028, 1063, 16129, 1065, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 101, 4180, 6509, 3769, 6279, 2003, 3491, 2648, 1996, 3898, 7372, 102, 2004, 2017, 2064, 2156, 2013, 1996, 3746, 1010, 1996, 9262, 22483, 4180, 6509, 3769, 6279, 8834, 2648, 1996, 3898, 6192, 2000, 1996, 2157, 1012, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 101, 25718, 8285, 9006, 10814, 3508, 2005, 6687, 4725, 102, 2043, 2017, 2058, 26373, 1037, 6687, 4118, 2017, 2411, 2342, 2000, 2655, 2009, 2013, 1996, 2047, 4118, 1010, 2742, 1024, 1063, 3642, 1065, 1026, 1029, 25718, 2465, 6687, 1063, 2270, 3853, 9998, 8462, 20744, 11783, 1006, 1007, 1063, 1065, 1065, 2465, 2775, 1063, 2270, 3853, 9998, 8462, 20744, 11783, 1006, 1007, 1063, 1002, 2023, 1011, 1028, 1038, 2721, 1027, 1005, 29379, 1005, 1025, 2709, 6687, 1024, 1024, 1001, 4180, 6509, 2182, 2323, 2031, 9998, 8462, 20744, 11783, 1006, 1007, 1065, 1065, 1029, 1028, 1063, 3642, 1065, 26794, 5162, 2515, 2025, 8285, 9006, 10814, 2618, 1996, 4725, 2044, 1000, 6687, 1024, 1024, 1000, 4081, 8081, 1024, 1001, 3535, 2000, 28024, 1001, 4638, 2000, 2156, 2065, 1996, 8875, 2003, 4964, 1999, 1019, 1012, 1018, 1010, 2030, 1999, 1037, 10947, 2544, 1997, 1996, 1019, 1012, 1017, 11968, 8043, 2015, 1001, 2065, 2025, 1999, 2256, 3642, 1998, 2064, 1005, 1056, 2022, 4964, 1010, 4957, 2000, 22851, 2102, 3277, 28789, 1996, 3291, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 101, 11920, 2019, 3746, 2046, 1996, 16129, 3559, 2323, 3443, 2019, 3746, 6415, 102, 11920, 2019, 3746, 2046, 1996, 3559, 2323, 3443, 1037, 10047, 2290, 6415, 1012, 2017, 2064, 3193, 2023, 5248, 1999, 3793, 8585, 1012, 7510, 2019, 3746, 3031, 1996, 16129, 3559, 19274, 2015, 2019, 3746, 6415, 2007, 1996, 5816, 4130, 2000, 1996, 3746, 1006, 2013, 2023, 16129, 5371, 1007, 1010, 1996, 2152, 2102, 1998, 9381, 1010, 1998, 1996, 12456, 3793, 2004, 1996, 3988, 1011, 3007, 3550, 2544, 1997, 1996, 5371, 18442, 1024, 1045, 1012, 1041, 1012, 11920, 1000, 3964, 1012, 1052, 3070, 1000, 3957, 2033, 1024, 1063, 3642, 1065, 1026, 10047, 2290, 5034, 2278, 1027, 1000, 4871, 1013, 3964, 1012, 1052, 3070, 1000, 9381, 1027, 1000, 3590, 1000, 4578, 1027, 1000, 3590, 1000, 12456, 1027, 1000, 3964, 1000, 1028, 1063, 3642, 1065, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "BATCH_SIZE :  19\n",
      "BATCH_SIZE :  19\n",
      "usingbert tokenizer\n",
      "BATCH_SIZE :  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for  {'train': ['aptanastudio'], 'test': ['aptanastudio']} .....\n",
      ">>> epoch  0\n",
      " Average training MAE loss: 6.33\n",
      "-\n",
      " Average eval MAE loss: 3.59\n",
      "===============================\n",
      "MAE:  3.8603523\n",
      "MdAE:  3.3924856\n",
      ">>> epoch  1\n",
      " Average training MAE loss: 5.19\n",
      "-\n",
      " Average eval MAE loss: 3.52\n",
      "===============================\n",
      "MAE:  3.7480836\n",
      "MdAE:  3.2132874\n",
      ">>> epoch  2\n",
      " Average training MAE loss: 4.54\n",
      "-\n",
      " Average eval MAE loss: 3.73\n",
      "===============================\n",
      "MAE:  3.5083067\n",
      "MdAE:  2.1990442\n",
      ">>> epoch  3\n",
      " Average training MAE loss: 4.58\n",
      "-\n",
      " Average eval MAE loss: 4.19\n",
      "===============================\n",
      "MAE:  3.343536\n",
      "MdAE:  2.0486503\n",
      ">>> epoch  4\n",
      " Average training MAE loss: 4.34\n",
      "-\n",
      " Average eval MAE loss: 3.49\n",
      "===============================\n",
      "MAE:  3.694932\n",
      "MdAE:  3.1284494\n",
      ">>> epoch  5\n",
      " Average training MAE loss: 4.47\n",
      "-\n",
      " Average eval MAE loss: 3.67\n",
      "===============================\n",
      "MAE:  3.5323696\n",
      "MdAE:  2.380608\n",
      ">>> epoch  6\n",
      " Average training MAE loss: 4.55\n",
      "-\n",
      " Average eval MAE loss: 4.09\n",
      "===============================\n",
      "MAE:  4.643793\n",
      "MdAE:  4.6429768\n",
      ">>> epoch  7\n",
      " Average training MAE loss: 4.87\n",
      "-\n",
      " Average eval MAE loss: 4.52\n",
      "===============================\n",
      "MAE:  3.2338662\n",
      "MdAE:  2.9589133\n",
      ">>> epoch  8\n",
      " Average training MAE loss: 4.45\n",
      "-\n",
      " Average eval MAE loss: 3.46\n",
      "===============================\n",
      "MAE:  3.6082904\n",
      "MdAE:  2.9534626\n",
      ">>> epoch  9\n",
      " Average training MAE loss: 4.36\n",
      "-\n",
      " Average eval MAE loss: 3.57\n",
      "===============================\n",
      "MAE:  3.8155715\n",
      "MdAE:  3.3210087\n",
      ">>> epoch  10\n",
      " Average training MAE loss: 4.34\n",
      "-\n",
      " Average eval MAE loss: 4.14\n",
      "===============================\n",
      "MAE:  3.3591897\n",
      "MdAE:  1.9261122\n",
      ">>> epoch  11\n",
      " Average training MAE loss: 4.59\n",
      "-\n",
      " Average eval MAE loss: 3.49\n",
      "===============================\n",
      "MAE:  3.5968785\n",
      "MdAE:  2.8673568\n",
      ">>> epoch  12\n",
      " Average training MAE loss: 4.48\n",
      "-\n",
      " Average eval MAE loss: 3.55\n",
      "===============================\n",
      "MAE:  3.573371\n",
      "MdAE:  2.6899853\n",
      ">>> epoch  13\n",
      " Average training MAE loss: 4.25\n",
      "-\n",
      " Average eval MAE loss: 3.59\n",
      "===============================\n",
      "MAE:  3.8506458\n",
      "MdAE:  3.3769932\n",
      ">>> epoch  14\n",
      " Average training MAE loss: 4.41\n",
      "-\n",
      " Average eval MAE loss: 3.55\n",
      "===============================\n",
      "MAE:  3.575938\n",
      "MdAE:  2.7093515\n",
      ">>> epoch  15\n",
      " Average training MAE loss: 4.45\n",
      "-\n",
      " Average eval MAE loss: 3.82\n",
      "===============================\n",
      "MAE:  4.2227535\n",
      "MdAE:  3.970933\n",
      ">>> epoch  16\n",
      " Average training MAE loss: 4.38\n",
      "-\n",
      " Average eval MAE loss: 3.80\n",
      "===============================\n",
      "MAE:  4.1818824\n",
      "MdAE:  3.9056969\n",
      ">>> epoch  17\n",
      " Average training MAE loss: 4.32\n",
      "-\n",
      " Average eval MAE loss: 3.51\n",
      "===============================\n",
      "MAE:  3.7296128\n",
      "MdAE:  3.1838055\n",
      ">>> epoch  18\n",
      " Average training MAE loss: 4.23\n",
      "-\n",
      " Average eval MAE loss: 3.55\n",
      "===============================\n",
      "MAE:  3.791917\n",
      "MdAE:  3.2832527\n",
      ">>> epoch  19\n",
      " Average training MAE loss: 4.25\n",
      "-\n",
      " Average eval MAE loss: 3.55\n",
      "===============================\n",
      "MAE:  3.7871482\n",
      "MdAE:  3.2756414\n",
      "all done for one project\n",
      "results have been written into a text file!\n",
      "n_embd/hidden_size :  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertSP were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.dense1.weight', 'bert.dense2.weight', 'bert.score.weight', 'bert.transformer.embeddings.LayerNorm.bias', 'bert.transformer.embeddings.LayerNorm.weight', 'bert.transformer.embeddings.position_embeddings.weight', 'bert.transformer.embeddings.token_type_embeddings.weight', 'bert.transformer.embeddings.word_embeddings.weight', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.attention.output.dense.bias', 'bert.transformer.encoder.layer.0.attention.output.dense.weight', 'bert.transformer.encoder.layer.0.attention.self.key.bias', 'bert.transformer.encoder.layer.0.attention.self.key.weight', 'bert.transformer.encoder.layer.0.attention.self.query.bias', 'bert.transformer.encoder.layer.0.attention.self.query.weight', 'bert.transformer.encoder.layer.0.attention.self.value.bias', 'bert.transformer.encoder.layer.0.attention.self.value.weight', 'bert.transformer.encoder.layer.0.intermediate.dense.bias', 'bert.transformer.encoder.layer.0.intermediate.dense.weight', 'bert.transformer.encoder.layer.0.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.output.dense.bias', 'bert.transformer.encoder.layer.0.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.attention.output.dense.bias', 'bert.transformer.encoder.layer.1.attention.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.self.key.bias', 'bert.transformer.encoder.layer.1.attention.self.key.weight', 'bert.transformer.encoder.layer.1.attention.self.query.bias', 'bert.transformer.encoder.layer.1.attention.self.query.weight', 'bert.transformer.encoder.layer.1.attention.self.value.bias', 'bert.transformer.encoder.layer.1.attention.self.value.weight', 'bert.transformer.encoder.layer.1.intermediate.dense.bias', 'bert.transformer.encoder.layer.1.intermediate.dense.weight', 'bert.transformer.encoder.layer.1.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.output.dense.bias', 'bert.transformer.encoder.layer.1.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.attention.output.dense.bias', 'bert.transformer.encoder.layer.10.attention.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.self.key.bias', 'bert.transformer.encoder.layer.10.attention.self.key.weight', 'bert.transformer.encoder.layer.10.attention.self.query.bias', 'bert.transformer.encoder.layer.10.attention.self.query.weight', 'bert.transformer.encoder.layer.10.attention.self.value.bias', 'bert.transformer.encoder.layer.10.attention.self.value.weight', 'bert.transformer.encoder.layer.10.intermediate.dense.bias', 'bert.transformer.encoder.layer.10.intermediate.dense.weight', 'bert.transformer.encoder.layer.10.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.output.dense.bias', 'bert.transformer.encoder.layer.10.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.attention.output.dense.bias', 'bert.transformer.encoder.layer.11.attention.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.self.key.bias', 'bert.transformer.encoder.layer.11.attention.self.key.weight', 'bert.transformer.encoder.layer.11.attention.self.query.bias', 'bert.transformer.encoder.layer.11.attention.self.query.weight', 'bert.transformer.encoder.layer.11.attention.self.value.bias', 'bert.transformer.encoder.layer.11.attention.self.value.weight', 'bert.transformer.encoder.layer.11.intermediate.dense.bias', 'bert.transformer.encoder.layer.11.intermediate.dense.weight', 'bert.transformer.encoder.layer.11.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.output.dense.bias', 'bert.transformer.encoder.layer.11.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.attention.output.dense.bias', 'bert.transformer.encoder.layer.2.attention.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.self.key.bias', 'bert.transformer.encoder.layer.2.attention.self.key.weight', 'bert.transformer.encoder.layer.2.attention.self.query.bias', 'bert.transformer.encoder.layer.2.attention.self.query.weight', 'bert.transformer.encoder.layer.2.attention.self.value.bias', 'bert.transformer.encoder.layer.2.attention.self.value.weight', 'bert.transformer.encoder.layer.2.intermediate.dense.bias', 'bert.transformer.encoder.layer.2.intermediate.dense.weight', 'bert.transformer.encoder.layer.2.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.output.dense.bias', 'bert.transformer.encoder.layer.2.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.attention.output.dense.bias', 'bert.transformer.encoder.layer.3.attention.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.self.key.bias', 'bert.transformer.encoder.layer.3.attention.self.key.weight', 'bert.transformer.encoder.layer.3.attention.self.query.bias', 'bert.transformer.encoder.layer.3.attention.self.query.weight', 'bert.transformer.encoder.layer.3.attention.self.value.bias', 'bert.transformer.encoder.layer.3.attention.self.value.weight', 'bert.transformer.encoder.layer.3.intermediate.dense.bias', 'bert.transformer.encoder.layer.3.intermediate.dense.weight', 'bert.transformer.encoder.layer.3.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.output.dense.bias', 'bert.transformer.encoder.layer.3.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.attention.output.dense.bias', 'bert.transformer.encoder.layer.4.attention.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.self.key.bias', 'bert.transformer.encoder.layer.4.attention.self.key.weight', 'bert.transformer.encoder.layer.4.attention.self.query.bias', 'bert.transformer.encoder.layer.4.attention.self.query.weight', 'bert.transformer.encoder.layer.4.attention.self.value.bias', 'bert.transformer.encoder.layer.4.attention.self.value.weight', 'bert.transformer.encoder.layer.4.intermediate.dense.bias', 'bert.transformer.encoder.layer.4.intermediate.dense.weight', 'bert.transformer.encoder.layer.4.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.output.dense.bias', 'bert.transformer.encoder.layer.4.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.attention.output.dense.bias', 'bert.transformer.encoder.layer.5.attention.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.self.key.bias', 'bert.transformer.encoder.layer.5.attention.self.key.weight', 'bert.transformer.encoder.layer.5.attention.self.query.bias', 'bert.transformer.encoder.layer.5.attention.self.query.weight', 'bert.transformer.encoder.layer.5.attention.self.value.bias', 'bert.transformer.encoder.layer.5.attention.self.value.weight', 'bert.transformer.encoder.layer.5.intermediate.dense.bias', 'bert.transformer.encoder.layer.5.intermediate.dense.weight', 'bert.transformer.encoder.layer.5.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.output.dense.bias', 'bert.transformer.encoder.layer.5.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.attention.output.dense.bias', 'bert.transformer.encoder.layer.6.attention.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.self.key.bias', 'bert.transformer.encoder.layer.6.attention.self.key.weight', 'bert.transformer.encoder.layer.6.attention.self.query.bias', 'bert.transformer.encoder.layer.6.attention.self.query.weight', 'bert.transformer.encoder.layer.6.attention.self.value.bias', 'bert.transformer.encoder.layer.6.attention.self.value.weight', 'bert.transformer.encoder.layer.6.intermediate.dense.bias', 'bert.transformer.encoder.layer.6.intermediate.dense.weight', 'bert.transformer.encoder.layer.6.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.output.dense.bias', 'bert.transformer.encoder.layer.6.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.attention.output.dense.bias', 'bert.transformer.encoder.layer.7.attention.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.self.key.bias', 'bert.transformer.encoder.layer.7.attention.self.key.weight', 'bert.transformer.encoder.layer.7.attention.self.query.bias', 'bert.transformer.encoder.layer.7.attention.self.query.weight', 'bert.transformer.encoder.layer.7.attention.self.value.bias', 'bert.transformer.encoder.layer.7.attention.self.value.weight', 'bert.transformer.encoder.layer.7.intermediate.dense.bias', 'bert.transformer.encoder.layer.7.intermediate.dense.weight', 'bert.transformer.encoder.layer.7.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.output.dense.bias', 'bert.transformer.encoder.layer.7.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.attention.output.dense.bias', 'bert.transformer.encoder.layer.8.attention.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.self.key.bias', 'bert.transformer.encoder.layer.8.attention.self.key.weight', 'bert.transformer.encoder.layer.8.attention.self.query.bias', 'bert.transformer.encoder.layer.8.attention.self.query.weight', 'bert.transformer.encoder.layer.8.attention.self.value.bias', 'bert.transformer.encoder.layer.8.attention.self.value.weight', 'bert.transformer.encoder.layer.8.intermediate.dense.bias', 'bert.transformer.encoder.layer.8.intermediate.dense.weight', 'bert.transformer.encoder.layer.8.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.output.dense.bias', 'bert.transformer.encoder.layer.8.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.attention.output.dense.bias', 'bert.transformer.encoder.layer.9.attention.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.self.key.bias', 'bert.transformer.encoder.layer.9.attention.self.key.weight', 'bert.transformer.encoder.layer.9.attention.self.query.bias', 'bert.transformer.encoder.layer.9.attention.self.query.weight', 'bert.transformer.encoder.layer.9.attention.self.value.bias', 'bert.transformer.encoder.layer.9.attention.self.value.weight', 'bert.transformer.encoder.layer.9.intermediate.dense.bias', 'bert.transformer.encoder.layer.9.intermediate.dense.weight', 'bert.transformer.encoder.layer.9.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.output.dense.bias', 'bert.transformer.encoder.layer.9.output.dense.weight', 'bert.transformer.pooler.dense.bias', 'bert.transformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/tmp/ipykernel_9945/1514377913.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text : title+description\n",
      "Input data feed :::  [CLS]Allows CVS repo to timeout and report on locking issues[SEP]Sometimes, when you perform a CVS action you get something like    {noformat}  cvs update: [01:38:32] waiting for mchai's lock in /cvsroot/atlassian/maven2test/bamboo  {noformat}    so Bamboo would probably just hang and become not so happy. We should allow Bamboo to timeout, or conditionally stop and tell the user how to dix the problem[SEP]\n",
      "within project split!\n",
      "usingbert tokenizer\n",
      "usingbert tokenizer\n",
      "[[101, 101, 4473, 26226, 2015, 16360, 2080, 2000, 2051, 5833, 1998, 3189, 2006, 14889, 3314, 102, 2823, 1010, 2043, 2017, 4685, 1037, 26226, 2015, 2895, 2017, 2131, 2242, 2066, 1063, 2053, 14192, 4017, 1065, 26226, 2015, 10651, 1024, 1031, 5890, 1024, 4229, 1024, 3590, 1033, 3403, 2005, 11338, 10932, 1005, 1055, 5843, 1999, 1013, 26226, 21338, 17206, 1013, 11568, 17043, 1013, 5003, 8159, 2475, 22199, 1013, 15216, 1063, 2053, 14192, 4017, 1065, 2061, 15216, 2052, 2763, 2074, 6865, 1998, 2468, 2025, 2061, 3407, 1012, 2057, 2323, 3499, 15216, 2000, 2051, 5833, 1010, 2030, 18462, 2135, 2644, 1998, 2425, 1996, 5310, 2129, 2000, 4487, 2595, 1996, 3291, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 101, 3499, 1037, 3857, 2000, 2022, 2872, 2012, 1996, 2132, 1997, 1996, 3857, 24240, 1012, 1012, 1012, 1006, 2030, 10086, 1996, 24240, 2344, 1007, 102, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 101, 2765, 2025, 5552, 2043, 4638, 5833, 11896, 102, 3047, 7483, 2006, 2256, 4354, 15216, 1024, 16770, 1024, 1013, 1013, 21942, 1012, 15216, 2475, 1012, 11568, 17043, 1012, 4012, 1013, 11347, 2063, 1013, 20014, 1011, 24529, 2102, 15216, 2001, 9725, 2013, 1016, 1012, 1014, 1012, 1019, 2000, 1016, 1012, 2321, 1045, 2018, 3857, 8833, 7696, 2066, 1024, 1063, 2053, 14192, 4017, 1065, 2756, 1011, 5553, 1011, 2268, 6021, 1024, 2260, 1024, 2603, 3857, 20014, 1011, 24529, 2102, 1011, 10114, 2581, 2318, 2311, 2006, 4005, 12398, 4005, 2756, 1011, 5553, 1011, 2268, 6021, 1024, 2260, 1024, 2603, 2039, 16616, 3120, 3642, 2000, 13921, 1024, 25717, 20842, 2756, 1011, 5553, 1011, 2268, 6021, 1024, 2260, 1024, 2603, 3120, 2179, 2012, 1005, 1013, 23569, 1013, 1046, 2475, 4402, 1013, 13100, 1013, 15216, 2475, 1012, 11568, 17043, 1012, 4012, 1013, 21942, 1013, 4773, 29098, 2015, 1013, 2951, 1013, 15216, 1011, 1016, 1012, 1014, 1012, 1016, 1011, 3535, 1013, 20950, 1011, 2951, 1013, 3857, 1011, 16101, 1013, 20014, 1011, 24529, 2102, 1005, 1012, 2039, 16616, 3120, 1012, 1012, 1012, 2756, 1011, 5553, 1011, 2268, 6021, 1024, 2260, 1024, 2484, 1013, 23569, 1013, 1046, 2475, 4402, 1013, 13100, 1013, 15216, 2475, 1012, 11568, 17043, 1012, 4012, 1013, 21942, 1013, 4773, 29098, 2015, 1013, 2951, 1013, 15216, 1011, 1016, 1012, 1014, 1012, 1016, 1011, 3535, 1013, 20950, 1011, 2951, 1013, 3857, 1011, 16101, 1013, 20014, 1011, 24529, 2102, 1013, 5034, 2278, 1013, 3231, 1013, 9262, 1013, 4012, 1013, 11568, 17043, 1013, 1996, 24759, 15916, 2378, 1013, 2801, 2756, 1011, 5553, 1011, 2268, 6021, 1024, 2260, 1024, 2484, 1013, 23569, 1013, 1046, 2475, 4402, 1013, 13100, 1013, 15216, 2475, 1012, 11568, 17043, 1012, 4012, 1013, 21942, 1013, 4773, 29098, 2015, 1013, 2951, 1013, 15216, 1011, 1016, 1012, 1014, 1012, 1016, 1011, 3535, 1013, 20950, 1011, 2951, 1013, 3857, 1011, 16101, 1013, 20014, 1011, 24529, 2102, 1013, 5034, 2278, 1013, 3231, 1013, 9262, 1013, 4012, 1013, 11568, 17043, 1013, 1996, 24759, 15916, 2378, 2756, 1011, 5553, 1011, 2268, 6021, 1024, 2260, 1024, 2484, 1013, 23569, 1013, 1046, 2475, 4402, 1013, 13100, 1013, 15216, 2475, 1012, 11568, 17043, 1012, 4012, 1013, 21942, 1013, 4773, 29098, 2015, 1013, 2951, 1013, 15216, 1011, 1016, 1012, 1014, 1012, 1016, 1011, 3535, 1013, 20950, 1011, 2951, 1013, 3857, 1011, 16101, 1013, 20014, 1011, 24529, 2102, 1013, 5034, 2278, 1013, 3231, 1013, 9262, 1013, 4012, 1013, 11568, 17043, 2756, 1011, 5553, 1011, 2268, 6021, 1024, 2260, 1024, 2484, 1013, 23569, 1013, 1046, 2475, 4402, 1013, 13100, 1013, 15216, 2475, 1012, 11568, 17043, 1012, 4012, 1013, 21942, 1013, 4773, 29098, 2015, 1013, 2951, 1013, 15216, 1011, 1016, 1012, 1014, 1012, 1016, 1011, 3535, 1013, 20950, 1011, 2951, 1013, 3857, 1011, 16101, 1013, 20014, 1011, 24529, 2102, 1013, 5034, 2278, 1013, 3231, 1013, 9262, 1013, 4012, 2756, 1011, 5553, 1011, 2268, 6021, 1024, 2260, 1024, 2484, 1013, 23569, 1013, 1046, 2475, 4402, 1013, 13100, 1013, 15216, 2475, 1012, 11568, 17043, 1012, 4012, 1013, 21942, 1013, 4773, 29098, 2015, 1013, 2951, 1013, 15216, 1011, 1016, 1012, 1014, 1012, 1016, 1011, 3535, 1013, 20950, 1011, 2951, 1013, 3857, 1011, 102], [101, 101, 2831, 5963, 2013, 21274, 4005, 2000, 15216, 8241, 2000, 2421, 1041, 5910, 3872, 4057, 3463, 102, 2043, 2019, 21274, 6013, 1013, 4005, 2003, 26928, 2000, 4057, 1037, 1041, 5910, 3872, 4820, 1037, 20057, 12326, 2076, 22752, 1996, 5082, 1013, 3112, 1013, 8246, 2323, 2022, 7349, 2067, 2000, 15216, 8241, 2005, 4653, 1012, 1996, 8833, 1999, 1013, 1056, 8737, 1013, 16437, 15878, 4757, 2532, 4523, 12326, 1012, 8833, 2071, 2022, 2109, 2000, 2832, 5082, 1998, 3463, 1012, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 101, 5198, 2064, 2156, 1996, 5003, 8159, 11336, 1006, 2177, 3593, 1010, 20785, 3593, 1010, 2544, 1007, 2114, 2169, 2933, 1012, 102, 1008, 2323, 4847, 1996, 4942, 1011, 2551, 14176, 1012, 2069, 2298, 2005, 13433, 5244, 2104, 1996, 4942, 1011, 2551, 14176, 1008, 2069, 3191, 2327, 2504, 13433, 2213, 2005, 14184, 1008, 13433, 2213, 2003, 3191, 2069, 2043, 2311, 1012, 1008, 2023, 2003, 2069, 3191, 2069, 1008, 2169, 2933, 2089, 2031, 3674, 10471, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "BATCH_SIZE :  12\n",
      "BATCH_SIZE :  12\n",
      "usingbert tokenizer\n",
      "BATCH_SIZE :  12\n",
      "Start training for  {'train': ['bamboo'], 'test': ['bamboo']} .....\n",
      ">>> epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training MAE loss: 4.01\n",
      "-\n",
      " Average eval MAE loss: 1.40\n",
      "===============================\n",
      "MAE:  1.3443125\n",
      "MdAE:  1.0339017\n",
      ">>> epoch  1\n",
      " Average training MAE loss: 1.75\n",
      "-\n",
      " Average eval MAE loss: 2.80\n",
      "===============================\n",
      "MAE:  2.709782\n",
      "MdAE:  2.551826\n",
      ">>> epoch  2\n",
      " Average training MAE loss: 1.78\n",
      "-\n",
      " Average eval MAE loss: 1.20\n",
      "===============================\n",
      "MAE:  1.1853597\n",
      "MdAE:  0.77055573\n",
      ">>> epoch  3\n",
      " Average training MAE loss: 1.77\n",
      "-\n",
      " Average eval MAE loss: 0.74\n",
      "===============================\n",
      "MAE:  0.83854705\n",
      "MdAE:  0.6959566\n",
      ">>> epoch  4\n",
      " Average training MAE loss: 1.59\n",
      "-\n",
      " Average eval MAE loss: 1.52\n",
      "===============================\n",
      "MAE:  1.465989\n",
      "MdAE:  1.171278\n",
      ">>> epoch  5\n",
      " Average training MAE loss: 1.52\n",
      "-\n",
      " Average eval MAE loss: 0.67\n",
      "===============================\n",
      "MAE:  0.76978016\n",
      "MdAE:  0.85946786\n",
      ">>> epoch  6\n",
      " Average training MAE loss: 1.60\n",
      "-\n",
      " Average eval MAE loss: 0.72\n",
      "===============================\n",
      "MAE:  0.8151274\n",
      "MdAE:  0.506798\n",
      ">>> epoch  7\n",
      " Average training MAE loss: 1.56\n",
      "-\n",
      " Average eval MAE loss: 1.27\n",
      "===============================\n",
      "MAE:  1.2370858\n",
      "MdAE:  0.86261106\n",
      ">>> epoch  8\n",
      " Average training MAE loss: 1.48\n",
      "-\n",
      " Average eval MAE loss: 0.79\n",
      "===============================\n",
      "MAE:  0.8629075\n",
      "MdAE:  0.8033004\n",
      ">>> epoch  9\n",
      " Average training MAE loss: 1.47\n",
      "-\n",
      " Average eval MAE loss: 1.33\n",
      "===============================\n",
      "MAE:  1.2887677\n",
      "MdAE:  0.954587\n",
      ">>> epoch  10\n",
      " Average training MAE loss: 1.48\n",
      "-\n",
      " Average eval MAE loss: 0.71\n",
      "===============================\n",
      "MAE:  0.7976562\n",
      "MdAE:  0.9194257\n",
      ">>> epoch  11\n",
      " Average training MAE loss: 1.45\n",
      "-\n",
      " Average eval MAE loss: 0.80\n",
      "===============================\n",
      "MAE:  0.87053156\n",
      "MdAE:  0.7897322\n",
      ">>> epoch  12\n",
      " Average training MAE loss: 1.43\n",
      "-\n",
      " Average eval MAE loss: 1.00\n",
      "===============================\n",
      "MAE:  1.0240092\n",
      "MdAE:  0.51659393\n",
      ">>> epoch  13\n",
      " Average training MAE loss: 1.47\n",
      "-\n",
      " Average eval MAE loss: 0.67\n",
      "===============================\n",
      "MAE:  0.7668978\n",
      "MdAE:  0.882748\n",
      ">>> epoch  14\n",
      " Average training MAE loss: 1.54\n",
      "-\n",
      " Average eval MAE loss: 0.66\n",
      "===============================\n",
      "MAE:  0.7572631\n",
      "MdAE:  0.96056724\n",
      ">>> epoch  15\n",
      " Average training MAE loss: 1.43\n",
      "-\n",
      " Average eval MAE loss: 0.70\n",
      "===============================\n",
      "MAE:  0.7862271\n",
      "MdAE:  0.93976545\n",
      ">>> epoch  16\n",
      " Average training MAE loss: 1.42\n",
      "-\n",
      " Average eval MAE loss: 0.69\n",
      "===============================\n",
      "MAE:  0.7829278\n",
      "MdAE:  0.94563746\n",
      ">>> epoch  17\n",
      " Average training MAE loss: 1.43\n",
      "-\n",
      " Average eval MAE loss: 0.71\n",
      "===============================\n",
      "MAE:  0.7970987\n",
      "MdAE:  0.92041755\n",
      ">>> epoch  18\n",
      " Average training MAE loss: 1.42\n",
      "-\n",
      " Average eval MAE loss: 0.79\n",
      "===============================\n",
      "MAE:  0.860672\n",
      "MdAE:  0.8072791\n",
      ">>> epoch  19\n",
      " Average training MAE loss: 1.42\n",
      "-\n",
      " Average eval MAE loss: 0.73\n",
      "===============================\n",
      "MAE:  0.8159172\n",
      "MdAE:  0.8869271\n",
      "all done for one project\n",
      "results have been written into a text file!\n",
      "n_embd/hidden_size :  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertSP were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.dense1.weight', 'bert.dense2.weight', 'bert.score.weight', 'bert.transformer.embeddings.LayerNorm.bias', 'bert.transformer.embeddings.LayerNorm.weight', 'bert.transformer.embeddings.position_embeddings.weight', 'bert.transformer.embeddings.token_type_embeddings.weight', 'bert.transformer.embeddings.word_embeddings.weight', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.attention.output.dense.bias', 'bert.transformer.encoder.layer.0.attention.output.dense.weight', 'bert.transformer.encoder.layer.0.attention.self.key.bias', 'bert.transformer.encoder.layer.0.attention.self.key.weight', 'bert.transformer.encoder.layer.0.attention.self.query.bias', 'bert.transformer.encoder.layer.0.attention.self.query.weight', 'bert.transformer.encoder.layer.0.attention.self.value.bias', 'bert.transformer.encoder.layer.0.attention.self.value.weight', 'bert.transformer.encoder.layer.0.intermediate.dense.bias', 'bert.transformer.encoder.layer.0.intermediate.dense.weight', 'bert.transformer.encoder.layer.0.output.LayerNorm.bias', 'bert.transformer.encoder.layer.0.output.LayerNorm.weight', 'bert.transformer.encoder.layer.0.output.dense.bias', 'bert.transformer.encoder.layer.0.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.attention.output.dense.bias', 'bert.transformer.encoder.layer.1.attention.output.dense.weight', 'bert.transformer.encoder.layer.1.attention.self.key.bias', 'bert.transformer.encoder.layer.1.attention.self.key.weight', 'bert.transformer.encoder.layer.1.attention.self.query.bias', 'bert.transformer.encoder.layer.1.attention.self.query.weight', 'bert.transformer.encoder.layer.1.attention.self.value.bias', 'bert.transformer.encoder.layer.1.attention.self.value.weight', 'bert.transformer.encoder.layer.1.intermediate.dense.bias', 'bert.transformer.encoder.layer.1.intermediate.dense.weight', 'bert.transformer.encoder.layer.1.output.LayerNorm.bias', 'bert.transformer.encoder.layer.1.output.LayerNorm.weight', 'bert.transformer.encoder.layer.1.output.dense.bias', 'bert.transformer.encoder.layer.1.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.attention.output.dense.bias', 'bert.transformer.encoder.layer.10.attention.output.dense.weight', 'bert.transformer.encoder.layer.10.attention.self.key.bias', 'bert.transformer.encoder.layer.10.attention.self.key.weight', 'bert.transformer.encoder.layer.10.attention.self.query.bias', 'bert.transformer.encoder.layer.10.attention.self.query.weight', 'bert.transformer.encoder.layer.10.attention.self.value.bias', 'bert.transformer.encoder.layer.10.attention.self.value.weight', 'bert.transformer.encoder.layer.10.intermediate.dense.bias', 'bert.transformer.encoder.layer.10.intermediate.dense.weight', 'bert.transformer.encoder.layer.10.output.LayerNorm.bias', 'bert.transformer.encoder.layer.10.output.LayerNorm.weight', 'bert.transformer.encoder.layer.10.output.dense.bias', 'bert.transformer.encoder.layer.10.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.attention.output.dense.bias', 'bert.transformer.encoder.layer.11.attention.output.dense.weight', 'bert.transformer.encoder.layer.11.attention.self.key.bias', 'bert.transformer.encoder.layer.11.attention.self.key.weight', 'bert.transformer.encoder.layer.11.attention.self.query.bias', 'bert.transformer.encoder.layer.11.attention.self.query.weight', 'bert.transformer.encoder.layer.11.attention.self.value.bias', 'bert.transformer.encoder.layer.11.attention.self.value.weight', 'bert.transformer.encoder.layer.11.intermediate.dense.bias', 'bert.transformer.encoder.layer.11.intermediate.dense.weight', 'bert.transformer.encoder.layer.11.output.LayerNorm.bias', 'bert.transformer.encoder.layer.11.output.LayerNorm.weight', 'bert.transformer.encoder.layer.11.output.dense.bias', 'bert.transformer.encoder.layer.11.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.attention.output.dense.bias', 'bert.transformer.encoder.layer.2.attention.output.dense.weight', 'bert.transformer.encoder.layer.2.attention.self.key.bias', 'bert.transformer.encoder.layer.2.attention.self.key.weight', 'bert.transformer.encoder.layer.2.attention.self.query.bias', 'bert.transformer.encoder.layer.2.attention.self.query.weight', 'bert.transformer.encoder.layer.2.attention.self.value.bias', 'bert.transformer.encoder.layer.2.attention.self.value.weight', 'bert.transformer.encoder.layer.2.intermediate.dense.bias', 'bert.transformer.encoder.layer.2.intermediate.dense.weight', 'bert.transformer.encoder.layer.2.output.LayerNorm.bias', 'bert.transformer.encoder.layer.2.output.LayerNorm.weight', 'bert.transformer.encoder.layer.2.output.dense.bias', 'bert.transformer.encoder.layer.2.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.attention.output.dense.bias', 'bert.transformer.encoder.layer.3.attention.output.dense.weight', 'bert.transformer.encoder.layer.3.attention.self.key.bias', 'bert.transformer.encoder.layer.3.attention.self.key.weight', 'bert.transformer.encoder.layer.3.attention.self.query.bias', 'bert.transformer.encoder.layer.3.attention.self.query.weight', 'bert.transformer.encoder.layer.3.attention.self.value.bias', 'bert.transformer.encoder.layer.3.attention.self.value.weight', 'bert.transformer.encoder.layer.3.intermediate.dense.bias', 'bert.transformer.encoder.layer.3.intermediate.dense.weight', 'bert.transformer.encoder.layer.3.output.LayerNorm.bias', 'bert.transformer.encoder.layer.3.output.LayerNorm.weight', 'bert.transformer.encoder.layer.3.output.dense.bias', 'bert.transformer.encoder.layer.3.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.attention.output.dense.bias', 'bert.transformer.encoder.layer.4.attention.output.dense.weight', 'bert.transformer.encoder.layer.4.attention.self.key.bias', 'bert.transformer.encoder.layer.4.attention.self.key.weight', 'bert.transformer.encoder.layer.4.attention.self.query.bias', 'bert.transformer.encoder.layer.4.attention.self.query.weight', 'bert.transformer.encoder.layer.4.attention.self.value.bias', 'bert.transformer.encoder.layer.4.attention.self.value.weight', 'bert.transformer.encoder.layer.4.intermediate.dense.bias', 'bert.transformer.encoder.layer.4.intermediate.dense.weight', 'bert.transformer.encoder.layer.4.output.LayerNorm.bias', 'bert.transformer.encoder.layer.4.output.LayerNorm.weight', 'bert.transformer.encoder.layer.4.output.dense.bias', 'bert.transformer.encoder.layer.4.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.attention.output.dense.bias', 'bert.transformer.encoder.layer.5.attention.output.dense.weight', 'bert.transformer.encoder.layer.5.attention.self.key.bias', 'bert.transformer.encoder.layer.5.attention.self.key.weight', 'bert.transformer.encoder.layer.5.attention.self.query.bias', 'bert.transformer.encoder.layer.5.attention.self.query.weight', 'bert.transformer.encoder.layer.5.attention.self.value.bias', 'bert.transformer.encoder.layer.5.attention.self.value.weight', 'bert.transformer.encoder.layer.5.intermediate.dense.bias', 'bert.transformer.encoder.layer.5.intermediate.dense.weight', 'bert.transformer.encoder.layer.5.output.LayerNorm.bias', 'bert.transformer.encoder.layer.5.output.LayerNorm.weight', 'bert.transformer.encoder.layer.5.output.dense.bias', 'bert.transformer.encoder.layer.5.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.attention.output.dense.bias', 'bert.transformer.encoder.layer.6.attention.output.dense.weight', 'bert.transformer.encoder.layer.6.attention.self.key.bias', 'bert.transformer.encoder.layer.6.attention.self.key.weight', 'bert.transformer.encoder.layer.6.attention.self.query.bias', 'bert.transformer.encoder.layer.6.attention.self.query.weight', 'bert.transformer.encoder.layer.6.attention.self.value.bias', 'bert.transformer.encoder.layer.6.attention.self.value.weight', 'bert.transformer.encoder.layer.6.intermediate.dense.bias', 'bert.transformer.encoder.layer.6.intermediate.dense.weight', 'bert.transformer.encoder.layer.6.output.LayerNorm.bias', 'bert.transformer.encoder.layer.6.output.LayerNorm.weight', 'bert.transformer.encoder.layer.6.output.dense.bias', 'bert.transformer.encoder.layer.6.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.attention.output.dense.bias', 'bert.transformer.encoder.layer.7.attention.output.dense.weight', 'bert.transformer.encoder.layer.7.attention.self.key.bias', 'bert.transformer.encoder.layer.7.attention.self.key.weight', 'bert.transformer.encoder.layer.7.attention.self.query.bias', 'bert.transformer.encoder.layer.7.attention.self.query.weight', 'bert.transformer.encoder.layer.7.attention.self.value.bias', 'bert.transformer.encoder.layer.7.attention.self.value.weight', 'bert.transformer.encoder.layer.7.intermediate.dense.bias', 'bert.transformer.encoder.layer.7.intermediate.dense.weight', 'bert.transformer.encoder.layer.7.output.LayerNorm.bias', 'bert.transformer.encoder.layer.7.output.LayerNorm.weight', 'bert.transformer.encoder.layer.7.output.dense.bias', 'bert.transformer.encoder.layer.7.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.attention.output.dense.bias', 'bert.transformer.encoder.layer.8.attention.output.dense.weight', 'bert.transformer.encoder.layer.8.attention.self.key.bias', 'bert.transformer.encoder.layer.8.attention.self.key.weight', 'bert.transformer.encoder.layer.8.attention.self.query.bias', 'bert.transformer.encoder.layer.8.attention.self.query.weight', 'bert.transformer.encoder.layer.8.attention.self.value.bias', 'bert.transformer.encoder.layer.8.attention.self.value.weight', 'bert.transformer.encoder.layer.8.intermediate.dense.bias', 'bert.transformer.encoder.layer.8.intermediate.dense.weight', 'bert.transformer.encoder.layer.8.output.LayerNorm.bias', 'bert.transformer.encoder.layer.8.output.LayerNorm.weight', 'bert.transformer.encoder.layer.8.output.dense.bias', 'bert.transformer.encoder.layer.8.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.attention.output.dense.bias', 'bert.transformer.encoder.layer.9.attention.output.dense.weight', 'bert.transformer.encoder.layer.9.attention.self.key.bias', 'bert.transformer.encoder.layer.9.attention.self.key.weight', 'bert.transformer.encoder.layer.9.attention.self.query.bias', 'bert.transformer.encoder.layer.9.attention.self.query.weight', 'bert.transformer.encoder.layer.9.attention.self.value.bias', 'bert.transformer.encoder.layer.9.attention.self.value.weight', 'bert.transformer.encoder.layer.9.intermediate.dense.bias', 'bert.transformer.encoder.layer.9.intermediate.dense.weight', 'bert.transformer.encoder.layer.9.output.LayerNorm.bias', 'bert.transformer.encoder.layer.9.output.LayerNorm.weight', 'bert.transformer.encoder.layer.9.output.dense.bias', 'bert.transformer.encoder.layer.9.output.dense.weight', 'bert.transformer.pooler.dense.bias', 'bert.transformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/tmp/ipykernel_9945/1514377913.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text : title+description\n",
      "Input data feed :::  [CLS]Line coverage data is inconsistent[SEP]I'm running 2.4.1 on IDEA 7 and get inconsistent line and branch coverage in the editor: every line that is hit by the a test always gets \"1\" as the hitcount.  [SEP]\n",
      "within project split!\n",
      "usingbert tokenizer\n",
      "usingbert tokenizer\n",
      "[[101, 101, 2240, 6325, 2951, 2003, 20316, 102, 1045, 1005, 1049, 2770, 1016, 1012, 1018, 1012, 1015, 2006, 2801, 1021, 1998, 2131, 20316, 2240, 1998, 3589, 6325, 1999, 1996, 3559, 1024, 2296, 2240, 2008, 2003, 2718, 2011, 1996, 1037, 3231, 2467, 4152, 1000, 1015, 1000, 2004, 1996, 2718, 3597, 16671, 1012, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 101, 2469, 10273, 2465, 15069, 2003, 16542, 2043, 5834, 2006, 1037, 15723, 1998, 1037, 3231, 1011, 15723, 2013, 1996, 2168, 5003, 8159, 11336, 102, 2057, 2031, 2048, 2367, 5097, 2008, 2031, 1996, 2168, 25353, 27718, 5358, 1012, 2037, 3231, 3572, 2147, 7919, 2043, 6472, 2302, 25133, 1010, 2021, 2043, 2057, 2448, 2068, 2007, 25133, 1010, 2027, 8246, 2138, 4280, 2030, 7692, 6764, 2024, 4394, 2013, 1996, 2465, 15069, 1012, 2043, 2770, 1996, 16473, 2007, 25133, 1010, 1996, 3231, 3572, 2024, 6472, 3674, 2335, 1012, 2069, 1996, 2197, 2051, 2027, 2448, 2027, 8246, 1012, 2043, 9361, 1996, 5003, 8159, 2139, 8569, 2290, 6434, 1006, 2478, 1996, 1011, 1060, 5724, 1007, 1010, 1045, 2179, 2008, 1996, 2197, 2051, 1996, 3231, 3572, 2024, 2448, 1010, 1037, 15723, 5371, 2003, 4394, 2013, 1996, 2465, 15069, 1012, 2007, 2119, 5097, 2009, 2003, 1037, 15723, 5371, 2013, 1037, 5003, 8159, 11336, 2005, 2029, 2057, 2119, 12530, 2006, 1996, 15723, 1998, 3231, 1011, 15723, 4127, 1997, 1996, 11336, 1012, 2005, 2742, 2057, 2031, 1996, 2206, 1999, 1996, 13433, 2213, 1012, 20950, 5371, 1024, 1026, 24394, 1028, 1026, 2177, 3593, 1028, 1002, 1063, 6687, 1012, 2177, 3593, 1065, 1026, 1013, 2177, 3593, 1028, 1026, 20785, 3593, 1028, 8241, 1011, 2951, 1011, 3229, 1026, 1013, 20785, 3593, 1028, 1026, 2544, 1028, 1002, 1063, 2544, 1065, 1026, 1013, 2544, 1028, 1026, 2828, 1028, 3231, 1011, 15723, 1026, 1013, 2828, 1028, 1026, 9531, 1028, 3231, 1026, 1013, 9531, 1028, 1026, 1013, 24394, 1028, 1026, 24394, 1028, 1026, 2177, 3593, 1028, 1002, 1063, 6687, 1012, 2177, 3593, 1065, 1026, 1013, 2177, 3593, 1028, 1026, 20785, 3593, 1028, 8241, 1011, 2951, 1011, 3229, 1026, 1013, 20785, 3593, 1028, 1026, 2544, 1028, 1002, 1063, 2544, 1065, 1026, 1013, 2544, 1028, 1026, 1013, 24394, 1028, 1998, 2005, 2070, 3114, 1010, 2043, 1996, 3231, 3572, 2024, 6472, 2005, 1996, 2197, 2051, 1010, 1996, 2206, 2117, 24394, 2003, 2025, 2443, 1999, 1996, 2862, 1997, 25067, 1999, 1996, 2465, 15069, 1012, 1045, 2031, 4987, 1996, 13433, 2213, 1012, 20950, 6764, 2013, 1996, 11336, 2005, 2029, 1996, 3231, 3572, 8246, 1006, 8241, 1011, 4773, 1012, 13433, 2213, 1007, 1010, 1996, 13433, 2213, 1012, 20950, 6764, 2013, 2049, 3008, 1010, 1996, 13433, 2213, 1012, 20950, 5371, 2005, 1996, 11336, 2008, 19421, 2119, 1037, 15723, 1998, 1037, 3231, 1011, 15723, 1006, 8241, 1011, 2951, 1011, 3229, 1012, 13433, 2213, 1007, 1998, 1996, 8833, 5371, 2008, 1045, 2131, 2043, 2770, 5003, 8159, 2007, 1996, 1011, 1060, 5724, 1012, 2023, 2003, 1996, 2465, 15069, 2043, 1996, 3231, 3572, 8246, 1006, 5060, 2008, 1013, 23569, 1013, 15216, 1013, 15216, 1013, 20950, 1011, 2951, 1013, 3857, 1011, 16101, 1013, 8822, 1011, 22390, 1013, 8822, 1011, 8241, 1013, 8241, 1011, 2951, 1011, 3229, 1013, 4539, 1013, 8241, 1011, 2951, 1011, 3229, 1011, 1015, 1012, 1014, 1012, 1016, 1011, 20057, 12326, 1012, 15723, 2003, 4394, 1007, 1024, 3857, 2322, 1011, 13292, 1011, 2263, 5511, 1024, 4700, 1024, 5401, 1031, 2139, 8569, 2290, 1033, 1013, 23569, 1013, 15216, 1013, 15216, 1013, 20950, 1011, 2951, 1013, 3857, 1011, 16101, 1013, 8822, 1011, 22390, 1013, 8822, 1011, 8241, 1013, 8241, 102], [101, 101, 4292, 2569, 16015, 6434, 16101, 2000, 1037, 3120, 16101, 3972, 12870, 2015, 2035, 3120, 999, 102, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 101, 5587, 4118, 1013, 4861, 2504, 16015, 4292, 1999, 2622, 5144, 3931, 102, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 101, 2191, 3231, 2448, 10566, 4685, 2488, 1998, 2644, 14889, 1996, 21318, 11689, 102, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "BATCH_SIZE :  9\n",
      "BATCH_SIZE :  9\n",
      "usingbert tokenizer\n",
      "BATCH_SIZE :  9\n",
      "Start training for  {'train': ['clover'], 'test': ['clover']} .....\n",
      ">>> epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training MAE loss: 7.84\n",
      "-\n",
      " Average eval MAE loss: 2.08\n",
      "===============================\n",
      "MAE:  3.8808305\n",
      "MdAE:  0.7529577\n",
      ">>> epoch  1\n",
      " Average training MAE loss: 4.29\n",
      "-\n",
      " Average eval MAE loss: 5.54\n",
      "===============================\n",
      "MAE:  6.403457\n",
      "MdAE:  5.70718\n",
      ">>> epoch  2\n",
      " Average training MAE loss: 5.30\n",
      "-\n",
      " Average eval MAE loss: 2.04\n",
      "===============================\n",
      "MAE:  3.7138937\n",
      "MdAE:  1.6633122\n",
      ">>> epoch  3\n",
      " Average training MAE loss: 3.57\n",
      "-\n",
      " Average eval MAE loss: 2.16\n",
      "===============================\n",
      "MAE:  3.790447\n",
      "MdAE:  2.0924\n",
      ">>> epoch  4\n",
      " Average training MAE loss: 3.49\n",
      "-\n",
      " Average eval MAE loss: 2.11\n",
      "===============================\n",
      "MAE:  3.7529385\n",
      "MdAE:  1.9973655\n",
      ">>> epoch  5\n",
      " Average training MAE loss: 3.47\n",
      "-\n",
      " Average eval MAE loss: 2.16\n",
      "===============================\n",
      "MAE:  3.7857273\n",
      "MdAE:  2.080677\n",
      ">>> epoch  6\n",
      " Average training MAE loss: 3.61\n",
      "-\n",
      " Average eval MAE loss: 2.07\n",
      "===============================\n",
      "MAE:  3.8719645\n",
      "MdAE:  0.72565126\n",
      ">>> epoch  7\n",
      " Average training MAE loss: 3.64\n",
      "-\n",
      " Average eval MAE loss: 2.05\n",
      "===============================\n",
      "MAE:  3.7203655\n",
      "MdAE:  1.7186813\n",
      ">>> epoch  8\n",
      " Average training MAE loss: 3.47\n",
      "-\n",
      " Average eval MAE loss: 1.93\n",
      "===============================\n",
      "MAE:  3.6822367\n",
      "MdAE:  0.8587117\n",
      ">>> epoch  9\n",
      " Average training MAE loss: 3.86\n",
      "-\n",
      " Average eval MAE loss: 2.96\n",
      "===============================\n",
      "MAE:  4.320417\n",
      "MdAE:  3.3620596\n",
      ">>> epoch  10\n",
      " Average training MAE loss: 3.53\n",
      "-\n",
      " Average eval MAE loss: 2.12\n",
      "===============================\n",
      "MAE:  3.7592654\n",
      "MdAE:  2.0149486\n",
      ">>> epoch  11\n",
      " Average training MAE loss: 3.47\n",
      "-\n",
      " Average eval MAE loss: 2.29\n",
      "===============================\n",
      "MAE:  3.8737087\n",
      "MdAE:  2.2992098\n",
      ">>> epoch  12\n",
      " Average training MAE loss: 3.45\n",
      "-\n",
      " Average eval MAE loss: 1.94\n",
      "===============================\n",
      "MAE:  3.6948285\n",
      "MdAE:  0.81992924\n",
      ">>> epoch  13\n",
      " Average training MAE loss: 3.46\n",
      "-\n",
      " Average eval MAE loss: 1.93\n",
      "===============================\n",
      "MAE:  3.654935\n",
      "MdAE:  1.1588874\n",
      ">>> epoch  14\n",
      " Average training MAE loss: 3.49\n",
      "-\n",
      " Average eval MAE loss: 2.30\n",
      "===============================\n",
      "MAE:  3.8782845\n",
      "MdAE:  2.3105762\n",
      ">>> epoch  15\n",
      " Average training MAE loss: 3.52\n",
      "-\n",
      " Average eval MAE loss: 1.92\n",
      "===============================\n",
      "MAE:  3.6510177\n",
      "MdAE:  1.1253731\n",
      ">>> epoch  16\n",
      " Average training MAE loss: 3.49\n",
      "-\n",
      " Average eval MAE loss: 2.07\n",
      "===============================\n",
      "MAE:  3.7305393\n",
      "MdAE:  1.8057263\n",
      ">>> epoch  17\n",
      " Average training MAE loss: 3.46\n",
      "-\n",
      " Average eval MAE loss: 2.10\n",
      "===============================\n",
      "MAE:  3.7488832\n",
      "MdAE:  1.9626677\n",
      ">>> epoch  18\n",
      " Average training MAE loss: 3.47\n",
      "-\n",
      " Average eval MAE loss: 2.07\n",
      "===============================\n",
      "MAE:  3.734964\n",
      "MdAE:  1.8435788\n",
      ">>> epoch  19\n",
      " Average training MAE loss: 3.52\n",
      "-\n",
      " Average eval MAE loss: 2.06\n",
      "===============================\n",
      "MAE:  3.725845\n",
      "MdAE:  1.765562\n",
      "all done for one project\n",
      "results have been written into a text file!\n"
     ]
    }
   ],
   "source": [
    "global WITHIN_PROJECT\n",
    "WITHIN_PROJECT = True\n",
    "\n",
    "TRAIN_TEST_FILE_PAIRS = [\n",
    "                        # {'train': ['appceleratorstudio'], 'test': ['appceleratorstudio']},\n",
    "                        {'train': ['aptanastudio'], 'test': ['aptanastudio']},\n",
    "                        {'train': ['bamboo'], 'test': ['bamboo']},\n",
    "                        {'train': ['clover'], 'test': ['clover']},\n",
    "                        # {'train': ['datamanagement'], 'test': ['datamanagement']},\n",
    "                        # {'train': ['duracloud'], 'test': ['duracloud']},\n",
    "                        # {'train': ['jirasoftware'], 'test': ['jirasoftware']},\n",
    "                        # {'train': ['mesos'], 'test': ['mesos']},\n",
    "                        # {'train': ['moodle'], 'test': ['moodle']},\n",
    "                        # {'train': ['mule'], 'test': ['mule']},\n",
    "                        # {'train': ['mulestudio'], 'test': ['mulestudio']},\n",
    "                        # {'train': ['springxd'], 'test': ['springxd']},\n",
    "                        # {'train': ['talenddataquality'], 'test': ['talenddataquality']},\n",
    "                        # {'train': ['talendesb'], 'test': ['talendesb']},\n",
    "                        # {'train': ['titanium'], 'test': ['titanium']},\n",
    "                        # {'train': ['usergrid'], 'test': ['usergrid']},\n",
    "                        ]\n",
    "\n",
    "\n",
    "def main():\n",
    "    global TRAIN_TEST_FILE_PAIRS, MODEL, TOKENIZER, MODEL_NAME\n",
    "    for file in TRAIN_TEST_FILE_PAIRS:\n",
    "        if TOKENIZER == 'bbpe':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=50257)\n",
    "        elif TOKENIZER == 'gpt2':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=50256)\n",
    "        elif TOKENIZER == 'wordpiece':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
    "        elif TOKENIZER == 'sentencepiece':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
    "        elif TOKENIZER == 'wordlevel':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=3)\n",
    "        elif TOKENIZER == 'bert':\n",
    "            config = BertConfig(num_labels=1, pad_token_id=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if MODEL_NAME == 'gpt2':\n",
    "            MODEL = LinearGPT2.from_pretrained('gpt2', config=config)\n",
    "            MODEL.cuda()\n",
    "        elif MODEL_NAME == 'gpt2sp':\n",
    "            MODEL = GPT2SP.from_pretrained('gpt2', config=config)\n",
    "            MODEL.cuda()\n",
    "        elif MODEL_NAME == 'bert':\n",
    "            MODEL = BertSP.from_pretrained('bert-base-uncased', config=config)\n",
    "            MODEL.cuda()\n",
    "\n",
    "\n",
    "\n",
    "        file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names = data_processing(file_pair=file)\n",
    "        train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, MODEL, test_file_names)\n",
    "        del MODEL\n",
    "        torch.cuda.empty_cache()\n",
    "        global OUTPUT\n",
    "        with open('./results/' + str(file['train'][0]) + '_' + str(file['test'][0]) +'.txt', 'w+') as f:\n",
    "            f.writelines(OUTPUT)\n",
    "            print('results have been written into a text file!')\n",
    "            OUTPUT = \"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSte0lR_hfbo"
   },
   "source": [
    "### Cross Project Training Script - Within Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ij9vp2J2hfbo"
   },
   "outputs": [],
   "source": [
    "global WITHIN_PROJECT\n",
    "WITHIN_PROJECT = False\n",
    "\n",
    "# within repo\n",
    "TRAIN_TEST_FILE_PAIRS = [\n",
    "                        {'train': ['mesos'], 'test': ['usergrid']},\n",
    "                        {'train': ['usergrid'], 'test': ['mesos']},\n",
    "                        {'train': ['appceleratorstudio'], 'test': ['aptanastudio']},\n",
    "                        {'train': ['appceleratorstudio'], 'test': ['titanium']},\n",
    "                        {'train': ['titanium'], 'test': ['appceleratorstudio']},\n",
    "                        {'train': ['aptanastudio'], 'test': ['titanium']},\n",
    "                        {'train': ['mule'], 'test': ['mulestudio']},\n",
    "                        {'train': ['mulestudio'], 'test': ['mule']}\n",
    "                        ]\n",
    "\n",
    "\n",
    "def main():\n",
    "    global TRAIN_TEST_FILE_PAIRS, MODEL, TOKENIZER, MODEL_NAME\n",
    "    for file in TRAIN_TEST_FILE_PAIRS:\n",
    "        if TOKENIZER == 'bbpe':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=50257)\n",
    "        elif TOKENIZER == 'gpt2':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=50256)\n",
    "        elif TOKENIZER == 'wordpiece':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
    "        elif TOKENIZER == 'sentencepiece':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
    "        elif TOKENIZER == 'wordlevel':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=3)\n",
    "        if MODEL_NAME == 'gpt2':\n",
    "            MODEL = LinearGPT2.from_pretrained('gpt2', config=config)\n",
    "            MODEL.cuda()\n",
    "        elif MODEL_NAME == 'gpt2sp':\n",
    "            MODEL = GPT2SP.from_pretrained('gpt2', config=config)\n",
    "            MODEL.cuda()\n",
    "        file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names = data_processing(file_pair=file)\n",
    "        train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, MODEL, test_file_names)\n",
    "        del MODEL\n",
    "        torch.cuda.empty_cache()\n",
    "        global OUTPUT\n",
    "        with open('./results/' + str(file['train'][0]) + '_' + str(file['test'][0]) +'.txt', 'w+') as f:\n",
    "            f.writelines(OUTPUT)\n",
    "            print('results have been written into a text file!')\n",
    "            OUTPUT = \"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMcxbMB7hfbp"
   },
   "source": [
    "### Cross Project Training Script - Cross Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35iJqeeNhfbp"
   },
   "outputs": [],
   "source": [
    "global WITHIN_PROJECT\n",
    "WITHIN_PROJECT = False\n",
    "\n",
    "# cross repo\n",
    "TRAIN_TEST_FILE_PAIRS = [\n",
    "                        {'train': ['clover'], 'test': ['usergrid']},\n",
    "                        {'train': ['talendesb'], 'test': ['mesos']},\n",
    "                        {'train': ['talenddataquality'], 'test': ['aptanastudio']},\n",
    "                        {'train': ['mule'], 'test': ['titanium']},\n",
    "                        {'train': ['talenddataquality'], 'test': ['appceleratorstudio']},\n",
    "                        {'train': ['mulestudio'], 'test': ['titanium']},\n",
    "                        {'train': ['appceleratorstudio'], 'test': ['mulestudio']},\n",
    "                        {'train': ['appceleratorstudio'], 'test': ['mule']}\n",
    "                        ]\n",
    "\n",
    "\n",
    "def main():\n",
    "    global TRAIN_TEST_FILE_PAIRS, MODEL, TOKENIZER, MODEL_NAME\n",
    "    for file in TRAIN_TEST_FILE_PAIRS:\n",
    "        if TOKENIZER == 'gpt2':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=50256)\n",
    "        elif TOKENIZER == 'wordpiece':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
    "        elif TOKENIZER == 'sentencepiece':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=0)\n",
    "        elif TOKENIZER == 'wordlevel':\n",
    "            config = GPT2Config(num_labels=1, pad_token_id=3)\n",
    "        if MODEL_NAME == 'gpt2':\n",
    "            MODEL = LinearGPT2.from_pretrained('gpt2', config=config)\n",
    "            MODEL.cuda()\n",
    "        elif MODEL_NAME == 'gpt2sp':\n",
    "            MODEL = GPT2SP.from_pretrained('gpt2', config=config)\n",
    "            MODEL.cuda()\n",
    "        file_pair, train_dataloader, val_dataloader, all_test_dataloader, test_file_names = data_processing(file_pair=file)\n",
    "        train_eval_test(file_pair, train_dataloader, val_dataloader, all_test_dataloader, MODEL, test_file_names)\n",
    "        del MODEL\n",
    "        torch.cuda.empty_cache()\n",
    "        global OUTPUT\n",
    "        with open('./results/' + str(file['train'][0]) + '_' + str(file['test'][0]) +'.txt', 'w+') as f:\n",
    "            f.writelines(OUTPUT)\n",
    "            print('results have been written into a text file!')\n",
    "            OUTPUT = \"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "95502c86ed2e8b82df6e58f8450b4387aca3c902602792f25ea2aa6818e861bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
